{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "RL flood prediction.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "C_ckkFiFgPfr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zv8bStsXgPf1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = pd.read_csv(\"Train.csv\") \n",
        "#random.shuffle(data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dpD7YsUigPf5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_train, data_test = train_test_split(data, train_size = 0.7)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EuIIgustgPgA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b8fd4f95-aaa7-47fa-bd4f-c30dab2ae1e1"
      },
      "source": [
        "data[54:110]"
      ],
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>X</th>\n",
              "      <th>Y</th>\n",
              "      <th>target_2015</th>\n",
              "      <th>elevation</th>\n",
              "      <th>precip 2014-11-16 - 2014-11-23</th>\n",
              "      <th>precip 2014-11-23 - 2014-11-30</th>\n",
              "      <th>precip 2014-11-30 - 2014-12-07</th>\n",
              "      <th>precip 2014-12-07 - 2014-12-14</th>\n",
              "      <th>precip 2014-12-14 - 2014-12-21</th>\n",
              "      <th>precip 2014-12-21 - 2014-12-28</th>\n",
              "      <th>precip 2014-12-28 - 2015-01-04</th>\n",
              "      <th>precip 2015-01-04 - 2015-01-11</th>\n",
              "      <th>precip 2015-01-11 - 2015-01-18</th>\n",
              "      <th>precip 2015-01-18 - 2015-01-25</th>\n",
              "      <th>precip 2015-01-25 - 2015-02-01</th>\n",
              "      <th>precip 2015-02-01 - 2015-02-08</th>\n",
              "      <th>precip 2015-02-08 - 2015-02-15</th>\n",
              "      <th>precip 2015-02-15 - 2015-02-22</th>\n",
              "      <th>precip 2015-02-22 - 2015-03-01</th>\n",
              "      <th>precip 2015-03-01 - 2015-03-08</th>\n",
              "      <th>precip 2015-03-08 - 2015-03-15</th>\n",
              "      <th>precip 2019-01-20 - 2019-01-27</th>\n",
              "      <th>precip 2019-01-27 - 2019-02-03</th>\n",
              "      <th>precip 2019-02-03 - 2019-02-10</th>\n",
              "      <th>precip 2019-02-10 - 2019-02-17</th>\n",
              "      <th>precip 2019-02-17 - 2019-02-24</th>\n",
              "      <th>precip 2019-02-24 - 2019-03-03</th>\n",
              "      <th>precip 2019-03-03 - 2019-03-10</th>\n",
              "      <th>precip 2019-03-10 - 2019-03-17</th>\n",
              "      <th>precip 2019-03-17 - 2019-03-24</th>\n",
              "      <th>precip 2019-03-24 - 2019-03-31</th>\n",
              "      <th>precip 2019-03-31 - 2019-04-07</th>\n",
              "      <th>precip 2019-04-07 - 2019-04-14</th>\n",
              "      <th>precip 2019-04-14 - 2019-04-21</th>\n",
              "      <th>precip 2019-04-21 - 2019-04-28</th>\n",
              "      <th>precip 2019-04-28 - 2019-05-05</th>\n",
              "      <th>precip 2019-05-05 - 2019-05-12</th>\n",
              "      <th>precip 2019-05-12 - 2019-05-19</th>\n",
              "      <th>LC_Type1_mode</th>\n",
              "      <th>Square_ID</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>54</th>\n",
              "      <td>34.30</td>\n",
              "      <td>-15.93</td>\n",
              "      <td>0.0</td>\n",
              "      <td>423.262197</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>14.844025</td>\n",
              "      <td>14.552823</td>\n",
              "      <td>12.237766</td>\n",
              "      <td>57.451361</td>\n",
              "      <td>30.127047</td>\n",
              "      <td>30.449468</td>\n",
              "      <td>1.521829</td>\n",
              "      <td>29.389995</td>\n",
              "      <td>32.878318</td>\n",
              "      <td>8.179804</td>\n",
              "      <td>0.963981</td>\n",
              "      <td>16.659097</td>\n",
              "      <td>3.304466</td>\n",
              "      <td>0.0</td>\n",
              "      <td>12.992620</td>\n",
              "      <td>4.582856</td>\n",
              "      <td>35.037532</td>\n",
              "      <td>4.796012</td>\n",
              "      <td>28.083314</td>\n",
              "      <td>0.0</td>\n",
              "      <td>58.362456</td>\n",
              "      <td>18.264692</td>\n",
              "      <td>17.537486</td>\n",
              "      <td>0.896323</td>\n",
              "      <td>1.680000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9</td>\n",
              "      <td>4e3c38cc-14ce-11ea-bce5-f49634744a41</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>55</th>\n",
              "      <td>34.30</td>\n",
              "      <td>-15.92</td>\n",
              "      <td>0.0</td>\n",
              "      <td>397.435392</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>14.844025</td>\n",
              "      <td>14.552823</td>\n",
              "      <td>12.237766</td>\n",
              "      <td>57.451361</td>\n",
              "      <td>30.127047</td>\n",
              "      <td>30.449468</td>\n",
              "      <td>1.521829</td>\n",
              "      <td>29.389995</td>\n",
              "      <td>32.878318</td>\n",
              "      <td>8.179804</td>\n",
              "      <td>0.963981</td>\n",
              "      <td>16.659097</td>\n",
              "      <td>3.304466</td>\n",
              "      <td>0.0</td>\n",
              "      <td>12.992620</td>\n",
              "      <td>4.582856</td>\n",
              "      <td>35.037532</td>\n",
              "      <td>4.796012</td>\n",
              "      <td>28.083314</td>\n",
              "      <td>0.0</td>\n",
              "      <td>58.362456</td>\n",
              "      <td>18.264692</td>\n",
              "      <td>17.537486</td>\n",
              "      <td>0.896323</td>\n",
              "      <td>1.680000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9</td>\n",
              "      <td>4e3c38cd-14ce-11ea-bce5-f49634744a41</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>56</th>\n",
              "      <td>34.30</td>\n",
              "      <td>-15.91</td>\n",
              "      <td>0.0</td>\n",
              "      <td>426.076473</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>14.844025</td>\n",
              "      <td>14.552823</td>\n",
              "      <td>12.237766</td>\n",
              "      <td>57.451361</td>\n",
              "      <td>30.127047</td>\n",
              "      <td>30.449468</td>\n",
              "      <td>1.521829</td>\n",
              "      <td>29.389995</td>\n",
              "      <td>32.878318</td>\n",
              "      <td>8.179804</td>\n",
              "      <td>0.963981</td>\n",
              "      <td>16.659097</td>\n",
              "      <td>3.304466</td>\n",
              "      <td>0.0</td>\n",
              "      <td>12.992620</td>\n",
              "      <td>4.582856</td>\n",
              "      <td>35.037532</td>\n",
              "      <td>4.796012</td>\n",
              "      <td>28.083314</td>\n",
              "      <td>0.0</td>\n",
              "      <td>58.362456</td>\n",
              "      <td>18.264692</td>\n",
              "      <td>17.537486</td>\n",
              "      <td>0.896323</td>\n",
              "      <td>1.680000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9</td>\n",
              "      <td>4e3c38ce-14ce-11ea-bce5-f49634744a41</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57</th>\n",
              "      <td>34.30</td>\n",
              "      <td>-15.90</td>\n",
              "      <td>0.0</td>\n",
              "      <td>393.515730</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>14.844025</td>\n",
              "      <td>14.552823</td>\n",
              "      <td>12.237766</td>\n",
              "      <td>57.451361</td>\n",
              "      <td>30.127047</td>\n",
              "      <td>30.449468</td>\n",
              "      <td>1.521829</td>\n",
              "      <td>29.389995</td>\n",
              "      <td>32.878318</td>\n",
              "      <td>8.179804</td>\n",
              "      <td>0.963981</td>\n",
              "      <td>16.659097</td>\n",
              "      <td>3.304466</td>\n",
              "      <td>0.0</td>\n",
              "      <td>12.992620</td>\n",
              "      <td>4.582856</td>\n",
              "      <td>35.037532</td>\n",
              "      <td>4.796012</td>\n",
              "      <td>28.083314</td>\n",
              "      <td>0.0</td>\n",
              "      <td>58.362456</td>\n",
              "      <td>18.264692</td>\n",
              "      <td>17.537486</td>\n",
              "      <td>0.896323</td>\n",
              "      <td>1.680000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>10</td>\n",
              "      <td>4e3c38cf-14ce-11ea-bce5-f49634744a41</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>58</th>\n",
              "      <td>34.30</td>\n",
              "      <td>-15.89</td>\n",
              "      <td>0.0</td>\n",
              "      <td>377.585188</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>14.844025</td>\n",
              "      <td>14.552823</td>\n",
              "      <td>12.237766</td>\n",
              "      <td>57.451361</td>\n",
              "      <td>30.127047</td>\n",
              "      <td>30.449468</td>\n",
              "      <td>1.521829</td>\n",
              "      <td>29.389995</td>\n",
              "      <td>32.878318</td>\n",
              "      <td>8.179804</td>\n",
              "      <td>0.963981</td>\n",
              "      <td>16.659097</td>\n",
              "      <td>3.304466</td>\n",
              "      <td>0.0</td>\n",
              "      <td>12.992620</td>\n",
              "      <td>4.582856</td>\n",
              "      <td>35.037532</td>\n",
              "      <td>4.796012</td>\n",
              "      <td>28.083314</td>\n",
              "      <td>0.0</td>\n",
              "      <td>58.362456</td>\n",
              "      <td>18.264692</td>\n",
              "      <td>17.537486</td>\n",
              "      <td>0.896323</td>\n",
              "      <td>1.680000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>10</td>\n",
              "      <td>4e3c38d0-14ce-11ea-bce5-f49634744a41</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59</th>\n",
              "      <td>34.30</td>\n",
              "      <td>-15.88</td>\n",
              "      <td>0.0</td>\n",
              "      <td>382.242232</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>14.844025</td>\n",
              "      <td>14.552823</td>\n",
              "      <td>12.237766</td>\n",
              "      <td>57.451361</td>\n",
              "      <td>30.127047</td>\n",
              "      <td>30.449468</td>\n",
              "      <td>1.521829</td>\n",
              "      <td>29.389995</td>\n",
              "      <td>32.878318</td>\n",
              "      <td>8.179804</td>\n",
              "      <td>0.963981</td>\n",
              "      <td>16.659097</td>\n",
              "      <td>3.304466</td>\n",
              "      <td>0.0</td>\n",
              "      <td>12.992620</td>\n",
              "      <td>4.582856</td>\n",
              "      <td>35.037532</td>\n",
              "      <td>4.796012</td>\n",
              "      <td>28.083314</td>\n",
              "      <td>0.0</td>\n",
              "      <td>58.362456</td>\n",
              "      <td>18.264692</td>\n",
              "      <td>17.537486</td>\n",
              "      <td>0.896323</td>\n",
              "      <td>1.680000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>10</td>\n",
              "      <td>4e3c38d1-14ce-11ea-bce5-f49634744a41</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>60</th>\n",
              "      <td>34.30</td>\n",
              "      <td>-15.87</td>\n",
              "      <td>0.0</td>\n",
              "      <td>386.651364</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>14.844025</td>\n",
              "      <td>14.552823</td>\n",
              "      <td>12.237766</td>\n",
              "      <td>57.451361</td>\n",
              "      <td>30.127047</td>\n",
              "      <td>30.449468</td>\n",
              "      <td>1.521829</td>\n",
              "      <td>29.389995</td>\n",
              "      <td>32.878318</td>\n",
              "      <td>8.179804</td>\n",
              "      <td>0.963981</td>\n",
              "      <td>16.659097</td>\n",
              "      <td>3.304466</td>\n",
              "      <td>0.0</td>\n",
              "      <td>12.992620</td>\n",
              "      <td>4.582856</td>\n",
              "      <td>35.037532</td>\n",
              "      <td>4.796012</td>\n",
              "      <td>28.083314</td>\n",
              "      <td>0.0</td>\n",
              "      <td>58.362456</td>\n",
              "      <td>18.264692</td>\n",
              "      <td>17.537486</td>\n",
              "      <td>0.896323</td>\n",
              "      <td>1.680000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>10</td>\n",
              "      <td>4e3c38d2-14ce-11ea-bce5-f49634744a41</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>61</th>\n",
              "      <td>34.30</td>\n",
              "      <td>-15.86</td>\n",
              "      <td>0.0</td>\n",
              "      <td>370.314149</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>14.844025</td>\n",
              "      <td>14.552823</td>\n",
              "      <td>12.237766</td>\n",
              "      <td>57.451361</td>\n",
              "      <td>30.127047</td>\n",
              "      <td>30.449468</td>\n",
              "      <td>1.521829</td>\n",
              "      <td>29.389995</td>\n",
              "      <td>32.878318</td>\n",
              "      <td>8.179804</td>\n",
              "      <td>0.963981</td>\n",
              "      <td>16.659097</td>\n",
              "      <td>3.304466</td>\n",
              "      <td>0.0</td>\n",
              "      <td>12.992620</td>\n",
              "      <td>4.582856</td>\n",
              "      <td>35.037532</td>\n",
              "      <td>4.796012</td>\n",
              "      <td>28.083314</td>\n",
              "      <td>0.0</td>\n",
              "      <td>58.362456</td>\n",
              "      <td>18.264692</td>\n",
              "      <td>17.537486</td>\n",
              "      <td>0.896323</td>\n",
              "      <td>1.680000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9</td>\n",
              "      <td>4e3c38d3-14ce-11ea-bce5-f49634744a41</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>62</th>\n",
              "      <td>34.30</td>\n",
              "      <td>-15.85</td>\n",
              "      <td>0.0</td>\n",
              "      <td>353.401633</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>14.844025</td>\n",
              "      <td>14.552823</td>\n",
              "      <td>12.237766</td>\n",
              "      <td>57.451361</td>\n",
              "      <td>30.127047</td>\n",
              "      <td>30.449468</td>\n",
              "      <td>1.521829</td>\n",
              "      <td>29.389995</td>\n",
              "      <td>32.878318</td>\n",
              "      <td>8.179804</td>\n",
              "      <td>0.963981</td>\n",
              "      <td>16.659097</td>\n",
              "      <td>3.304466</td>\n",
              "      <td>0.0</td>\n",
              "      <td>12.992620</td>\n",
              "      <td>4.582856</td>\n",
              "      <td>35.037532</td>\n",
              "      <td>4.796012</td>\n",
              "      <td>28.083314</td>\n",
              "      <td>0.0</td>\n",
              "      <td>58.362456</td>\n",
              "      <td>18.264692</td>\n",
              "      <td>17.537486</td>\n",
              "      <td>0.896323</td>\n",
              "      <td>1.680000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9</td>\n",
              "      <td>4e3c38d4-14ce-11ea-bce5-f49634744a41</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>63</th>\n",
              "      <td>34.30</td>\n",
              "      <td>-15.84</td>\n",
              "      <td>0.0</td>\n",
              "      <td>343.453363</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>14.844025</td>\n",
              "      <td>14.552823</td>\n",
              "      <td>12.237766</td>\n",
              "      <td>57.451361</td>\n",
              "      <td>30.127047</td>\n",
              "      <td>30.449468</td>\n",
              "      <td>1.521829</td>\n",
              "      <td>29.389995</td>\n",
              "      <td>32.878318</td>\n",
              "      <td>8.179804</td>\n",
              "      <td>0.963981</td>\n",
              "      <td>16.659097</td>\n",
              "      <td>3.304466</td>\n",
              "      <td>0.0</td>\n",
              "      <td>12.992620</td>\n",
              "      <td>4.582856</td>\n",
              "      <td>35.037532</td>\n",
              "      <td>4.796012</td>\n",
              "      <td>28.083314</td>\n",
              "      <td>0.0</td>\n",
              "      <td>58.362456</td>\n",
              "      <td>18.264692</td>\n",
              "      <td>17.537486</td>\n",
              "      <td>0.896323</td>\n",
              "      <td>1.680000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9</td>\n",
              "      <td>4e3c38d5-14ce-11ea-bce5-f49634744a41</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>64</th>\n",
              "      <td>34.30</td>\n",
              "      <td>-15.83</td>\n",
              "      <td>0.0</td>\n",
              "      <td>336.420345</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>14.844025</td>\n",
              "      <td>14.552823</td>\n",
              "      <td>12.237766</td>\n",
              "      <td>57.451361</td>\n",
              "      <td>30.127047</td>\n",
              "      <td>30.449468</td>\n",
              "      <td>1.521829</td>\n",
              "      <td>29.389995</td>\n",
              "      <td>32.878318</td>\n",
              "      <td>8.179804</td>\n",
              "      <td>0.963981</td>\n",
              "      <td>16.659097</td>\n",
              "      <td>3.304466</td>\n",
              "      <td>0.0</td>\n",
              "      <td>12.992620</td>\n",
              "      <td>4.582856</td>\n",
              "      <td>35.037532</td>\n",
              "      <td>4.796012</td>\n",
              "      <td>28.083314</td>\n",
              "      <td>0.0</td>\n",
              "      <td>58.362456</td>\n",
              "      <td>18.264692</td>\n",
              "      <td>17.537486</td>\n",
              "      <td>0.896323</td>\n",
              "      <td>1.680000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9</td>\n",
              "      <td>4e3c38d6-14ce-11ea-bce5-f49634744a41</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>65</th>\n",
              "      <td>34.30</td>\n",
              "      <td>-15.82</td>\n",
              "      <td>0.0</td>\n",
              "      <td>349.031354</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>14.844025</td>\n",
              "      <td>14.552823</td>\n",
              "      <td>12.237766</td>\n",
              "      <td>57.451361</td>\n",
              "      <td>30.127047</td>\n",
              "      <td>30.449468</td>\n",
              "      <td>1.521829</td>\n",
              "      <td>29.389995</td>\n",
              "      <td>32.878318</td>\n",
              "      <td>8.179804</td>\n",
              "      <td>0.963981</td>\n",
              "      <td>16.659097</td>\n",
              "      <td>3.304466</td>\n",
              "      <td>0.0</td>\n",
              "      <td>12.992620</td>\n",
              "      <td>4.582856</td>\n",
              "      <td>35.037532</td>\n",
              "      <td>4.796012</td>\n",
              "      <td>28.083314</td>\n",
              "      <td>0.0</td>\n",
              "      <td>58.362456</td>\n",
              "      <td>18.264692</td>\n",
              "      <td>17.537486</td>\n",
              "      <td>0.896323</td>\n",
              "      <td>1.680000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9</td>\n",
              "      <td>4e3c38d7-14ce-11ea-bce5-f49634744a41</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>66</th>\n",
              "      <td>34.30</td>\n",
              "      <td>-15.81</td>\n",
              "      <td>0.0</td>\n",
              "      <td>454.469955</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>14.844025</td>\n",
              "      <td>14.552823</td>\n",
              "      <td>12.237766</td>\n",
              "      <td>57.451361</td>\n",
              "      <td>30.127047</td>\n",
              "      <td>30.449468</td>\n",
              "      <td>1.521829</td>\n",
              "      <td>29.389995</td>\n",
              "      <td>32.878318</td>\n",
              "      <td>8.179804</td>\n",
              "      <td>0.963981</td>\n",
              "      <td>16.659097</td>\n",
              "      <td>3.304466</td>\n",
              "      <td>0.0</td>\n",
              "      <td>12.992620</td>\n",
              "      <td>4.582856</td>\n",
              "      <td>35.037532</td>\n",
              "      <td>4.796012</td>\n",
              "      <td>28.083314</td>\n",
              "      <td>0.0</td>\n",
              "      <td>58.362456</td>\n",
              "      <td>18.264692</td>\n",
              "      <td>17.537486</td>\n",
              "      <td>0.896323</td>\n",
              "      <td>1.680000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9</td>\n",
              "      <td>4e3c38d8-14ce-11ea-bce5-f49634744a41</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>67</th>\n",
              "      <td>34.30</td>\n",
              "      <td>-15.80</td>\n",
              "      <td>0.0</td>\n",
              "      <td>514.125447</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>14.844025</td>\n",
              "      <td>14.552823</td>\n",
              "      <td>12.237766</td>\n",
              "      <td>57.451361</td>\n",
              "      <td>30.127047</td>\n",
              "      <td>30.449468</td>\n",
              "      <td>1.521829</td>\n",
              "      <td>29.389995</td>\n",
              "      <td>32.878318</td>\n",
              "      <td>8.179804</td>\n",
              "      <td>0.963981</td>\n",
              "      <td>16.659097</td>\n",
              "      <td>3.304466</td>\n",
              "      <td>0.0</td>\n",
              "      <td>12.992620</td>\n",
              "      <td>4.582856</td>\n",
              "      <td>35.037532</td>\n",
              "      <td>4.796012</td>\n",
              "      <td>28.083314</td>\n",
              "      <td>0.0</td>\n",
              "      <td>58.362456</td>\n",
              "      <td>18.264692</td>\n",
              "      <td>17.537486</td>\n",
              "      <td>0.896323</td>\n",
              "      <td>1.680000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9</td>\n",
              "      <td>4e3c38d9-14ce-11ea-bce5-f49634744a41</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>68</th>\n",
              "      <td>34.30</td>\n",
              "      <td>-15.79</td>\n",
              "      <td>0.0</td>\n",
              "      <td>526.816048</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>14.844025</td>\n",
              "      <td>14.552823</td>\n",
              "      <td>12.237766</td>\n",
              "      <td>57.451361</td>\n",
              "      <td>30.127047</td>\n",
              "      <td>30.449468</td>\n",
              "      <td>1.521829</td>\n",
              "      <td>29.389995</td>\n",
              "      <td>32.878318</td>\n",
              "      <td>8.179804</td>\n",
              "      <td>0.963981</td>\n",
              "      <td>16.659097</td>\n",
              "      <td>3.304466</td>\n",
              "      <td>0.0</td>\n",
              "      <td>12.992620</td>\n",
              "      <td>4.582856</td>\n",
              "      <td>35.037532</td>\n",
              "      <td>4.796012</td>\n",
              "      <td>28.083314</td>\n",
              "      <td>0.0</td>\n",
              "      <td>58.362456</td>\n",
              "      <td>18.264692</td>\n",
              "      <td>17.537486</td>\n",
              "      <td>0.896323</td>\n",
              "      <td>1.680000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9</td>\n",
              "      <td>4e3c38da-14ce-11ea-bce5-f49634744a41</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>69</th>\n",
              "      <td>34.30</td>\n",
              "      <td>-15.78</td>\n",
              "      <td>0.0</td>\n",
              "      <td>531.141623</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>14.844025</td>\n",
              "      <td>14.552823</td>\n",
              "      <td>12.237766</td>\n",
              "      <td>57.451361</td>\n",
              "      <td>30.127047</td>\n",
              "      <td>30.449468</td>\n",
              "      <td>1.521829</td>\n",
              "      <td>29.389995</td>\n",
              "      <td>32.878318</td>\n",
              "      <td>8.179804</td>\n",
              "      <td>0.963981</td>\n",
              "      <td>16.659097</td>\n",
              "      <td>3.304466</td>\n",
              "      <td>0.0</td>\n",
              "      <td>12.992620</td>\n",
              "      <td>4.582856</td>\n",
              "      <td>35.037532</td>\n",
              "      <td>4.796012</td>\n",
              "      <td>28.083314</td>\n",
              "      <td>0.0</td>\n",
              "      <td>58.362456</td>\n",
              "      <td>18.264692</td>\n",
              "      <td>17.537486</td>\n",
              "      <td>0.896323</td>\n",
              "      <td>1.680000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9</td>\n",
              "      <td>4e3c38db-14ce-11ea-bce5-f49634744a41</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>70</th>\n",
              "      <td>34.30</td>\n",
              "      <td>-15.77</td>\n",
              "      <td>0.0</td>\n",
              "      <td>557.624375</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>14.844025</td>\n",
              "      <td>14.552823</td>\n",
              "      <td>12.237766</td>\n",
              "      <td>57.451361</td>\n",
              "      <td>30.127047</td>\n",
              "      <td>30.449468</td>\n",
              "      <td>1.521829</td>\n",
              "      <td>29.389995</td>\n",
              "      <td>32.878318</td>\n",
              "      <td>8.179804</td>\n",
              "      <td>0.963981</td>\n",
              "      <td>16.659097</td>\n",
              "      <td>3.304466</td>\n",
              "      <td>0.0</td>\n",
              "      <td>12.992620</td>\n",
              "      <td>4.582856</td>\n",
              "      <td>35.037532</td>\n",
              "      <td>4.796012</td>\n",
              "      <td>28.083314</td>\n",
              "      <td>0.0</td>\n",
              "      <td>58.362456</td>\n",
              "      <td>18.264692</td>\n",
              "      <td>17.537486</td>\n",
              "      <td>0.896323</td>\n",
              "      <td>1.680000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9</td>\n",
              "      <td>4e3c38dc-14ce-11ea-bce5-f49634744a41</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>71</th>\n",
              "      <td>34.31</td>\n",
              "      <td>-15.94</td>\n",
              "      <td>0.0</td>\n",
              "      <td>362.128244</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>14.844025</td>\n",
              "      <td>14.552823</td>\n",
              "      <td>12.237766</td>\n",
              "      <td>57.451361</td>\n",
              "      <td>30.127047</td>\n",
              "      <td>30.449468</td>\n",
              "      <td>1.521829</td>\n",
              "      <td>29.389995</td>\n",
              "      <td>32.878318</td>\n",
              "      <td>8.179804</td>\n",
              "      <td>0.963981</td>\n",
              "      <td>16.659097</td>\n",
              "      <td>3.304466</td>\n",
              "      <td>0.0</td>\n",
              "      <td>12.992620</td>\n",
              "      <td>4.582856</td>\n",
              "      <td>35.037532</td>\n",
              "      <td>4.796012</td>\n",
              "      <td>28.083314</td>\n",
              "      <td>0.0</td>\n",
              "      <td>58.362456</td>\n",
              "      <td>18.264692</td>\n",
              "      <td>17.537486</td>\n",
              "      <td>0.896323</td>\n",
              "      <td>1.680000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>10</td>\n",
              "      <td>4e3c38dd-14ce-11ea-bce5-f49634744a41</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>72</th>\n",
              "      <td>34.31</td>\n",
              "      <td>-15.93</td>\n",
              "      <td>0.0</td>\n",
              "      <td>365.429064</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>14.844025</td>\n",
              "      <td>14.552823</td>\n",
              "      <td>12.237766</td>\n",
              "      <td>57.451361</td>\n",
              "      <td>30.127047</td>\n",
              "      <td>30.449468</td>\n",
              "      <td>1.521829</td>\n",
              "      <td>29.389995</td>\n",
              "      <td>32.878318</td>\n",
              "      <td>8.179804</td>\n",
              "      <td>0.963981</td>\n",
              "      <td>16.659097</td>\n",
              "      <td>3.304466</td>\n",
              "      <td>0.0</td>\n",
              "      <td>12.992620</td>\n",
              "      <td>4.582856</td>\n",
              "      <td>35.037532</td>\n",
              "      <td>4.796012</td>\n",
              "      <td>28.083314</td>\n",
              "      <td>0.0</td>\n",
              "      <td>58.362456</td>\n",
              "      <td>18.264692</td>\n",
              "      <td>17.537486</td>\n",
              "      <td>0.896323</td>\n",
              "      <td>1.680000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>10</td>\n",
              "      <td>4e3c38de-14ce-11ea-bce5-f49634744a41</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>73</th>\n",
              "      <td>34.31</td>\n",
              "      <td>-15.92</td>\n",
              "      <td>0.0</td>\n",
              "      <td>408.424255</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>14.844025</td>\n",
              "      <td>14.552823</td>\n",
              "      <td>12.237766</td>\n",
              "      <td>57.451361</td>\n",
              "      <td>30.127047</td>\n",
              "      <td>30.449468</td>\n",
              "      <td>1.521829</td>\n",
              "      <td>29.389995</td>\n",
              "      <td>32.878318</td>\n",
              "      <td>8.179804</td>\n",
              "      <td>0.963981</td>\n",
              "      <td>16.659097</td>\n",
              "      <td>3.304466</td>\n",
              "      <td>0.0</td>\n",
              "      <td>12.992620</td>\n",
              "      <td>4.582856</td>\n",
              "      <td>35.037532</td>\n",
              "      <td>4.796012</td>\n",
              "      <td>28.083314</td>\n",
              "      <td>0.0</td>\n",
              "      <td>58.362456</td>\n",
              "      <td>18.264692</td>\n",
              "      <td>17.537486</td>\n",
              "      <td>0.896323</td>\n",
              "      <td>1.680000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9</td>\n",
              "      <td>4e3c38df-14ce-11ea-bce5-f49634744a41</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>74</th>\n",
              "      <td>34.31</td>\n",
              "      <td>-15.91</td>\n",
              "      <td>0.0</td>\n",
              "      <td>441.564703</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>14.844025</td>\n",
              "      <td>14.552823</td>\n",
              "      <td>12.237766</td>\n",
              "      <td>57.451361</td>\n",
              "      <td>30.127047</td>\n",
              "      <td>30.449468</td>\n",
              "      <td>1.521829</td>\n",
              "      <td>29.389995</td>\n",
              "      <td>32.878318</td>\n",
              "      <td>8.179804</td>\n",
              "      <td>0.963981</td>\n",
              "      <td>16.659097</td>\n",
              "      <td>3.304466</td>\n",
              "      <td>0.0</td>\n",
              "      <td>12.992620</td>\n",
              "      <td>4.582856</td>\n",
              "      <td>35.037532</td>\n",
              "      <td>4.796012</td>\n",
              "      <td>28.083314</td>\n",
              "      <td>0.0</td>\n",
              "      <td>58.362456</td>\n",
              "      <td>18.264692</td>\n",
              "      <td>17.537486</td>\n",
              "      <td>0.896323</td>\n",
              "      <td>1.680000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9</td>\n",
              "      <td>4e3c38e0-14ce-11ea-bce5-f49634744a41</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75</th>\n",
              "      <td>34.31</td>\n",
              "      <td>-15.90</td>\n",
              "      <td>0.0</td>\n",
              "      <td>386.994461</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>14.844025</td>\n",
              "      <td>14.552823</td>\n",
              "      <td>12.237766</td>\n",
              "      <td>57.451361</td>\n",
              "      <td>30.127047</td>\n",
              "      <td>30.449468</td>\n",
              "      <td>1.521829</td>\n",
              "      <td>29.389995</td>\n",
              "      <td>32.878318</td>\n",
              "      <td>8.179804</td>\n",
              "      <td>0.963981</td>\n",
              "      <td>16.659097</td>\n",
              "      <td>3.304466</td>\n",
              "      <td>0.0</td>\n",
              "      <td>12.992620</td>\n",
              "      <td>4.582856</td>\n",
              "      <td>35.037532</td>\n",
              "      <td>4.796012</td>\n",
              "      <td>28.083314</td>\n",
              "      <td>0.0</td>\n",
              "      <td>58.362456</td>\n",
              "      <td>18.264692</td>\n",
              "      <td>17.537486</td>\n",
              "      <td>0.896323</td>\n",
              "      <td>1.680000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9</td>\n",
              "      <td>4e3c38e1-14ce-11ea-bce5-f49634744a41</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>76</th>\n",
              "      <td>34.31</td>\n",
              "      <td>-15.89</td>\n",
              "      <td>0.0</td>\n",
              "      <td>372.116383</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>14.844025</td>\n",
              "      <td>14.552823</td>\n",
              "      <td>12.237766</td>\n",
              "      <td>57.451361</td>\n",
              "      <td>30.127047</td>\n",
              "      <td>30.449468</td>\n",
              "      <td>1.521829</td>\n",
              "      <td>29.389995</td>\n",
              "      <td>32.878318</td>\n",
              "      <td>8.179804</td>\n",
              "      <td>0.963981</td>\n",
              "      <td>16.659097</td>\n",
              "      <td>3.304466</td>\n",
              "      <td>0.0</td>\n",
              "      <td>12.992620</td>\n",
              "      <td>4.582856</td>\n",
              "      <td>35.037532</td>\n",
              "      <td>4.796012</td>\n",
              "      <td>28.083314</td>\n",
              "      <td>0.0</td>\n",
              "      <td>58.362456</td>\n",
              "      <td>18.264692</td>\n",
              "      <td>17.537486</td>\n",
              "      <td>0.896323</td>\n",
              "      <td>1.680000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9</td>\n",
              "      <td>4e3c38e2-14ce-11ea-bce5-f49634744a41</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>77</th>\n",
              "      <td>34.31</td>\n",
              "      <td>-15.88</td>\n",
              "      <td>0.0</td>\n",
              "      <td>381.983484</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>14.844025</td>\n",
              "      <td>14.552823</td>\n",
              "      <td>12.237766</td>\n",
              "      <td>57.451361</td>\n",
              "      <td>30.127047</td>\n",
              "      <td>30.449468</td>\n",
              "      <td>1.521829</td>\n",
              "      <td>29.389995</td>\n",
              "      <td>32.878318</td>\n",
              "      <td>8.179804</td>\n",
              "      <td>0.963981</td>\n",
              "      <td>16.659097</td>\n",
              "      <td>3.304466</td>\n",
              "      <td>0.0</td>\n",
              "      <td>12.992620</td>\n",
              "      <td>4.582856</td>\n",
              "      <td>35.037532</td>\n",
              "      <td>4.796012</td>\n",
              "      <td>28.083314</td>\n",
              "      <td>0.0</td>\n",
              "      <td>58.362456</td>\n",
              "      <td>18.264692</td>\n",
              "      <td>17.537486</td>\n",
              "      <td>0.896323</td>\n",
              "      <td>1.680000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>10</td>\n",
              "      <td>4e3c38e3-14ce-11ea-bce5-f49634744a41</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>78</th>\n",
              "      <td>34.31</td>\n",
              "      <td>-15.87</td>\n",
              "      <td>0.0</td>\n",
              "      <td>379.456464</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>14.844025</td>\n",
              "      <td>14.552823</td>\n",
              "      <td>12.237766</td>\n",
              "      <td>57.451361</td>\n",
              "      <td>30.127047</td>\n",
              "      <td>30.449468</td>\n",
              "      <td>1.521829</td>\n",
              "      <td>29.389995</td>\n",
              "      <td>32.878318</td>\n",
              "      <td>8.179804</td>\n",
              "      <td>0.963981</td>\n",
              "      <td>16.659097</td>\n",
              "      <td>3.304466</td>\n",
              "      <td>0.0</td>\n",
              "      <td>12.992620</td>\n",
              "      <td>4.582856</td>\n",
              "      <td>35.037532</td>\n",
              "      <td>4.796012</td>\n",
              "      <td>28.083314</td>\n",
              "      <td>0.0</td>\n",
              "      <td>58.362456</td>\n",
              "      <td>18.264692</td>\n",
              "      <td>17.537486</td>\n",
              "      <td>0.896323</td>\n",
              "      <td>1.680000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>10</td>\n",
              "      <td>4e3c38e4-14ce-11ea-bce5-f49634744a41</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>79</th>\n",
              "      <td>34.31</td>\n",
              "      <td>-15.86</td>\n",
              "      <td>0.0</td>\n",
              "      <td>355.160001</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>14.844025</td>\n",
              "      <td>14.552823</td>\n",
              "      <td>12.237766</td>\n",
              "      <td>57.451361</td>\n",
              "      <td>30.127047</td>\n",
              "      <td>30.449468</td>\n",
              "      <td>1.521829</td>\n",
              "      <td>29.389995</td>\n",
              "      <td>32.878318</td>\n",
              "      <td>8.179804</td>\n",
              "      <td>0.963981</td>\n",
              "      <td>16.659097</td>\n",
              "      <td>3.304466</td>\n",
              "      <td>0.0</td>\n",
              "      <td>12.992620</td>\n",
              "      <td>4.582856</td>\n",
              "      <td>35.037532</td>\n",
              "      <td>4.796012</td>\n",
              "      <td>28.083314</td>\n",
              "      <td>0.0</td>\n",
              "      <td>58.362456</td>\n",
              "      <td>18.264692</td>\n",
              "      <td>17.537486</td>\n",
              "      <td>0.896323</td>\n",
              "      <td>1.680000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>10</td>\n",
              "      <td>4e3c38e5-14ce-11ea-bce5-f49634744a41</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>80</th>\n",
              "      <td>34.31</td>\n",
              "      <td>-15.85</td>\n",
              "      <td>0.0</td>\n",
              "      <td>341.530890</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>14.844025</td>\n",
              "      <td>14.552823</td>\n",
              "      <td>12.237766</td>\n",
              "      <td>57.451361</td>\n",
              "      <td>30.127047</td>\n",
              "      <td>30.449468</td>\n",
              "      <td>1.521829</td>\n",
              "      <td>29.389995</td>\n",
              "      <td>32.878318</td>\n",
              "      <td>8.179804</td>\n",
              "      <td>0.963981</td>\n",
              "      <td>16.659097</td>\n",
              "      <td>3.304466</td>\n",
              "      <td>0.0</td>\n",
              "      <td>12.992620</td>\n",
              "      <td>4.582856</td>\n",
              "      <td>35.037532</td>\n",
              "      <td>4.796012</td>\n",
              "      <td>28.083314</td>\n",
              "      <td>0.0</td>\n",
              "      <td>58.362456</td>\n",
              "      <td>18.264692</td>\n",
              "      <td>17.537486</td>\n",
              "      <td>0.896323</td>\n",
              "      <td>1.680000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9</td>\n",
              "      <td>4e3c38e6-14ce-11ea-bce5-f49634744a41</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>81</th>\n",
              "      <td>34.31</td>\n",
              "      <td>-15.84</td>\n",
              "      <td>0.0</td>\n",
              "      <td>327.545023</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>14.844025</td>\n",
              "      <td>14.552823</td>\n",
              "      <td>12.237766</td>\n",
              "      <td>57.451361</td>\n",
              "      <td>30.127047</td>\n",
              "      <td>30.449468</td>\n",
              "      <td>1.521829</td>\n",
              "      <td>29.389995</td>\n",
              "      <td>32.878318</td>\n",
              "      <td>8.179804</td>\n",
              "      <td>0.963981</td>\n",
              "      <td>16.659097</td>\n",
              "      <td>3.304466</td>\n",
              "      <td>0.0</td>\n",
              "      <td>12.992620</td>\n",
              "      <td>4.582856</td>\n",
              "      <td>35.037532</td>\n",
              "      <td>4.796012</td>\n",
              "      <td>28.083314</td>\n",
              "      <td>0.0</td>\n",
              "      <td>58.362456</td>\n",
              "      <td>18.264692</td>\n",
              "      <td>17.537486</td>\n",
              "      <td>0.896323</td>\n",
              "      <td>1.680000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9</td>\n",
              "      <td>4e3c38e7-14ce-11ea-bce5-f49634744a41</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>82</th>\n",
              "      <td>34.31</td>\n",
              "      <td>-15.83</td>\n",
              "      <td>0.0</td>\n",
              "      <td>335.254097</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>14.844025</td>\n",
              "      <td>14.552823</td>\n",
              "      <td>12.237766</td>\n",
              "      <td>57.451361</td>\n",
              "      <td>30.127047</td>\n",
              "      <td>30.449468</td>\n",
              "      <td>1.521829</td>\n",
              "      <td>29.389995</td>\n",
              "      <td>32.878318</td>\n",
              "      <td>8.179804</td>\n",
              "      <td>0.963981</td>\n",
              "      <td>16.659097</td>\n",
              "      <td>3.304466</td>\n",
              "      <td>0.0</td>\n",
              "      <td>12.992620</td>\n",
              "      <td>4.582856</td>\n",
              "      <td>35.037532</td>\n",
              "      <td>4.796012</td>\n",
              "      <td>28.083314</td>\n",
              "      <td>0.0</td>\n",
              "      <td>58.362456</td>\n",
              "      <td>18.264692</td>\n",
              "      <td>17.537486</td>\n",
              "      <td>0.896323</td>\n",
              "      <td>1.680000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9</td>\n",
              "      <td>4e3c38e8-14ce-11ea-bce5-f49634744a41</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>83</th>\n",
              "      <td>34.31</td>\n",
              "      <td>-15.82</td>\n",
              "      <td>0.0</td>\n",
              "      <td>457.314529</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>14.844025</td>\n",
              "      <td>14.552823</td>\n",
              "      <td>12.237766</td>\n",
              "      <td>57.451361</td>\n",
              "      <td>30.127047</td>\n",
              "      <td>30.449468</td>\n",
              "      <td>1.521829</td>\n",
              "      <td>29.389995</td>\n",
              "      <td>32.878318</td>\n",
              "      <td>8.179804</td>\n",
              "      <td>0.963981</td>\n",
              "      <td>16.659097</td>\n",
              "      <td>3.304466</td>\n",
              "      <td>0.0</td>\n",
              "      <td>12.992620</td>\n",
              "      <td>4.582856</td>\n",
              "      <td>35.037532</td>\n",
              "      <td>4.796012</td>\n",
              "      <td>28.083314</td>\n",
              "      <td>0.0</td>\n",
              "      <td>58.362456</td>\n",
              "      <td>18.264692</td>\n",
              "      <td>17.537486</td>\n",
              "      <td>0.896323</td>\n",
              "      <td>1.680000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9</td>\n",
              "      <td>4e3c38e9-14ce-11ea-bce5-f49634744a41</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>84</th>\n",
              "      <td>34.31</td>\n",
              "      <td>-15.81</td>\n",
              "      <td>0.0</td>\n",
              "      <td>536.997119</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>14.844025</td>\n",
              "      <td>14.552823</td>\n",
              "      <td>12.237766</td>\n",
              "      <td>57.451361</td>\n",
              "      <td>30.127047</td>\n",
              "      <td>30.449468</td>\n",
              "      <td>1.521829</td>\n",
              "      <td>29.389995</td>\n",
              "      <td>32.878318</td>\n",
              "      <td>8.179804</td>\n",
              "      <td>0.963981</td>\n",
              "      <td>16.659097</td>\n",
              "      <td>3.304466</td>\n",
              "      <td>0.0</td>\n",
              "      <td>12.992620</td>\n",
              "      <td>4.582856</td>\n",
              "      <td>35.037532</td>\n",
              "      <td>4.796012</td>\n",
              "      <td>28.083314</td>\n",
              "      <td>0.0</td>\n",
              "      <td>58.362456</td>\n",
              "      <td>18.264692</td>\n",
              "      <td>17.537486</td>\n",
              "      <td>0.896323</td>\n",
              "      <td>1.680000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9</td>\n",
              "      <td>4e3c38ea-14ce-11ea-bce5-f49634744a41</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>85</th>\n",
              "      <td>34.31</td>\n",
              "      <td>-15.80</td>\n",
              "      <td>0.0</td>\n",
              "      <td>507.131209</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>14.844025</td>\n",
              "      <td>14.552823</td>\n",
              "      <td>12.237766</td>\n",
              "      <td>57.451361</td>\n",
              "      <td>30.127047</td>\n",
              "      <td>30.449468</td>\n",
              "      <td>1.521829</td>\n",
              "      <td>29.389995</td>\n",
              "      <td>32.878318</td>\n",
              "      <td>8.179804</td>\n",
              "      <td>0.963981</td>\n",
              "      <td>16.659097</td>\n",
              "      <td>3.304466</td>\n",
              "      <td>0.0</td>\n",
              "      <td>12.992620</td>\n",
              "      <td>4.582856</td>\n",
              "      <td>35.037532</td>\n",
              "      <td>4.796012</td>\n",
              "      <td>28.083314</td>\n",
              "      <td>0.0</td>\n",
              "      <td>58.362456</td>\n",
              "      <td>18.264692</td>\n",
              "      <td>17.537486</td>\n",
              "      <td>0.896323</td>\n",
              "      <td>1.680000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9</td>\n",
              "      <td>4e3c38eb-14ce-11ea-bce5-f49634744a41</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>86</th>\n",
              "      <td>34.31</td>\n",
              "      <td>-15.79</td>\n",
              "      <td>0.0</td>\n",
              "      <td>530.290230</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>14.844025</td>\n",
              "      <td>14.552823</td>\n",
              "      <td>12.237766</td>\n",
              "      <td>57.451361</td>\n",
              "      <td>30.127047</td>\n",
              "      <td>30.449468</td>\n",
              "      <td>1.521829</td>\n",
              "      <td>29.389995</td>\n",
              "      <td>32.878318</td>\n",
              "      <td>8.179804</td>\n",
              "      <td>0.963981</td>\n",
              "      <td>16.659097</td>\n",
              "      <td>3.304466</td>\n",
              "      <td>0.0</td>\n",
              "      <td>12.992620</td>\n",
              "      <td>4.582856</td>\n",
              "      <td>35.037532</td>\n",
              "      <td>4.796012</td>\n",
              "      <td>28.083314</td>\n",
              "      <td>0.0</td>\n",
              "      <td>58.362456</td>\n",
              "      <td>18.264692</td>\n",
              "      <td>17.537486</td>\n",
              "      <td>0.896323</td>\n",
              "      <td>1.680000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8</td>\n",
              "      <td>4e3c38ec-14ce-11ea-bce5-f49634744a41</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>87</th>\n",
              "      <td>34.31</td>\n",
              "      <td>-15.78</td>\n",
              "      <td>0.0</td>\n",
              "      <td>554.398753</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>14.844025</td>\n",
              "      <td>14.552823</td>\n",
              "      <td>12.237766</td>\n",
              "      <td>57.451361</td>\n",
              "      <td>30.127047</td>\n",
              "      <td>30.449468</td>\n",
              "      <td>1.521829</td>\n",
              "      <td>29.389995</td>\n",
              "      <td>32.878318</td>\n",
              "      <td>8.179804</td>\n",
              "      <td>0.963981</td>\n",
              "      <td>16.659097</td>\n",
              "      <td>3.304466</td>\n",
              "      <td>0.0</td>\n",
              "      <td>12.992620</td>\n",
              "      <td>4.582856</td>\n",
              "      <td>35.037532</td>\n",
              "      <td>4.796012</td>\n",
              "      <td>28.083314</td>\n",
              "      <td>0.0</td>\n",
              "      <td>58.362456</td>\n",
              "      <td>18.264692</td>\n",
              "      <td>17.537486</td>\n",
              "      <td>0.896323</td>\n",
              "      <td>1.680000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8</td>\n",
              "      <td>4e3c38ed-14ce-11ea-bce5-f49634744a41</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88</th>\n",
              "      <td>34.31</td>\n",
              "      <td>-15.77</td>\n",
              "      <td>0.0</td>\n",
              "      <td>562.430027</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>14.844025</td>\n",
              "      <td>14.552823</td>\n",
              "      <td>12.237766</td>\n",
              "      <td>57.451361</td>\n",
              "      <td>30.127047</td>\n",
              "      <td>30.449468</td>\n",
              "      <td>1.521829</td>\n",
              "      <td>29.389995</td>\n",
              "      <td>32.878318</td>\n",
              "      <td>8.179804</td>\n",
              "      <td>0.963981</td>\n",
              "      <td>16.659097</td>\n",
              "      <td>3.304466</td>\n",
              "      <td>0.0</td>\n",
              "      <td>12.992620</td>\n",
              "      <td>4.582856</td>\n",
              "      <td>35.037532</td>\n",
              "      <td>4.796012</td>\n",
              "      <td>28.083314</td>\n",
              "      <td>0.0</td>\n",
              "      <td>58.362456</td>\n",
              "      <td>18.264692</td>\n",
              "      <td>17.537486</td>\n",
              "      <td>0.896323</td>\n",
              "      <td>1.680000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9</td>\n",
              "      <td>4e3c38ee-14ce-11ea-bce5-f49634744a41</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>89</th>\n",
              "      <td>34.31</td>\n",
              "      <td>-15.76</td>\n",
              "      <td>0.0</td>\n",
              "      <td>594.816432</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>14.844025</td>\n",
              "      <td>14.552823</td>\n",
              "      <td>12.237766</td>\n",
              "      <td>57.451361</td>\n",
              "      <td>30.127047</td>\n",
              "      <td>30.449468</td>\n",
              "      <td>1.521829</td>\n",
              "      <td>29.389995</td>\n",
              "      <td>32.878318</td>\n",
              "      <td>8.179804</td>\n",
              "      <td>0.963981</td>\n",
              "      <td>16.659097</td>\n",
              "      <td>3.304466</td>\n",
              "      <td>0.0</td>\n",
              "      <td>12.992620</td>\n",
              "      <td>4.582856</td>\n",
              "      <td>35.037532</td>\n",
              "      <td>4.796012</td>\n",
              "      <td>28.083314</td>\n",
              "      <td>0.0</td>\n",
              "      <td>58.362456</td>\n",
              "      <td>18.264692</td>\n",
              "      <td>17.537486</td>\n",
              "      <td>0.896323</td>\n",
              "      <td>1.680000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9</td>\n",
              "      <td>4e3c38ef-14ce-11ea-bce5-f49634744a41</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>90</th>\n",
              "      <td>34.32</td>\n",
              "      <td>-15.94</td>\n",
              "      <td>0.0</td>\n",
              "      <td>352.013483</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>14.844025</td>\n",
              "      <td>14.552823</td>\n",
              "      <td>12.237766</td>\n",
              "      <td>57.451361</td>\n",
              "      <td>30.127047</td>\n",
              "      <td>30.449468</td>\n",
              "      <td>1.521829</td>\n",
              "      <td>29.389995</td>\n",
              "      <td>32.878318</td>\n",
              "      <td>8.179804</td>\n",
              "      <td>0.963981</td>\n",
              "      <td>16.659097</td>\n",
              "      <td>3.304466</td>\n",
              "      <td>0.0</td>\n",
              "      <td>12.992620</td>\n",
              "      <td>4.582856</td>\n",
              "      <td>35.037532</td>\n",
              "      <td>4.796012</td>\n",
              "      <td>28.083314</td>\n",
              "      <td>0.0</td>\n",
              "      <td>58.362456</td>\n",
              "      <td>18.264692</td>\n",
              "      <td>17.537486</td>\n",
              "      <td>0.896323</td>\n",
              "      <td>1.680000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>10</td>\n",
              "      <td>4e3c38f0-14ce-11ea-bce5-f49634744a41</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>91</th>\n",
              "      <td>34.32</td>\n",
              "      <td>-15.93</td>\n",
              "      <td>0.0</td>\n",
              "      <td>343.523888</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>14.844025</td>\n",
              "      <td>14.552823</td>\n",
              "      <td>12.237766</td>\n",
              "      <td>57.451361</td>\n",
              "      <td>30.127047</td>\n",
              "      <td>30.449468</td>\n",
              "      <td>1.521829</td>\n",
              "      <td>29.389995</td>\n",
              "      <td>32.878318</td>\n",
              "      <td>8.179804</td>\n",
              "      <td>0.963981</td>\n",
              "      <td>16.659097</td>\n",
              "      <td>3.304466</td>\n",
              "      <td>0.0</td>\n",
              "      <td>12.992620</td>\n",
              "      <td>4.582856</td>\n",
              "      <td>35.037532</td>\n",
              "      <td>4.796012</td>\n",
              "      <td>28.083314</td>\n",
              "      <td>0.0</td>\n",
              "      <td>58.362456</td>\n",
              "      <td>18.264692</td>\n",
              "      <td>17.537486</td>\n",
              "      <td>0.896323</td>\n",
              "      <td>1.680000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>10</td>\n",
              "      <td>4e3c38f1-14ce-11ea-bce5-f49634744a41</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>92</th>\n",
              "      <td>34.32</td>\n",
              "      <td>-15.92</td>\n",
              "      <td>0.0</td>\n",
              "      <td>342.378283</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>14.844025</td>\n",
              "      <td>14.552823</td>\n",
              "      <td>12.237766</td>\n",
              "      <td>57.451361</td>\n",
              "      <td>30.127047</td>\n",
              "      <td>30.449468</td>\n",
              "      <td>1.521829</td>\n",
              "      <td>29.389995</td>\n",
              "      <td>32.878318</td>\n",
              "      <td>8.179804</td>\n",
              "      <td>0.963981</td>\n",
              "      <td>16.659097</td>\n",
              "      <td>3.304466</td>\n",
              "      <td>0.0</td>\n",
              "      <td>12.992620</td>\n",
              "      <td>4.582856</td>\n",
              "      <td>35.037532</td>\n",
              "      <td>4.796012</td>\n",
              "      <td>28.083314</td>\n",
              "      <td>0.0</td>\n",
              "      <td>58.362456</td>\n",
              "      <td>18.264692</td>\n",
              "      <td>17.537486</td>\n",
              "      <td>0.896323</td>\n",
              "      <td>1.680000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9</td>\n",
              "      <td>4e3c38f2-14ce-11ea-bce5-f49634744a41</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>93</th>\n",
              "      <td>34.32</td>\n",
              "      <td>-15.91</td>\n",
              "      <td>0.0</td>\n",
              "      <td>354.656964</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>14.844025</td>\n",
              "      <td>14.552823</td>\n",
              "      <td>12.237766</td>\n",
              "      <td>57.451361</td>\n",
              "      <td>30.127047</td>\n",
              "      <td>30.449468</td>\n",
              "      <td>1.521829</td>\n",
              "      <td>29.389995</td>\n",
              "      <td>32.878318</td>\n",
              "      <td>8.179804</td>\n",
              "      <td>0.963981</td>\n",
              "      <td>16.659097</td>\n",
              "      <td>3.304466</td>\n",
              "      <td>0.0</td>\n",
              "      <td>12.992620</td>\n",
              "      <td>4.582856</td>\n",
              "      <td>35.037532</td>\n",
              "      <td>4.796012</td>\n",
              "      <td>28.083314</td>\n",
              "      <td>0.0</td>\n",
              "      <td>58.362456</td>\n",
              "      <td>18.264692</td>\n",
              "      <td>17.537486</td>\n",
              "      <td>0.896323</td>\n",
              "      <td>1.680000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9</td>\n",
              "      <td>4e3c38f3-14ce-11ea-bce5-f49634744a41</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>94</th>\n",
              "      <td>34.32</td>\n",
              "      <td>-15.90</td>\n",
              "      <td>0.0</td>\n",
              "      <td>359.054342</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>14.844025</td>\n",
              "      <td>14.552823</td>\n",
              "      <td>12.237766</td>\n",
              "      <td>57.451361</td>\n",
              "      <td>30.127047</td>\n",
              "      <td>30.449468</td>\n",
              "      <td>1.521829</td>\n",
              "      <td>29.389995</td>\n",
              "      <td>32.878318</td>\n",
              "      <td>8.179804</td>\n",
              "      <td>0.963981</td>\n",
              "      <td>16.659097</td>\n",
              "      <td>3.304466</td>\n",
              "      <td>0.0</td>\n",
              "      <td>12.992620</td>\n",
              "      <td>4.582856</td>\n",
              "      <td>35.037532</td>\n",
              "      <td>4.796012</td>\n",
              "      <td>28.083314</td>\n",
              "      <td>0.0</td>\n",
              "      <td>58.362456</td>\n",
              "      <td>18.264692</td>\n",
              "      <td>17.537486</td>\n",
              "      <td>0.896323</td>\n",
              "      <td>1.680000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9</td>\n",
              "      <td>4e3c38f4-14ce-11ea-bce5-f49634744a41</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>34.32</td>\n",
              "      <td>-15.89</td>\n",
              "      <td>0.0</td>\n",
              "      <td>379.097639</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>14.844025</td>\n",
              "      <td>14.552823</td>\n",
              "      <td>12.237766</td>\n",
              "      <td>57.451361</td>\n",
              "      <td>30.127047</td>\n",
              "      <td>30.449468</td>\n",
              "      <td>1.521829</td>\n",
              "      <td>29.389995</td>\n",
              "      <td>32.878318</td>\n",
              "      <td>8.179804</td>\n",
              "      <td>0.963981</td>\n",
              "      <td>16.659097</td>\n",
              "      <td>3.304466</td>\n",
              "      <td>0.0</td>\n",
              "      <td>12.992620</td>\n",
              "      <td>4.582856</td>\n",
              "      <td>35.037532</td>\n",
              "      <td>4.796012</td>\n",
              "      <td>28.083314</td>\n",
              "      <td>0.0</td>\n",
              "      <td>58.362456</td>\n",
              "      <td>18.264692</td>\n",
              "      <td>17.537486</td>\n",
              "      <td>0.896323</td>\n",
              "      <td>1.680000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9</td>\n",
              "      <td>4e3c38f5-14ce-11ea-bce5-f49634744a41</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>34.32</td>\n",
              "      <td>-15.88</td>\n",
              "      <td>0.0</td>\n",
              "      <td>375.119882</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>14.844025</td>\n",
              "      <td>14.552823</td>\n",
              "      <td>12.237766</td>\n",
              "      <td>57.451361</td>\n",
              "      <td>30.127047</td>\n",
              "      <td>30.449468</td>\n",
              "      <td>1.521829</td>\n",
              "      <td>29.389995</td>\n",
              "      <td>32.878318</td>\n",
              "      <td>8.179804</td>\n",
              "      <td>0.963981</td>\n",
              "      <td>16.659097</td>\n",
              "      <td>3.304466</td>\n",
              "      <td>0.0</td>\n",
              "      <td>12.992620</td>\n",
              "      <td>4.582856</td>\n",
              "      <td>35.037532</td>\n",
              "      <td>4.796012</td>\n",
              "      <td>28.083314</td>\n",
              "      <td>0.0</td>\n",
              "      <td>58.362456</td>\n",
              "      <td>18.264692</td>\n",
              "      <td>17.537486</td>\n",
              "      <td>0.896323</td>\n",
              "      <td>1.680000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9</td>\n",
              "      <td>4e3c38f6-14ce-11ea-bce5-f49634744a41</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>34.32</td>\n",
              "      <td>-15.87</td>\n",
              "      <td>0.0</td>\n",
              "      <td>380.654085</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>14.844025</td>\n",
              "      <td>14.552823</td>\n",
              "      <td>12.237766</td>\n",
              "      <td>57.451361</td>\n",
              "      <td>30.127047</td>\n",
              "      <td>30.449468</td>\n",
              "      <td>1.521829</td>\n",
              "      <td>29.389995</td>\n",
              "      <td>32.878318</td>\n",
              "      <td>8.179804</td>\n",
              "      <td>0.963981</td>\n",
              "      <td>16.659097</td>\n",
              "      <td>3.304466</td>\n",
              "      <td>0.0</td>\n",
              "      <td>12.992620</td>\n",
              "      <td>4.582856</td>\n",
              "      <td>35.037532</td>\n",
              "      <td>4.796012</td>\n",
              "      <td>28.083314</td>\n",
              "      <td>0.0</td>\n",
              "      <td>58.362456</td>\n",
              "      <td>18.264692</td>\n",
              "      <td>17.537486</td>\n",
              "      <td>0.896323</td>\n",
              "      <td>1.680000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9</td>\n",
              "      <td>4e3c38f7-14ce-11ea-bce5-f49634744a41</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>34.32</td>\n",
              "      <td>-15.86</td>\n",
              "      <td>0.0</td>\n",
              "      <td>365.714453</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>14.844025</td>\n",
              "      <td>14.552823</td>\n",
              "      <td>12.237766</td>\n",
              "      <td>57.451361</td>\n",
              "      <td>30.127047</td>\n",
              "      <td>30.449468</td>\n",
              "      <td>1.521829</td>\n",
              "      <td>29.389995</td>\n",
              "      <td>32.878318</td>\n",
              "      <td>8.179804</td>\n",
              "      <td>0.963981</td>\n",
              "      <td>16.659097</td>\n",
              "      <td>3.304466</td>\n",
              "      <td>0.0</td>\n",
              "      <td>12.992620</td>\n",
              "      <td>4.582856</td>\n",
              "      <td>35.037532</td>\n",
              "      <td>4.796012</td>\n",
              "      <td>28.083314</td>\n",
              "      <td>0.0</td>\n",
              "      <td>58.362456</td>\n",
              "      <td>18.264692</td>\n",
              "      <td>17.537486</td>\n",
              "      <td>0.896323</td>\n",
              "      <td>1.680000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9</td>\n",
              "      <td>4e3c38f8-14ce-11ea-bce5-f49634744a41</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>34.32</td>\n",
              "      <td>-15.85</td>\n",
              "      <td>0.0</td>\n",
              "      <td>329.930179</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>14.844025</td>\n",
              "      <td>14.552823</td>\n",
              "      <td>12.237766</td>\n",
              "      <td>57.451361</td>\n",
              "      <td>30.127047</td>\n",
              "      <td>30.449468</td>\n",
              "      <td>1.521829</td>\n",
              "      <td>29.389995</td>\n",
              "      <td>32.878318</td>\n",
              "      <td>8.179804</td>\n",
              "      <td>0.963981</td>\n",
              "      <td>16.659097</td>\n",
              "      <td>3.304466</td>\n",
              "      <td>0.0</td>\n",
              "      <td>12.992620</td>\n",
              "      <td>4.582856</td>\n",
              "      <td>35.037532</td>\n",
              "      <td>4.796012</td>\n",
              "      <td>28.083314</td>\n",
              "      <td>0.0</td>\n",
              "      <td>58.362456</td>\n",
              "      <td>18.264692</td>\n",
              "      <td>17.537486</td>\n",
              "      <td>0.896323</td>\n",
              "      <td>1.680000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9</td>\n",
              "      <td>4e3c38f9-14ce-11ea-bce5-f49634744a41</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>100</th>\n",
              "      <td>34.32</td>\n",
              "      <td>-15.84</td>\n",
              "      <td>0.0</td>\n",
              "      <td>313.996551</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>14.844025</td>\n",
              "      <td>14.552823</td>\n",
              "      <td>12.237766</td>\n",
              "      <td>57.451361</td>\n",
              "      <td>30.127047</td>\n",
              "      <td>30.449468</td>\n",
              "      <td>1.521829</td>\n",
              "      <td>29.389995</td>\n",
              "      <td>32.878318</td>\n",
              "      <td>8.179804</td>\n",
              "      <td>0.963981</td>\n",
              "      <td>16.659097</td>\n",
              "      <td>3.304466</td>\n",
              "      <td>0.0</td>\n",
              "      <td>12.992620</td>\n",
              "      <td>4.582856</td>\n",
              "      <td>35.037532</td>\n",
              "      <td>4.796012</td>\n",
              "      <td>28.083314</td>\n",
              "      <td>0.0</td>\n",
              "      <td>58.362456</td>\n",
              "      <td>18.264692</td>\n",
              "      <td>17.537486</td>\n",
              "      <td>0.896323</td>\n",
              "      <td>1.680000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9</td>\n",
              "      <td>4e3c38fa-14ce-11ea-bce5-f49634744a41</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>101</th>\n",
              "      <td>34.32</td>\n",
              "      <td>-15.83</td>\n",
              "      <td>0.0</td>\n",
              "      <td>362.465133</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>14.844025</td>\n",
              "      <td>14.552823</td>\n",
              "      <td>12.237766</td>\n",
              "      <td>57.451361</td>\n",
              "      <td>30.127047</td>\n",
              "      <td>30.449468</td>\n",
              "      <td>1.521829</td>\n",
              "      <td>29.389995</td>\n",
              "      <td>32.878318</td>\n",
              "      <td>8.179804</td>\n",
              "      <td>0.963981</td>\n",
              "      <td>16.659097</td>\n",
              "      <td>3.304466</td>\n",
              "      <td>0.0</td>\n",
              "      <td>12.992620</td>\n",
              "      <td>4.582856</td>\n",
              "      <td>35.037532</td>\n",
              "      <td>4.796012</td>\n",
              "      <td>28.083314</td>\n",
              "      <td>0.0</td>\n",
              "      <td>58.362456</td>\n",
              "      <td>18.264692</td>\n",
              "      <td>17.537486</td>\n",
              "      <td>0.896323</td>\n",
              "      <td>1.680000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9</td>\n",
              "      <td>4e3c38fb-14ce-11ea-bce5-f49634744a41</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>102</th>\n",
              "      <td>34.32</td>\n",
              "      <td>-15.82</td>\n",
              "      <td>0.0</td>\n",
              "      <td>534.287129</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>14.844025</td>\n",
              "      <td>14.552823</td>\n",
              "      <td>12.237766</td>\n",
              "      <td>57.451361</td>\n",
              "      <td>30.127047</td>\n",
              "      <td>30.449468</td>\n",
              "      <td>1.521829</td>\n",
              "      <td>29.389995</td>\n",
              "      <td>32.878318</td>\n",
              "      <td>8.179804</td>\n",
              "      <td>0.963981</td>\n",
              "      <td>16.659097</td>\n",
              "      <td>3.304466</td>\n",
              "      <td>0.0</td>\n",
              "      <td>12.992620</td>\n",
              "      <td>4.582856</td>\n",
              "      <td>35.037532</td>\n",
              "      <td>4.796012</td>\n",
              "      <td>28.083314</td>\n",
              "      <td>0.0</td>\n",
              "      <td>58.362456</td>\n",
              "      <td>18.264692</td>\n",
              "      <td>17.537486</td>\n",
              "      <td>0.896323</td>\n",
              "      <td>1.680000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9</td>\n",
              "      <td>4e3c38fc-14ce-11ea-bce5-f49634744a41</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>103</th>\n",
              "      <td>34.32</td>\n",
              "      <td>-15.81</td>\n",
              "      <td>0.0</td>\n",
              "      <td>523.634098</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>14.844025</td>\n",
              "      <td>14.552823</td>\n",
              "      <td>12.237766</td>\n",
              "      <td>57.451361</td>\n",
              "      <td>30.127047</td>\n",
              "      <td>30.449468</td>\n",
              "      <td>1.521829</td>\n",
              "      <td>29.389995</td>\n",
              "      <td>32.878318</td>\n",
              "      <td>8.179804</td>\n",
              "      <td>0.963981</td>\n",
              "      <td>16.659097</td>\n",
              "      <td>3.304466</td>\n",
              "      <td>0.0</td>\n",
              "      <td>12.992620</td>\n",
              "      <td>4.582856</td>\n",
              "      <td>35.037532</td>\n",
              "      <td>4.796012</td>\n",
              "      <td>28.083314</td>\n",
              "      <td>0.0</td>\n",
              "      <td>58.362456</td>\n",
              "      <td>18.264692</td>\n",
              "      <td>17.537486</td>\n",
              "      <td>0.896323</td>\n",
              "      <td>1.680000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9</td>\n",
              "      <td>4e3c38fd-14ce-11ea-bce5-f49634744a41</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>104</th>\n",
              "      <td>34.32</td>\n",
              "      <td>-15.80</td>\n",
              "      <td>0.0</td>\n",
              "      <td>541.624090</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>14.844025</td>\n",
              "      <td>14.552823</td>\n",
              "      <td>12.237766</td>\n",
              "      <td>57.451361</td>\n",
              "      <td>30.127047</td>\n",
              "      <td>30.449468</td>\n",
              "      <td>1.521829</td>\n",
              "      <td>29.389995</td>\n",
              "      <td>32.878318</td>\n",
              "      <td>8.179804</td>\n",
              "      <td>0.963981</td>\n",
              "      <td>16.659097</td>\n",
              "      <td>3.304466</td>\n",
              "      <td>0.0</td>\n",
              "      <td>12.992620</td>\n",
              "      <td>4.582856</td>\n",
              "      <td>35.037532</td>\n",
              "      <td>4.796012</td>\n",
              "      <td>28.083314</td>\n",
              "      <td>0.0</td>\n",
              "      <td>58.362456</td>\n",
              "      <td>18.264692</td>\n",
              "      <td>17.537486</td>\n",
              "      <td>0.896323</td>\n",
              "      <td>1.680000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9</td>\n",
              "      <td>4e3c38fe-14ce-11ea-bce5-f49634744a41</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>105</th>\n",
              "      <td>34.32</td>\n",
              "      <td>-15.79</td>\n",
              "      <td>0.0</td>\n",
              "      <td>550.104063</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>14.844025</td>\n",
              "      <td>14.552823</td>\n",
              "      <td>12.237766</td>\n",
              "      <td>57.451361</td>\n",
              "      <td>30.127047</td>\n",
              "      <td>30.449468</td>\n",
              "      <td>1.521829</td>\n",
              "      <td>29.389995</td>\n",
              "      <td>32.878318</td>\n",
              "      <td>8.179804</td>\n",
              "      <td>0.963981</td>\n",
              "      <td>16.659097</td>\n",
              "      <td>3.304466</td>\n",
              "      <td>0.0</td>\n",
              "      <td>12.992620</td>\n",
              "      <td>4.582856</td>\n",
              "      <td>35.037532</td>\n",
              "      <td>4.796012</td>\n",
              "      <td>28.083314</td>\n",
              "      <td>0.0</td>\n",
              "      <td>58.362456</td>\n",
              "      <td>18.264692</td>\n",
              "      <td>17.537486</td>\n",
              "      <td>0.896323</td>\n",
              "      <td>1.680000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9</td>\n",
              "      <td>4e3c38ff-14ce-11ea-bce5-f49634744a41</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>106</th>\n",
              "      <td>34.32</td>\n",
              "      <td>-15.78</td>\n",
              "      <td>0.0</td>\n",
              "      <td>539.946561</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>14.844025</td>\n",
              "      <td>14.552823</td>\n",
              "      <td>12.237766</td>\n",
              "      <td>57.451361</td>\n",
              "      <td>30.127047</td>\n",
              "      <td>30.449468</td>\n",
              "      <td>1.521829</td>\n",
              "      <td>29.389995</td>\n",
              "      <td>32.878318</td>\n",
              "      <td>8.179804</td>\n",
              "      <td>0.963981</td>\n",
              "      <td>16.659097</td>\n",
              "      <td>3.304466</td>\n",
              "      <td>0.0</td>\n",
              "      <td>12.992620</td>\n",
              "      <td>4.582856</td>\n",
              "      <td>35.037532</td>\n",
              "      <td>4.796012</td>\n",
              "      <td>28.083314</td>\n",
              "      <td>0.0</td>\n",
              "      <td>58.362456</td>\n",
              "      <td>18.264692</td>\n",
              "      <td>17.537486</td>\n",
              "      <td>0.896323</td>\n",
              "      <td>1.680000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9</td>\n",
              "      <td>4e3c3900-14ce-11ea-bce5-f49634744a41</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>107</th>\n",
              "      <td>34.32</td>\n",
              "      <td>-15.77</td>\n",
              "      <td>0.0</td>\n",
              "      <td>561.422831</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>14.844025</td>\n",
              "      <td>14.552823</td>\n",
              "      <td>12.237766</td>\n",
              "      <td>57.451361</td>\n",
              "      <td>30.127047</td>\n",
              "      <td>30.449468</td>\n",
              "      <td>1.521829</td>\n",
              "      <td>29.389995</td>\n",
              "      <td>32.878318</td>\n",
              "      <td>8.179804</td>\n",
              "      <td>0.963981</td>\n",
              "      <td>16.659097</td>\n",
              "      <td>3.304466</td>\n",
              "      <td>0.0</td>\n",
              "      <td>12.992620</td>\n",
              "      <td>4.582856</td>\n",
              "      <td>35.037532</td>\n",
              "      <td>4.796012</td>\n",
              "      <td>28.083314</td>\n",
              "      <td>0.0</td>\n",
              "      <td>58.362456</td>\n",
              "      <td>18.264692</td>\n",
              "      <td>17.537486</td>\n",
              "      <td>0.896323</td>\n",
              "      <td>1.680000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9</td>\n",
              "      <td>4e3c3901-14ce-11ea-bce5-f49634744a41</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>108</th>\n",
              "      <td>34.32</td>\n",
              "      <td>-15.76</td>\n",
              "      <td>0.0</td>\n",
              "      <td>582.475265</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>14.844025</td>\n",
              "      <td>14.552823</td>\n",
              "      <td>12.237766</td>\n",
              "      <td>57.451361</td>\n",
              "      <td>30.127047</td>\n",
              "      <td>30.449468</td>\n",
              "      <td>1.521829</td>\n",
              "      <td>29.389995</td>\n",
              "      <td>32.878318</td>\n",
              "      <td>8.179804</td>\n",
              "      <td>0.963981</td>\n",
              "      <td>16.659097</td>\n",
              "      <td>3.304466</td>\n",
              "      <td>0.0</td>\n",
              "      <td>12.992620</td>\n",
              "      <td>4.582856</td>\n",
              "      <td>35.037532</td>\n",
              "      <td>4.796012</td>\n",
              "      <td>28.083314</td>\n",
              "      <td>0.0</td>\n",
              "      <td>58.362456</td>\n",
              "      <td>18.264692</td>\n",
              "      <td>17.537486</td>\n",
              "      <td>0.896323</td>\n",
              "      <td>1.680000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9</td>\n",
              "      <td>4e3c3902-14ce-11ea-bce5-f49634744a41</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>109</th>\n",
              "      <td>34.32</td>\n",
              "      <td>-15.75</td>\n",
              "      <td>0.0</td>\n",
              "      <td>610.011770</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>13.924272</td>\n",
              "      <td>16.446456</td>\n",
              "      <td>10.552790</td>\n",
              "      <td>58.673079</td>\n",
              "      <td>30.905407</td>\n",
              "      <td>32.755581</td>\n",
              "      <td>1.919791</td>\n",
              "      <td>27.470342</td>\n",
              "      <td>35.689307</td>\n",
              "      <td>8.490202</td>\n",
              "      <td>0.977308</td>\n",
              "      <td>17.263473</td>\n",
              "      <td>3.299306</td>\n",
              "      <td>0.0</td>\n",
              "      <td>13.259441</td>\n",
              "      <td>6.735691</td>\n",
              "      <td>32.524824</td>\n",
              "      <td>5.712793</td>\n",
              "      <td>30.377144</td>\n",
              "      <td>0.0</td>\n",
              "      <td>61.948196</td>\n",
              "      <td>17.130918</td>\n",
              "      <td>18.232313</td>\n",
              "      <td>0.899534</td>\n",
              "      <td>1.885987</td>\n",
              "      <td>1.566974</td>\n",
              "      <td>0.823949</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.787166</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9</td>\n",
              "      <td>4e3c3903-14ce-11ea-bce5-f49634744a41</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         X      Y  ...  LC_Type1_mode                             Square_ID\n",
              "54   34.30 -15.93  ...              9  4e3c38cc-14ce-11ea-bce5-f49634744a41\n",
              "55   34.30 -15.92  ...              9  4e3c38cd-14ce-11ea-bce5-f49634744a41\n",
              "56   34.30 -15.91  ...              9  4e3c38ce-14ce-11ea-bce5-f49634744a41\n",
              "57   34.30 -15.90  ...             10  4e3c38cf-14ce-11ea-bce5-f49634744a41\n",
              "58   34.30 -15.89  ...             10  4e3c38d0-14ce-11ea-bce5-f49634744a41\n",
              "59   34.30 -15.88  ...             10  4e3c38d1-14ce-11ea-bce5-f49634744a41\n",
              "60   34.30 -15.87  ...             10  4e3c38d2-14ce-11ea-bce5-f49634744a41\n",
              "61   34.30 -15.86  ...              9  4e3c38d3-14ce-11ea-bce5-f49634744a41\n",
              "62   34.30 -15.85  ...              9  4e3c38d4-14ce-11ea-bce5-f49634744a41\n",
              "63   34.30 -15.84  ...              9  4e3c38d5-14ce-11ea-bce5-f49634744a41\n",
              "64   34.30 -15.83  ...              9  4e3c38d6-14ce-11ea-bce5-f49634744a41\n",
              "65   34.30 -15.82  ...              9  4e3c38d7-14ce-11ea-bce5-f49634744a41\n",
              "66   34.30 -15.81  ...              9  4e3c38d8-14ce-11ea-bce5-f49634744a41\n",
              "67   34.30 -15.80  ...              9  4e3c38d9-14ce-11ea-bce5-f49634744a41\n",
              "68   34.30 -15.79  ...              9  4e3c38da-14ce-11ea-bce5-f49634744a41\n",
              "69   34.30 -15.78  ...              9  4e3c38db-14ce-11ea-bce5-f49634744a41\n",
              "70   34.30 -15.77  ...              9  4e3c38dc-14ce-11ea-bce5-f49634744a41\n",
              "71   34.31 -15.94  ...             10  4e3c38dd-14ce-11ea-bce5-f49634744a41\n",
              "72   34.31 -15.93  ...             10  4e3c38de-14ce-11ea-bce5-f49634744a41\n",
              "73   34.31 -15.92  ...              9  4e3c38df-14ce-11ea-bce5-f49634744a41\n",
              "74   34.31 -15.91  ...              9  4e3c38e0-14ce-11ea-bce5-f49634744a41\n",
              "75   34.31 -15.90  ...              9  4e3c38e1-14ce-11ea-bce5-f49634744a41\n",
              "76   34.31 -15.89  ...              9  4e3c38e2-14ce-11ea-bce5-f49634744a41\n",
              "77   34.31 -15.88  ...             10  4e3c38e3-14ce-11ea-bce5-f49634744a41\n",
              "78   34.31 -15.87  ...             10  4e3c38e4-14ce-11ea-bce5-f49634744a41\n",
              "79   34.31 -15.86  ...             10  4e3c38e5-14ce-11ea-bce5-f49634744a41\n",
              "80   34.31 -15.85  ...              9  4e3c38e6-14ce-11ea-bce5-f49634744a41\n",
              "81   34.31 -15.84  ...              9  4e3c38e7-14ce-11ea-bce5-f49634744a41\n",
              "82   34.31 -15.83  ...              9  4e3c38e8-14ce-11ea-bce5-f49634744a41\n",
              "83   34.31 -15.82  ...              9  4e3c38e9-14ce-11ea-bce5-f49634744a41\n",
              "84   34.31 -15.81  ...              9  4e3c38ea-14ce-11ea-bce5-f49634744a41\n",
              "85   34.31 -15.80  ...              9  4e3c38eb-14ce-11ea-bce5-f49634744a41\n",
              "86   34.31 -15.79  ...              8  4e3c38ec-14ce-11ea-bce5-f49634744a41\n",
              "87   34.31 -15.78  ...              8  4e3c38ed-14ce-11ea-bce5-f49634744a41\n",
              "88   34.31 -15.77  ...              9  4e3c38ee-14ce-11ea-bce5-f49634744a41\n",
              "89   34.31 -15.76  ...              9  4e3c38ef-14ce-11ea-bce5-f49634744a41\n",
              "90   34.32 -15.94  ...             10  4e3c38f0-14ce-11ea-bce5-f49634744a41\n",
              "91   34.32 -15.93  ...             10  4e3c38f1-14ce-11ea-bce5-f49634744a41\n",
              "92   34.32 -15.92  ...              9  4e3c38f2-14ce-11ea-bce5-f49634744a41\n",
              "93   34.32 -15.91  ...              9  4e3c38f3-14ce-11ea-bce5-f49634744a41\n",
              "94   34.32 -15.90  ...              9  4e3c38f4-14ce-11ea-bce5-f49634744a41\n",
              "95   34.32 -15.89  ...              9  4e3c38f5-14ce-11ea-bce5-f49634744a41\n",
              "96   34.32 -15.88  ...              9  4e3c38f6-14ce-11ea-bce5-f49634744a41\n",
              "97   34.32 -15.87  ...              9  4e3c38f7-14ce-11ea-bce5-f49634744a41\n",
              "98   34.32 -15.86  ...              9  4e3c38f8-14ce-11ea-bce5-f49634744a41\n",
              "99   34.32 -15.85  ...              9  4e3c38f9-14ce-11ea-bce5-f49634744a41\n",
              "100  34.32 -15.84  ...              9  4e3c38fa-14ce-11ea-bce5-f49634744a41\n",
              "101  34.32 -15.83  ...              9  4e3c38fb-14ce-11ea-bce5-f49634744a41\n",
              "102  34.32 -15.82  ...              9  4e3c38fc-14ce-11ea-bce5-f49634744a41\n",
              "103  34.32 -15.81  ...              9  4e3c38fd-14ce-11ea-bce5-f49634744a41\n",
              "104  34.32 -15.80  ...              9  4e3c38fe-14ce-11ea-bce5-f49634744a41\n",
              "105  34.32 -15.79  ...              9  4e3c38ff-14ce-11ea-bce5-f49634744a41\n",
              "106  34.32 -15.78  ...              9  4e3c3900-14ce-11ea-bce5-f49634744a41\n",
              "107  34.32 -15.77  ...              9  4e3c3901-14ce-11ea-bce5-f49634744a41\n",
              "108  34.32 -15.76  ...              9  4e3c3902-14ce-11ea-bce5-f49634744a41\n",
              "109  34.32 -15.75  ...              9  4e3c3903-14ce-11ea-bce5-f49634744a41\n",
              "\n",
              "[56 rows x 40 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 135
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5LU9YljLgPgG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 699
        },
        "outputId": "658751fa-fcc6-44b4-f32e-dfeb8cb89045"
      },
      "source": [
        "for col in data.columns: \n",
        "    print(col) "
      ],
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X\n",
            "Y\n",
            "target_2015\n",
            "elevation\n",
            "precip 2014-11-16 - 2014-11-23\n",
            "precip 2014-11-23 - 2014-11-30\n",
            "precip 2014-11-30 - 2014-12-07\n",
            "precip 2014-12-07 - 2014-12-14\n",
            "precip 2014-12-14 - 2014-12-21\n",
            "precip 2014-12-21 - 2014-12-28\n",
            "precip 2014-12-28 - 2015-01-04\n",
            "precip 2015-01-04 - 2015-01-11\n",
            "precip 2015-01-11 - 2015-01-18\n",
            "precip 2015-01-18 - 2015-01-25\n",
            "precip 2015-01-25 - 2015-02-01\n",
            "precip 2015-02-01 - 2015-02-08\n",
            "precip 2015-02-08 - 2015-02-15\n",
            "precip 2015-02-15 - 2015-02-22\n",
            "precip 2015-02-22 - 2015-03-01\n",
            "precip 2015-03-01 - 2015-03-08\n",
            "precip 2015-03-08 - 2015-03-15\n",
            "precip 2019-01-20 - 2019-01-27\n",
            "precip 2019-01-27 - 2019-02-03\n",
            "precip 2019-02-03 - 2019-02-10\n",
            "precip 2019-02-10 - 2019-02-17\n",
            "precip 2019-02-17 - 2019-02-24\n",
            "precip 2019-02-24 - 2019-03-03\n",
            "precip 2019-03-03 - 2019-03-10\n",
            "precip 2019-03-10 - 2019-03-17\n",
            "precip 2019-03-17 - 2019-03-24\n",
            "precip 2019-03-24 - 2019-03-31\n",
            "precip 2019-03-31 - 2019-04-07\n",
            "precip 2019-04-07 - 2019-04-14\n",
            "precip 2019-04-14 - 2019-04-21\n",
            "precip 2019-04-21 - 2019-04-28\n",
            "precip 2019-04-28 - 2019-05-05\n",
            "precip 2019-05-05 - 2019-05-12\n",
            "precip 2019-05-12 - 2019-05-19\n",
            "LC_Type1_mode\n",
            "Square_ID\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ejeN2rvAgPgN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q_mQoDqGgPgS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Y_train=data_train.iloc[:, 2]\n",
        "Y_test=data_test.iloc[:, 2]\n",
        "Y_all=data.iloc[:, 2]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nvRlg4FOgPgY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "806d0de6-30ab-440b-bc17-e8f5504f486c"
      },
      "source": [
        "Y_all"
      ],
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0        0.0\n",
              "1        0.0\n",
              "2        0.0\n",
              "3        0.0\n",
              "4        0.0\n",
              "        ... \n",
              "16461    0.0\n",
              "16462    0.0\n",
              "16463    0.0\n",
              "16464    0.0\n",
              "16465    0.0\n",
              "Name: target_2015, Length: 16466, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 119
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6rMVb4XvgPgb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#data.iloc[:, 38:39] \n",
        "#z=data.iloc[:, 38]\n",
        "#X.merge(z, how='outer')\n",
        "#z.to_numpy()\n",
        "#X[\"LC_Type1_mode\"]=z\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZVEf8kwZgPge",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#initialising  training and cross validation datas \n",
        "X_train=data_train.iloc[:, 4:21]\n",
        "X_test=data_test.iloc[:, 4:21]\n",
        "\n",
        "X_train[\"LC_Type1_mode\"]=data_train.iloc[:, 38].to_numpy()\n",
        "X_train[\"X\"]=data_train.iloc[:, 0].to_numpy()\n",
        "X_train[\"Y\"]=data_train.iloc[:, 1].to_numpy()\n",
        "X_train[\"elevation\"]=data_train.iloc[:, 3].to_numpy()\n",
        "\n",
        "X_test[\"LC_Type1_mode\"]=data_test.iloc[:, 38].to_numpy()\n",
        "X_test[\"X\"]=data_test.iloc[:, 0].to_numpy()\n",
        "X_test[\"Y\"]=data_test.iloc[:, 1].to_numpy()\n",
        "X_test[\"elevation\"]=data_test.iloc[:, 3].to_numpy()\n",
        "\n",
        "\n",
        "X_all=data.iloc[:, 4:21]\n",
        "\n",
        "X_all[\"LC_Type1_mode\"]=data.iloc[:, 38].to_numpy()\n",
        "X_all[\"X\"]=data.iloc[:, 0].to_numpy()\n",
        "X_all[\"Y\"]=data.iloc[:, 1].to_numpy()\n",
        "X_all[\"elevation\"]=data.iloc[:, 3].to_numpy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TBYfx66BgPgk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#getting test inputs \n",
        "test2019X=data.iloc[:, 21:38]\n",
        "\n",
        "test2019X[\"LC_Type1_mode\"]=data.iloc[:, 38].to_numpy()\n",
        "test2019X[\"X\"]=data.iloc[:, 0].to_numpy()\n",
        "test2019X[\"Y\"]=data.iloc[:, 1].to_numpy()\n",
        "test2019X[\"elevation\"]=data.iloc[:, 3].to_numpy()\n",
        "#test2019X.head()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LkGwlGCagPgn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        },
        "outputId": "c4b36aef-f316-4c99-d856-ffb110748555"
      },
      "source": [
        "X_all=(X_all.to_numpy())\n",
        "Y_all=(Y_all.to_numpy())\n",
        "\n",
        "X_train=(X_train.to_numpy())\n",
        "Y_train=(Y_train.to_numpy())\n",
        "X_test=X_test.to_numpy()\n",
        "Y_test=Y_test.to_numpy()\n",
        "test2019X=test2019X.to_numpy()\n",
        "\n"
      ],
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-123-f11c13b52d92>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX_all\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_all\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mY_all\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_all\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'to_numpy'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r6eKJhuTgPgq",
        "colab_type": "text"
      },
      "source": [
        "# parmeters with Normalization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wT_bRCIygPgr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def findtheta(X,Y):\n",
        "    inv=np.dot(X.T,X)\n",
        "    inv=np.linalg.inv(inv)\n",
        "    theta=(np.dot(inv,X.T)).dot(Y)\n",
        "    theta=theta.reshape((X.shape[1],1))\n",
        "    return theta"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PSMtNpqXgPgu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lNePYdQHgPgy",
        "colab_type": "text"
      },
      "source": [
        "# loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U7qvVp8ggPgz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def losss(theta,X,Y):\n",
        "    J=0\n",
        "    for i in range(X.shape[0]):\n",
        "        #print(X[i,:])\n",
        "        J+=(np.dot(theta.T,X[i,:].T)-Y[i])*(np.dot(theta.T,X[i,:].T)-Y[i])\n",
        "        J=J\n",
        "    return np.squeeze(J)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LyN3CUalgPg2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 409
        },
        "outputId": "7e85cbfa-0c6a-4d27-a192-57a8835a6bb3"
      },
      "source": [
        "theta=findtheta(X_all,Y_all)\n",
        "print(theta.shape)\n",
        "print(theta)\n",
        "losss(theta,X_test,Y_test)\n"
      ],
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(21, 1)\n",
            "[[-0.0053533 ]\n",
            " [-0.00386435]\n",
            " [ 0.01261638]\n",
            " [-0.01218064]\n",
            " [-0.00444949]\n",
            " [ 0.0057355 ]\n",
            " [-0.00028232]\n",
            " [-0.00027697]\n",
            " [-0.00084371]\n",
            " [ 0.01733098]\n",
            " [ 0.00032992]\n",
            " [ 0.00023717]\n",
            " [-0.00992422]\n",
            " [ 0.01062099]\n",
            " [-0.00474708]\n",
            " [ 0.00241598]\n",
            " [ 0.02308795]\n",
            " [-0.00802166]\n",
            " [ 0.03172881]\n",
            " [ 0.03909021]\n",
            " [-0.00014166]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(205.63177612)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 133
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ulr1qfMigPg6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X7DT2B7NgPg-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j-YTzVOHgPhC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 256
        },
        "outputId": "86f14662-626f-4ad7-e439-81120339c296"
      },
      "source": [
        "compare=pd.DataFrame()\n",
        "def comparer(X_test):\n",
        "    test=np.array([])\n",
        "\n",
        "    for i in range(X_test.shape[0]):\n",
        "        test=np.append(test,np.dot(theta.T,X_test[i,:].T))\n",
        "    return test\n",
        "\n",
        "compare[\"Square_ID\"]=data.iloc[:,39].to_numpy()\n",
        "compare[\"predict\"]=comparer(test2019X)\n",
        "#compare[\"expected\"]=Y_test\n",
        "compare.to_csv('out.csv', index=False)\n",
        "print(compare)"
      ],
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                                  Square_ID   predict\n",
            "0      4e3c3896-14ce-11ea-bce5-f49634744a41  0.418313\n",
            "1      4e3c3897-14ce-11ea-bce5-f49634744a41  0.439154\n",
            "2      4e3c3898-14ce-11ea-bce5-f49634744a41  0.464714\n",
            "3      4e3c3899-14ce-11ea-bce5-f49634744a41  0.474414\n",
            "4      4e3c389a-14ce-11ea-bce5-f49634744a41  0.475647\n",
            "...                                     ...       ...\n",
            "16461  4e6f5dfd-14ce-11ea-bce5-f49634744a41  0.917275\n",
            "16462  4e6f5dfe-14ce-11ea-bce5-f49634744a41  0.918102\n",
            "16463  4e6f5dff-14ce-11ea-bce5-f49634744a41  0.918514\n",
            "16464  4e6f5e00-14ce-11ea-bce5-f49634744a41  0.919355\n",
            "16465  4e6f5e01-14ce-11ea-bce5-f49634744a41  0.920186\n",
            "\n",
            "[16466 rows x 2 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "996_gvE5gPhG",
        "colab_type": "text"
      },
      "source": [
        "# NEURAL NETWORK\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DzPzxTpOgPhK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch import nn\n",
        "import torch\n",
        "from torch import optim\n",
        "\n",
        "X_train=torch.from_numpy(X_train)\n",
        "Y_train=torch.from_numpy(Y_train)\n",
        "X_all=torch.from_numpy(X_all)\n",
        "Y_all=torch.from_numpy(Y_all)\n",
        "X_test=torch.from_numpy(X_test)\n",
        "Y_test=torch.from_numpy(Y_test)\n",
        "test2019X=torch.from_numpy(test2019X)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "Fkofux2FgPhP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net,self).__init__()\n",
        "        \n",
        "\n",
        "        self.hl1=nn.Linear(21,32)\n",
        "        #self.hl2=nn.Linear(32,32)\n",
        "        self.ol=nn.Linear(32,1)\n",
        "        self.relu=nn.ReLU()\n",
        "    def forward(self, x):\n",
        "        h1 =self.hl1(x)\n",
        "        activation1 =self.relu(h1)\n",
        "        \n",
        "        #h2 =self.hl2(activation1)\n",
        "        #activation2 =self.relu(h2)\n",
        "\n",
        "\n",
        "        output=self.ol(activation1)\n",
        "        return output\n",
        "   \n",
        "net=Net()\n",
        "#loss_fn = nn.MSELoss()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ojQwj9xhgPhT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#output = net(X_train.float())\n",
        "#loss_fn = nn.MSELoss()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hZwDzhJDgPhV",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X8T5Py6CgPhW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch import optim\n",
        "# create your optimizer\n",
        "#optimizer = optim.Adam(net.parameters(), lr=1e-2)\n",
        "#optimizer.zero_grad()   # zero the gradient buffers\n",
        "#output = net(input)     # calculate output\n",
        "#loss = loss_fn(output, target) #calculate loss\n",
        "#print(loss)\n",
        "#loss.backward()      # calculate gradient\n",
        "#optimizer.step()     # update parameters\n",
        "#loss = loss_fn(output, target) #calculate loss\n",
        "#print(loss)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D6ZY__vigPhY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def training_loop(n_epochs,optimizer,model,loss_fn,inputs,target):\n",
        "    for epoch in range(1,n_epochs+1):\n",
        "        optimizer.zero_grad()   # zero the gradient buffers\n",
        "        output=net(inputs)\n",
        "        loss=loss_fn(output,target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        if epoch%1==0:\n",
        "            print(\"epoch %d, loss %f\" %(epoch , float(loss)))\n",
        "        if(loss<=1):\n",
        "           #lr = args.lr * (0.1)\n",
        "           for param_group in optimizer.param_groups:\n",
        "              param_group['lr'] = 0.1\n",
        "       \n",
        "        \n",
        "    return net.parameters"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3x1igarbnxoK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WUvH2RaagPhd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def training_while(optimizer,model,loss_fn,inputs,target):\n",
        "    last_loss=10000000000\n",
        "    loss=100000000\n",
        "    epoch=0\n",
        "    while(float(last_loss)>=float(loss)):\n",
        "        last_loss=loss\n",
        "        epoch+=1\n",
        "        optimizer.zero_grad()\n",
        "        output=net(inputs)\n",
        "        loss=loss_fn(output,target)\n",
        "        loss.backward()\n",
        "        if(float(last_loss)>=float(loss)):\n",
        "            optimizer.step()\n",
        "\n",
        "        if epoch%1==0:\n",
        "            print(\"epoch %d, loss %f\" %(epoch , float(loss)))\n",
        "        if(loss<=1):\n",
        "           #lr = args.lr * (0.1)\n",
        "           for param_group in optimizer.param_groups:\n",
        "              param_group['lr'] = 0.001\n",
        "        if(loss<=0.1):\n",
        "           #lr = args.lr * (0.1)\n",
        "           for param_group in optimizer.param_groups:\n",
        "              param_group['lr'] = 0.01\n",
        "    return net.parameters"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Co0fzPoBgPhb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = optim.Adam(net.parameters(), lr=0.001)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SF9Lh-KWn62h",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 480
        },
        "outputId": "01af9ad0-dc9d-4f73-cc0e-cc2a6c370927"
      },
      "source": [
        "training_loop(n_epochs=1000,optimizer=optimizer,model=net,loss_fn=nn.MSELoss(),\n",
        "            inputs=X_train.float(),target=Y_train.float())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/loss.py:431: UserWarning: Using a target size (torch.Size([11526])) that is different to the input size (torch.Size([11526, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch 1, loss 126.284462\n",
            "epoch 2, loss 88.136383\n",
            "epoch 3, loss 57.410625\n",
            "epoch 4, loss 34.044392\n",
            "epoch 5, loss 17.773779\n",
            "epoch 6, loss 8.053456\n",
            "epoch 7, loss 3.996086\n",
            "epoch 8, loss 4.340163\n",
            "epoch 9, loss 7.515652\n",
            "epoch 10, loss 11.858676\n",
            "epoch 11, loss 15.917964\n",
            "epoch 12, loss 18.706253\n",
            "epoch 13, loss 19.776436\n",
            "epoch 14, loss 19.144278\n",
            "epoch 15, loss 17.137499\n",
            "epoch 16, loss 14.243567\n",
            "epoch 17, loss 10.987811\n",
            "epoch 18, loss 7.848645\n",
            "epoch 19, loss 5.200991\n",
            "epoch 20, loss 3.284917\n",
            "epoch 21, loss 2.194240\n",
            "epoch 22, loss 1.884452\n",
            "epoch 23, loss 2.198819\n",
            "epoch 24, loss 2.908412\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5XZqAJ8AgPhg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = optim.Adam(net.parameters(), lr=0.00100000015)\n",
        "loss_fn=nn.MSELoss()\n",
        "training_while(optimizer=optimizer,model=net,loss_fn=nn.MSELoss(),\n",
        "             inputs=X_train.float(),target=Y_train.float())\n",
        "loss=loss_fn(net(X_train.float()),Y_train.float())\n",
        "print(loss)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZgBg_MpXBHeB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss=loss_fn(net(X_test.float()),Y_test.float())\n",
        "print(loss)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bg4stYHcp-rz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "net =Net()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FKxPj0_OqBSs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = optim.Adam(net.parameters(), lr=0.00008)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-q1-GO5spl9u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#training on all\n",
        "training_while(optimizer=optimizer,model=net,loss_fn=nn.MSELoss(),\n",
        "             inputs=X_train.float(),target=Y_train.float())\n",
        "loss=loss_fn(net(X_train.float()),Y_train.float())\n",
        "print(loss)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0-w-9d2-ps0e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#train all\n",
        "training_loop(n_epochs=1000,optimizer=optimizer,model=net,loss_fn=nn.MSELoss(),\n",
        "            inputs=X_train.float(),target=Y_train.float())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eXOAI2BLgPhk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#help(optimizer)\n",
        "#print(optimizer.__getstate__())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lAPgcD5Z0s3f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pd.set_option('display.multi_sparse', True)\n",
        "\n",
        "compare=pd.DataFrame()\n",
        "\n",
        "def comparer(X_test):\n",
        "    test=np.array([])\n",
        "    test=net(X_test.float())\n",
        "    return test\n",
        "Y=comparer(test2019X).detach().numpy()\n",
        "X=np.zeros((Y.shape[0],1))\n",
        "print(Y.shape)\n",
        "for i in range(Y.shape[0]):\n",
        "    #X[i,0]=0 if (Y[i,0]<=0.079) else Y[i,0]\n",
        "    if(Y[i,0]>=1):\n",
        "       X[i,0]=1\n",
        "compare[\"Square_ID\"]=data.iloc[:,39].to_numpy()\n",
        "compare[\"predict\"]=X#comparer(test2019X).detach().numpy()\n",
        "#compare[\"expected\"]=Y_test\n",
        "#compare=pd.DataFrame(X)\n",
        "compare.to_csv('out_nn.csv', index=False)\n",
        "compare.describe(include='all')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cCyYCFmB2EM7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8PwqjA7_w35C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#using anoaly dete"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JLkW_YPxxDGN",
        "colab_type": "text"
      },
      "source": [
        "# Anomaly detection\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tqObBR82GC9t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train=torch.from_numpy(X_train)\n",
        "Y_train=torch.from_numpy(Y_train)\n",
        "X_all=torch.from_numpy(X_all)\n",
        "Y_all=torch.from_numpy(Y_all)\n",
        "X_test=torch.from_numpy(X_test)\n",
        "Y_test=torch.from_numpy(Y_test)\n",
        "test2019X=torch.from_numpy(test2019X)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GIA77HYuxJQn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mean_X=X_train.sum(axis=0)/X_train.shape[0]\n",
        "#print(mean_X)\n",
        "sigma=np.cov(X_train.T)\n",
        "#print(sigma)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y_bGb2lKOGUj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from math import sqrt, pi, exp\n",
        "\n",
        "def loi_normale(x):\n",
        "  y=(1/sqrt(2*pi*np.linalg.det(sigma)))*np.exp(-0.5*np.dot(np.dot((x-mean_X).T,np.linalg.inv(sigma)),(x-mean_X)))\n",
        "  return y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BxUCoW64RYTy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def give_anomalie(X_tes):\n",
        "  X_test=X_tes\n",
        "  X_anomalie=torch.zeros((X_test.shape[0],1))\n",
        "  for i in range(X_test.shape[0]):\n",
        "    X_anomalie[i,0]=loi_normale(X_test[i,:])\n",
        "  X_anomalie.detach().numpy()\n",
        "  x=X_test.detach().numpy()\n",
        "  X_test=np.c_[x,X_anomalie.detach().numpy()]\n",
        "  X_test=torch.from_numpy(X_test)\n",
        "  return X_test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "csyaZ8JJun-R",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "ce98a170-b8a9-4d7e-a230-5eb715f2a9d9"
      },
      "source": [
        "print(X_test.shape)\n",
        "X_test=give_anomalie(X_test)\n",
        "X_train=give_anomalie(X_train)\n",
        "X_all=give_anomalie(X_all)\n",
        "test2019X=give_anomalie(test2019X)\n",
        "\n",
        "print(X_test.shape)"
      ],
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([4940, 21])\n",
            "torch.Size([4940, 22])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uu6ljoC-Vr_k",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 887
        },
        "outputId": "be68954e-ff4f-4847-ff5a-f528ca15df84"
      },
      "source": [
        "com=pd.DataFrame()\n",
        "com[\"target\"]=Y_all\n",
        "com[\"anomalie\"]=X_all[:,21]\n",
        "print(com[350:300])"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "       target      anomalie\n",
            "250  0.000000  6.568316e-13\n",
            "251  0.000000  6.018616e-13\n",
            "252  0.000000  4.774762e-13\n",
            "253  0.000000  4.245823e-15\n",
            "254  0.000000  2.118184e-13\n",
            "255  0.000000  1.659200e-13\n",
            "256  0.013324  1.139683e-12\n",
            "257  0.497974  5.777586e-17\n",
            "258  0.299487  6.202317e-17\n",
            "259  0.000000  5.974397e-17\n",
            "260  0.000000  6.152871e-17\n",
            "261  0.000000  6.410517e-17\n",
            "262  0.000000  5.677451e-17\n",
            "263  0.000000  1.164992e-12\n",
            "264  0.000000  1.231209e-12\n",
            "265  0.000000  1.265936e-12\n",
            "266  0.000000  1.293302e-12\n",
            "267  0.000000  1.340363e-12\n",
            "268  0.000000  1.308557e-12\n",
            "269  0.000000  8.705293e-13\n",
            "270  0.000000  8.987923e-13\n",
            "271  0.000000  8.879399e-13\n",
            "272  0.000000  8.884784e-13\n",
            "273  0.000000  1.182529e-12\n",
            "274  0.000000  1.190151e-12\n",
            "275  0.000000  1.118277e-12\n",
            "276  0.000000  1.128944e-12\n",
            "277  0.000000  1.051103e-12\n",
            "278  0.000000  9.351217e-13\n",
            "279  0.000000  8.550499e-13\n",
            "280  0.000000  7.624238e-13\n",
            "281  0.000000  6.951105e-13\n",
            "282  0.000000  5.725604e-13\n",
            "283  0.000000  5.003383e-13\n",
            "284  0.000000  4.724131e-13\n",
            "285  0.000000  3.510687e-13\n",
            "286  0.384718  3.115010e-13\n",
            "287  0.928526  2.692036e-13\n",
            "288  0.796779  1.205176e-12\n",
            "289  0.342849  7.102707e-17\n",
            "290  0.000000  6.864168e-17\n",
            "291  0.000000  5.993832e-17\n",
            "292  0.000000  5.469920e-17\n",
            "293  0.000000  5.094577e-17\n",
            "294  0.000000  7.209942e-17\n",
            "295  0.000000  6.351964e-17\n",
            "296  0.000000  5.622249e-17\n",
            "297  0.000000  1.122969e-12\n",
            "298  0.000000  1.216040e-12\n",
            "299  0.000000  1.236928e-12\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MUJnBI8UZaiY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net,self).__init__()\n",
        "        self.hl1=nn.Linear(22,32)\n",
        "        #self.hl2=nn.Linear(32,32)\n",
        "        self.ol=nn.Linear(32,1)\n",
        "        self.relu=nn.ReLU()\n",
        "    def forward(self, x):\n",
        "        h1 =self.hl1(x)\n",
        "        activation1 =self.relu(h1)\n",
        "        \n",
        "        #h2 =self.hl2(activation1)\n",
        "        #activation2 =self.relu(h2)\n",
        "\n",
        "\n",
        "        output=self.ol(activation1)\n",
        "        return output\n",
        "   \n",
        "net=Net()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m-gRJizaajB2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch import optim\n",
        "net=Net()\n",
        "optimizer= optim.Adam(net.parameters(), lr=0.008)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JQupVBVZadzA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "344dbf20-f8ba-48d0-9d7a-cf8ecc45555a"
      },
      "source": [
        "training_loop(n_epochs=1000,optimizer=optimizer,model=net,loss_fn=nn.MSELoss(),\n",
        "            inputs=X_train.float(),target=Y_train.float())"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/loss.py:431: UserWarning: Using a target size (torch.Size([11526])) that is different to the input size (torch.Size([11526, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch 1, loss 2250.619385\n",
            "epoch 2, loss 855.230286\n",
            "epoch 3, loss 157.720657\n",
            "epoch 4, loss 12.592723\n",
            "epoch 5, loss 179.900299\n",
            "epoch 6, loss 394.042450\n",
            "epoch 7, loss 498.578735\n",
            "epoch 8, loss 473.247009\n",
            "epoch 9, loss 365.076141\n",
            "epoch 10, loss 229.674332\n",
            "epoch 11, loss 110.568428\n",
            "epoch 12, loss 32.735840\n",
            "epoch 13, loss 3.317218\n",
            "epoch 14, loss 14.744899\n",
            "epoch 15, loss 50.397961\n",
            "epoch 16, loss 91.145103\n",
            "epoch 17, loss 121.363998\n",
            "epoch 18, loss 132.413254\n",
            "epoch 19, loss 123.335381\n",
            "epoch 20, loss 99.138321\n",
            "epoch 21, loss 67.894371\n",
            "epoch 22, loss 37.860523\n",
            "epoch 23, loss 15.335133\n",
            "epoch 24, loss 3.522229\n",
            "epoch 25, loss 2.380061\n",
            "epoch 26, loss 9.264216\n",
            "epoch 27, loss 20.069895\n",
            "epoch 28, loss 30.532457\n",
            "epoch 29, loss 37.342487\n",
            "epoch 30, loss 38.819153\n",
            "epoch 31, loss 35.037460\n",
            "epoch 32, loss 27.474915\n",
            "epoch 33, loss 18.364971\n",
            "epoch 34, loss 9.979436\n",
            "epoch 35, loss 4.033602\n",
            "epoch 36, loss 1.338236\n",
            "epoch 37, loss 1.739442\n",
            "epoch 38, loss 4.315837\n",
            "epoch 39, loss 7.745858\n",
            "epoch 40, loss 10.725363\n",
            "epoch 41, loss 12.316914\n",
            "epoch 42, loss 12.144650\n",
            "epoch 43, loss 10.403296\n",
            "epoch 44, loss 7.707010\n",
            "epoch 45, loss 4.845987\n",
            "epoch 46, loss 2.534011\n",
            "epoch 47, loss 1.218930\n",
            "epoch 48, loss 0.998841\n",
            "epoch 49, loss 1.650787\n",
            "epoch 50, loss 50.879700\n",
            "epoch 51, loss 35.163242\n",
            "epoch 52, loss 0.979108\n",
            "epoch 53, loss 33.120441\n",
            "epoch 54, loss 27.953243\n",
            "epoch 55, loss 0.731966\n",
            "epoch 56, loss 17.219719\n",
            "epoch 57, loss 23.804045\n",
            "epoch 58, loss 3.751135\n",
            "epoch 59, loss 4.909936\n",
            "epoch 60, loss 16.914623\n",
            "epoch 61, loss 8.974580\n",
            "epoch 62, loss 0.247024\n",
            "epoch 63, loss 6.876846\n",
            "epoch 64, loss 10.505247\n",
            "epoch 65, loss 3.409116\n",
            "epoch 66, loss 0.435662\n",
            "epoch 67, loss 5.211331\n",
            "epoch 68, loss 6.347034\n",
            "epoch 69, loss 1.867356\n",
            "epoch 70, loss 0.361471\n",
            "epoch 71, loss 3.238729\n",
            "epoch 72, loss 4.116491\n",
            "epoch 73, loss 1.529517\n",
            "epoch 74, loss 0.181347\n",
            "epoch 75, loss 1.716622\n",
            "epoch 76, loss 2.732757\n",
            "epoch 77, loss 1.439302\n",
            "epoch 78, loss 0.176433\n",
            "epoch 79, loss 0.748250\n",
            "epoch 80, loss 1.698029\n",
            "epoch 81, loss 1.307552\n",
            "epoch 82, loss 0.318635\n",
            "epoch 83, loss 0.259363\n",
            "epoch 84, loss 0.927190\n",
            "epoch 85, loss 1.055773\n",
            "epoch 86, loss 0.468400\n",
            "epoch 87, loss 0.124284\n",
            "epoch 88, loss 0.428645\n",
            "epoch 89, loss 0.732208\n",
            "epoch 90, loss 0.521374\n",
            "epoch 91, loss 0.164471\n",
            "epoch 92, loss 0.183728\n",
            "epoch 93, loss 0.438541\n",
            "epoch 94, loss 0.463870\n",
            "epoch 95, loss 0.232803\n",
            "epoch 96, loss 0.113424\n",
            "epoch 97, loss 0.238234\n",
            "epoch 98, loss 0.348712\n",
            "epoch 99, loss 0.258850\n",
            "epoch 100, loss 0.122512\n",
            "epoch 101, loss 0.137177\n",
            "epoch 102, loss 0.236117\n",
            "epoch 103, loss 0.238216\n",
            "epoch 104, loss 0.144876\n",
            "epoch 105, loss 0.104337\n",
            "epoch 106, loss 0.157796\n",
            "epoch 107, loss 0.195738\n",
            "epoch 108, loss 0.153580\n",
            "epoch 109, loss 0.102906\n",
            "epoch 110, loss 0.116161\n",
            "epoch 111, loss 0.154176\n",
            "epoch 112, loss 0.147050\n",
            "epoch 113, loss 0.108578\n",
            "epoch 114, loss 0.099554\n",
            "epoch 115, loss 0.123974\n",
            "epoch 116, loss 0.132942\n",
            "epoch 117, loss 0.111186\n",
            "epoch 118, loss 0.095118\n",
            "epoch 119, loss 0.105812\n",
            "epoch 120, loss 0.118203\n",
            "epoch 121, loss 0.109308\n",
            "epoch 122, loss 0.094614\n",
            "epoch 123, loss 0.096309\n",
            "epoch 124, loss 0.106342\n",
            "epoch 125, loss 0.104831\n",
            "epoch 126, loss 0.094360\n",
            "epoch 127, loss 0.091750\n",
            "epoch 128, loss 0.098090\n",
            "epoch 129, loss 0.099756\n",
            "epoch 130, loss 0.093374\n",
            "epoch 131, loss 0.089522\n",
            "epoch 132, loss 0.092775\n",
            "epoch 133, loss 0.095199\n",
            "epoch 134, loss 0.091753\n",
            "epoch 135, loss 0.088151\n",
            "epoch 136, loss 0.089390\n",
            "epoch 137, loss 0.091505\n",
            "epoch 138, loss 0.089828\n",
            "epoch 139, loss 0.086971\n",
            "epoch 140, loss 0.087107\n",
            "epoch 141, loss 0.088611\n",
            "epoch 142, loss 0.087863\n",
            "epoch 143, loss 0.085770\n",
            "epoch 144, loss 0.085403\n",
            "epoch 145, loss 0.086340\n",
            "epoch 146, loss 0.086019\n",
            "epoch 147, loss 0.084535\n",
            "epoch 148, loss 0.083999\n",
            "epoch 149, loss 0.084512\n",
            "epoch 150, loss 0.084351\n",
            "epoch 151, loss 0.083300\n",
            "epoch 152, loss 0.082755\n",
            "epoch 153, loss 0.082985\n",
            "epoch 154, loss 0.082861\n",
            "epoch 155, loss 0.082097\n",
            "epoch 156, loss 0.081601\n",
            "epoch 157, loss 0.081653\n",
            "epoch 158, loss 0.081517\n",
            "epoch 159, loss 0.080937\n",
            "epoch 160, loss 0.080506\n",
            "epoch 161, loss 0.080450\n",
            "epoch 162, loss 0.080288\n",
            "epoch 163, loss 0.079826\n",
            "epoch 164, loss 0.079454\n",
            "epoch 165, loss 0.079335\n",
            "epoch 166, loss 0.079150\n",
            "epoch 167, loss 0.078765\n",
            "epoch 168, loss 0.078441\n",
            "epoch 169, loss 0.078287\n",
            "epoch 170, loss 0.078086\n",
            "epoch 171, loss 0.077754\n",
            "epoch 172, loss 0.077468\n",
            "epoch 173, loss 0.077294\n",
            "epoch 174, loss 0.077084\n",
            "epoch 175, loss 0.076788\n",
            "epoch 176, loss 0.076532\n",
            "epoch 177, loss 0.076349\n",
            "epoch 178, loss 0.076134\n",
            "epoch 179, loss 0.075867\n",
            "epoch 180, loss 0.075633\n",
            "epoch 181, loss 0.075444\n",
            "epoch 182, loss 0.075230\n",
            "epoch 183, loss 0.074985\n",
            "epoch 184, loss 0.074768\n",
            "epoch 185, loss 0.074578\n",
            "epoch 186, loss 0.074367\n",
            "epoch 187, loss 0.074140\n",
            "epoch 188, loss 0.073936\n",
            "epoch 189, loss 0.073747\n",
            "epoch 190, loss 0.073542\n",
            "epoch 191, loss 0.073330\n",
            "epoch 192, loss 0.073136\n",
            "epoch 193, loss 0.072949\n",
            "epoch 194, loss 0.072751\n",
            "epoch 195, loss 0.072553\n",
            "epoch 196, loss 0.072367\n",
            "epoch 197, loss 0.072184\n",
            "epoch 198, loss 0.071994\n",
            "epoch 199, loss 0.071807\n",
            "epoch 200, loss 0.071629\n",
            "epoch 201, loss 0.071451\n",
            "epoch 202, loss 0.071269\n",
            "epoch 203, loss 0.071091\n",
            "epoch 204, loss 0.070919\n",
            "epoch 205, loss 0.070746\n",
            "epoch 206, loss 0.070572\n",
            "epoch 207, loss 0.070402\n",
            "epoch 208, loss 0.070236\n",
            "epoch 209, loss 0.070069\n",
            "epoch 210, loss 0.069903\n",
            "epoch 211, loss 0.069741\n",
            "epoch 212, loss 0.069580\n",
            "epoch 213, loss 0.069419\n",
            "epoch 214, loss 0.069260\n",
            "epoch 215, loss 0.069104\n",
            "epoch 216, loss 0.068950\n",
            "epoch 217, loss 0.068795\n",
            "epoch 218, loss 0.068643\n",
            "epoch 219, loss 0.068493\n",
            "epoch 220, loss 0.068344\n",
            "epoch 221, loss 0.068196\n",
            "epoch 222, loss 0.068049\n",
            "epoch 223, loss 0.067905\n",
            "epoch 224, loss 0.067762\n",
            "epoch 225, loss 0.067620\n",
            "epoch 226, loss 0.067479\n",
            "epoch 227, loss 0.067340\n",
            "epoch 228, loss 0.067203\n",
            "epoch 229, loss 0.067066\n",
            "epoch 230, loss 0.066931\n",
            "epoch 231, loss 0.066798\n",
            "epoch 232, loss 0.066665\n",
            "epoch 233, loss 0.066534\n",
            "epoch 234, loss 0.066404\n",
            "epoch 235, loss 0.066276\n",
            "epoch 236, loss 0.066149\n",
            "epoch 237, loss 0.066023\n",
            "epoch 238, loss 0.065898\n",
            "epoch 239, loss 0.065774\n",
            "epoch 240, loss 0.065652\n",
            "epoch 241, loss 0.065531\n",
            "epoch 242, loss 0.065412\n",
            "epoch 243, loss 0.065293\n",
            "epoch 244, loss 0.065176\n",
            "epoch 245, loss 0.065060\n",
            "epoch 246, loss 0.064945\n",
            "epoch 247, loss 0.064831\n",
            "epoch 248, loss 0.064718\n",
            "epoch 249, loss 0.064606\n",
            "epoch 250, loss 0.064496\n",
            "epoch 251, loss 0.064387\n",
            "epoch 252, loss 0.064278\n",
            "epoch 253, loss 0.064171\n",
            "epoch 254, loss 0.064065\n",
            "epoch 255, loss 0.063960\n",
            "epoch 256, loss 0.063856\n",
            "epoch 257, loss 0.063753\n",
            "epoch 258, loss 0.063651\n",
            "epoch 259, loss 0.063550\n",
            "epoch 260, loss 0.063450\n",
            "epoch 261, loss 0.063352\n",
            "epoch 262, loss 0.063254\n",
            "epoch 263, loss 0.063157\n",
            "epoch 264, loss 0.063061\n",
            "epoch 265, loss 0.062966\n",
            "epoch 266, loss 0.062872\n",
            "epoch 267, loss 0.062779\n",
            "epoch 268, loss 0.062687\n",
            "epoch 269, loss 0.062596\n",
            "epoch 270, loss 0.062506\n",
            "epoch 271, loss 0.062417\n",
            "epoch 272, loss 0.062329\n",
            "epoch 273, loss 0.062241\n",
            "epoch 274, loss 0.062155\n",
            "epoch 275, loss 0.062069\n",
            "epoch 276, loss 0.061984\n",
            "epoch 277, loss 0.061900\n",
            "epoch 278, loss 0.061817\n",
            "epoch 279, loss 0.061735\n",
            "epoch 280, loss 0.061654\n",
            "epoch 281, loss 0.061574\n",
            "epoch 282, loss 0.061494\n",
            "epoch 283, loss 0.061415\n",
            "epoch 284, loss 0.061337\n",
            "epoch 285, loss 0.061260\n",
            "epoch 286, loss 0.061184\n",
            "epoch 287, loss 0.061108\n",
            "epoch 288, loss 0.061034\n",
            "epoch 289, loss 0.060960\n",
            "epoch 290, loss 0.060886\n",
            "epoch 291, loss 0.060814\n",
            "epoch 292, loss 0.060742\n",
            "epoch 293, loss 0.060672\n",
            "epoch 294, loss 0.060601\n",
            "epoch 295, loss 0.060532\n",
            "epoch 296, loss 0.060464\n",
            "epoch 297, loss 0.060396\n",
            "epoch 298, loss 0.060329\n",
            "epoch 299, loss 0.060262\n",
            "epoch 300, loss 0.060197\n",
            "epoch 301, loss 0.060132\n",
            "epoch 302, loss 0.060067\n",
            "epoch 303, loss 0.060004\n",
            "epoch 304, loss 0.059941\n",
            "epoch 305, loss 0.059878\n",
            "epoch 306, loss 0.059817\n",
            "epoch 307, loss 0.059756\n",
            "epoch 308, loss 0.059695\n",
            "epoch 309, loss 0.059636\n",
            "epoch 310, loss 0.059576\n",
            "epoch 311, loss 0.059518\n",
            "epoch 312, loss 0.059460\n",
            "epoch 313, loss 0.059403\n",
            "epoch 314, loss 0.059346\n",
            "epoch 315, loss 0.059290\n",
            "epoch 316, loss 0.059235\n",
            "epoch 317, loss 0.059180\n",
            "epoch 318, loss 0.059125\n",
            "epoch 319, loss 0.059072\n",
            "epoch 320, loss 0.059018\n",
            "epoch 321, loss 0.058966\n",
            "epoch 322, loss 0.058914\n",
            "epoch 323, loss 0.058862\n",
            "epoch 324, loss 0.058811\n",
            "epoch 325, loss 0.058760\n",
            "epoch 326, loss 0.058710\n",
            "epoch 327, loss 0.058661\n",
            "epoch 328, loss 0.058612\n",
            "epoch 329, loss 0.058563\n",
            "epoch 330, loss 0.058515\n",
            "epoch 331, loss 0.058468\n",
            "epoch 332, loss 0.058421\n",
            "epoch 333, loss 0.058374\n",
            "epoch 334, loss 0.058328\n",
            "epoch 335, loss 0.058283\n",
            "epoch 336, loss 0.058237\n",
            "epoch 337, loss 0.058193\n",
            "epoch 338, loss 0.058149\n",
            "epoch 339, loss 0.058105\n",
            "epoch 340, loss 0.058061\n",
            "epoch 341, loss 0.058019\n",
            "epoch 342, loss 0.057976\n",
            "epoch 343, loss 0.057934\n",
            "epoch 344, loss 0.057893\n",
            "epoch 345, loss 0.057851\n",
            "epoch 346, loss 0.057811\n",
            "epoch 347, loss 0.057770\n",
            "epoch 348, loss 0.057730\n",
            "epoch 349, loss 0.057691\n",
            "epoch 350, loss 0.057651\n",
            "epoch 351, loss 0.057613\n",
            "epoch 352, loss 0.057574\n",
            "epoch 353, loss 0.057536\n",
            "epoch 354, loss 0.057499\n",
            "epoch 355, loss 0.057461\n",
            "epoch 356, loss 0.057424\n",
            "epoch 357, loss 0.057388\n",
            "epoch 358, loss 0.057352\n",
            "epoch 359, loss 0.057316\n",
            "epoch 360, loss 0.057281\n",
            "epoch 361, loss 0.057246\n",
            "epoch 362, loss 0.057211\n",
            "epoch 363, loss 0.057177\n",
            "epoch 364, loss 0.057143\n",
            "epoch 365, loss 0.057109\n",
            "epoch 366, loss 0.057076\n",
            "epoch 367, loss 0.057043\n",
            "epoch 368, loss 0.057010\n",
            "epoch 369, loss 0.056978\n",
            "epoch 370, loss 0.056946\n",
            "epoch 371, loss 0.056915\n",
            "epoch 372, loss 0.056883\n",
            "epoch 373, loss 0.056852\n",
            "epoch 374, loss 0.056822\n",
            "epoch 375, loss 0.056791\n",
            "epoch 376, loss 0.056761\n",
            "epoch 377, loss 0.056731\n",
            "epoch 378, loss 0.056702\n",
            "epoch 379, loss 0.056673\n",
            "epoch 380, loss 0.056644\n",
            "epoch 381, loss 0.056615\n",
            "epoch 382, loss 0.056587\n",
            "epoch 383, loss 0.056559\n",
            "epoch 384, loss 0.056531\n",
            "epoch 385, loss 0.056503\n",
            "epoch 386, loss 0.056476\n",
            "epoch 387, loss 0.056449\n",
            "epoch 388, loss 0.056422\n",
            "epoch 389, loss 0.056395\n",
            "epoch 390, loss 0.056369\n",
            "epoch 391, loss 0.056343\n",
            "epoch 392, loss 0.056317\n",
            "epoch 393, loss 0.056292\n",
            "epoch 394, loss 0.056267\n",
            "epoch 395, loss 0.056241\n",
            "epoch 396, loss 0.056217\n",
            "epoch 397, loss 0.056192\n",
            "epoch 398, loss 0.056168\n",
            "epoch 399, loss 0.056143\n",
            "epoch 400, loss 0.056119\n",
            "epoch 401, loss 0.056096\n",
            "epoch 402, loss 0.056072\n",
            "epoch 403, loss 0.056049\n",
            "epoch 404, loss 0.056026\n",
            "epoch 405, loss 0.056003\n",
            "epoch 406, loss 0.055980\n",
            "epoch 407, loss 0.055958\n",
            "epoch 408, loss 0.055936\n",
            "epoch 409, loss 0.055914\n",
            "epoch 410, loss 0.055892\n",
            "epoch 411, loss 0.055870\n",
            "epoch 412, loss 0.055849\n",
            "epoch 413, loss 0.055827\n",
            "epoch 414, loss 0.055806\n",
            "epoch 415, loss 0.055785\n",
            "epoch 416, loss 0.055765\n",
            "epoch 417, loss 0.055744\n",
            "epoch 418, loss 0.055724\n",
            "epoch 419, loss 0.055704\n",
            "epoch 420, loss 0.055684\n",
            "epoch 421, loss 0.055664\n",
            "epoch 422, loss 0.055645\n",
            "epoch 423, loss 0.055625\n",
            "epoch 424, loss 0.055606\n",
            "epoch 425, loss 0.055587\n",
            "epoch 426, loss 0.055568\n",
            "epoch 427, loss 0.055549\n",
            "epoch 428, loss 0.055531\n",
            "epoch 429, loss 0.055512\n",
            "epoch 430, loss 0.055494\n",
            "epoch 431, loss 0.055476\n",
            "epoch 432, loss 0.055458\n",
            "epoch 433, loss 0.055440\n",
            "epoch 434, loss 0.055423\n",
            "epoch 435, loss 0.055405\n",
            "epoch 436, loss 0.055388\n",
            "epoch 437, loss 0.055371\n",
            "epoch 438, loss 0.055354\n",
            "epoch 439, loss 0.055337\n",
            "epoch 440, loss 0.055320\n",
            "epoch 441, loss 0.055303\n",
            "epoch 442, loss 0.055287\n",
            "epoch 443, loss 0.055270\n",
            "epoch 444, loss 0.055254\n",
            "epoch 445, loss 0.055238\n",
            "epoch 446, loss 0.055222\n",
            "epoch 447, loss 0.055206\n",
            "epoch 448, loss 0.055190\n",
            "epoch 449, loss 0.055175\n",
            "epoch 450, loss 0.055159\n",
            "epoch 451, loss 0.055144\n",
            "epoch 452, loss 0.055129\n",
            "epoch 453, loss 0.055114\n",
            "epoch 454, loss 0.055099\n",
            "epoch 455, loss 0.055084\n",
            "epoch 456, loss 0.055069\n",
            "epoch 457, loss 0.055054\n",
            "epoch 458, loss 0.055040\n",
            "epoch 459, loss 0.055025\n",
            "epoch 460, loss 0.055011\n",
            "epoch 461, loss 0.054997\n",
            "epoch 462, loss 0.054983\n",
            "epoch 463, loss 0.054969\n",
            "epoch 464, loss 0.054955\n",
            "epoch 465, loss 0.054941\n",
            "epoch 466, loss 0.054927\n",
            "epoch 467, loss 0.054914\n",
            "epoch 468, loss 0.054900\n",
            "epoch 469, loss 0.054887\n",
            "epoch 470, loss 0.054874\n",
            "epoch 471, loss 0.054861\n",
            "epoch 472, loss 0.054847\n",
            "epoch 473, loss 0.054834\n",
            "epoch 474, loss 0.054822\n",
            "epoch 475, loss 0.054809\n",
            "epoch 476, loss 0.054796\n",
            "epoch 477, loss 0.054783\n",
            "epoch 478, loss 0.054771\n",
            "epoch 479, loss 0.054758\n",
            "epoch 480, loss 0.054746\n",
            "epoch 481, loss 0.054734\n",
            "epoch 482, loss 0.054722\n",
            "epoch 483, loss 0.054709\n",
            "epoch 484, loss 0.054697\n",
            "epoch 485, loss 0.054685\n",
            "epoch 486, loss 0.054674\n",
            "epoch 487, loss 0.054662\n",
            "epoch 488, loss 0.054650\n",
            "epoch 489, loss 0.054638\n",
            "epoch 490, loss 0.054627\n",
            "epoch 491, loss 0.054615\n",
            "epoch 492, loss 0.054604\n",
            "epoch 493, loss 0.054593\n",
            "epoch 494, loss 0.054581\n",
            "epoch 495, loss 0.054570\n",
            "epoch 496, loss 0.054559\n",
            "epoch 497, loss 0.054548\n",
            "epoch 498, loss 0.054537\n",
            "epoch 499, loss 0.054526\n",
            "epoch 500, loss 0.054515\n",
            "epoch 501, loss 0.054504\n",
            "epoch 502, loss 0.054494\n",
            "epoch 503, loss 0.054483\n",
            "epoch 504, loss 0.054472\n",
            "epoch 505, loss 0.054462\n",
            "epoch 506, loss 0.054451\n",
            "epoch 507, loss 0.054441\n",
            "epoch 508, loss 0.054431\n",
            "epoch 509, loss 0.054420\n",
            "epoch 510, loss 0.054410\n",
            "epoch 511, loss 0.054400\n",
            "epoch 512, loss 0.054390\n",
            "epoch 513, loss 0.054380\n",
            "epoch 514, loss 0.054370\n",
            "epoch 515, loss 0.054360\n",
            "epoch 516, loss 0.054350\n",
            "epoch 517, loss 0.054341\n",
            "epoch 518, loss 0.054331\n",
            "epoch 519, loss 0.054321\n",
            "epoch 520, loss 0.054312\n",
            "epoch 521, loss 0.054302\n",
            "epoch 522, loss 0.054293\n",
            "epoch 523, loss 0.054283\n",
            "epoch 524, loss 0.054274\n",
            "epoch 525, loss 0.054265\n",
            "epoch 526, loss 0.054256\n",
            "epoch 527, loss 0.054247\n",
            "epoch 528, loss 0.054237\n",
            "epoch 529, loss 0.054228\n",
            "epoch 530, loss 0.054220\n",
            "epoch 531, loss 0.054211\n",
            "epoch 532, loss 0.054202\n",
            "epoch 533, loss 0.054193\n",
            "epoch 534, loss 0.054184\n",
            "epoch 535, loss 0.054176\n",
            "epoch 536, loss 0.054167\n",
            "epoch 537, loss 0.054159\n",
            "epoch 538, loss 0.054150\n",
            "epoch 539, loss 0.054142\n",
            "epoch 540, loss 0.054133\n",
            "epoch 541, loss 0.054125\n",
            "epoch 542, loss 0.054117\n",
            "epoch 543, loss 0.054109\n",
            "epoch 544, loss 0.054101\n",
            "epoch 545, loss 0.054092\n",
            "epoch 546, loss 0.054084\n",
            "epoch 547, loss 0.054076\n",
            "epoch 548, loss 0.054069\n",
            "epoch 549, loss 0.054061\n",
            "epoch 550, loss 0.054053\n",
            "epoch 551, loss 0.054045\n",
            "epoch 552, loss 0.054037\n",
            "epoch 553, loss 0.054030\n",
            "epoch 554, loss 0.054022\n",
            "epoch 555, loss 0.054014\n",
            "epoch 556, loss 0.054007\n",
            "epoch 557, loss 0.053999\n",
            "epoch 558, loss 0.053992\n",
            "epoch 559, loss 0.053984\n",
            "epoch 560, loss 0.053977\n",
            "epoch 561, loss 0.053970\n",
            "epoch 562, loss 0.053962\n",
            "epoch 563, loss 0.053955\n",
            "epoch 564, loss 0.053948\n",
            "epoch 565, loss 0.053941\n",
            "epoch 566, loss 0.053934\n",
            "epoch 567, loss 0.053927\n",
            "epoch 568, loss 0.053920\n",
            "epoch 569, loss 0.053913\n",
            "epoch 570, loss 0.053906\n",
            "epoch 571, loss 0.053899\n",
            "epoch 572, loss 0.053892\n",
            "epoch 573, loss 0.053886\n",
            "epoch 574, loss 0.053879\n",
            "epoch 575, loss 0.053872\n",
            "epoch 576, loss 0.053865\n",
            "epoch 577, loss 0.053859\n",
            "epoch 578, loss 0.053852\n",
            "epoch 579, loss 0.053846\n",
            "epoch 580, loss 0.053839\n",
            "epoch 581, loss 0.053833\n",
            "epoch 582, loss 0.053826\n",
            "epoch 583, loss 0.053820\n",
            "epoch 584, loss 0.053814\n",
            "epoch 585, loss 0.053807\n",
            "epoch 586, loss 0.053801\n",
            "epoch 587, loss 0.053795\n",
            "epoch 588, loss 0.053789\n",
            "epoch 589, loss 0.053782\n",
            "epoch 590, loss 0.053776\n",
            "epoch 591, loss 0.053770\n",
            "epoch 592, loss 0.053764\n",
            "epoch 593, loss 0.053758\n",
            "epoch 594, loss 0.053752\n",
            "epoch 595, loss 0.053746\n",
            "epoch 596, loss 0.053740\n",
            "epoch 597, loss 0.053734\n",
            "epoch 598, loss 0.053728\n",
            "epoch 599, loss 0.053723\n",
            "epoch 600, loss 0.053717\n",
            "epoch 601, loss 0.053711\n",
            "epoch 602, loss 0.053705\n",
            "epoch 603, loss 0.053700\n",
            "epoch 604, loss 0.053694\n",
            "epoch 605, loss 0.053688\n",
            "epoch 606, loss 0.053683\n",
            "epoch 607, loss 0.053677\n",
            "epoch 608, loss 0.053672\n",
            "epoch 609, loss 0.053666\n",
            "epoch 610, loss 0.053661\n",
            "epoch 611, loss 0.053656\n",
            "epoch 612, loss 0.053650\n",
            "epoch 613, loss 0.053645\n",
            "epoch 614, loss 0.053639\n",
            "epoch 615, loss 0.053634\n",
            "epoch 616, loss 0.053629\n",
            "epoch 617, loss 0.053624\n",
            "epoch 618, loss 0.053619\n",
            "epoch 619, loss 0.053613\n",
            "epoch 620, loss 0.053608\n",
            "epoch 621, loss 0.053603\n",
            "epoch 622, loss 0.053598\n",
            "epoch 623, loss 0.053593\n",
            "epoch 624, loss 0.053588\n",
            "epoch 625, loss 0.053583\n",
            "epoch 626, loss 0.053578\n",
            "epoch 627, loss 0.053573\n",
            "epoch 628, loss 0.053568\n",
            "epoch 629, loss 0.053563\n",
            "epoch 630, loss 0.053559\n",
            "epoch 631, loss 0.053554\n",
            "epoch 632, loss 0.053549\n",
            "epoch 633, loss 0.053544\n",
            "epoch 634, loss 0.053540\n",
            "epoch 635, loss 0.053535\n",
            "epoch 636, loss 0.053530\n",
            "epoch 637, loss 0.053526\n",
            "epoch 638, loss 0.053521\n",
            "epoch 639, loss 0.053516\n",
            "epoch 640, loss 0.053512\n",
            "epoch 641, loss 0.053507\n",
            "epoch 642, loss 0.053503\n",
            "epoch 643, loss 0.053498\n",
            "epoch 644, loss 0.053494\n",
            "epoch 645, loss 0.053489\n",
            "epoch 646, loss 0.053485\n",
            "epoch 647, loss 0.053481\n",
            "epoch 648, loss 0.053476\n",
            "epoch 649, loss 0.053472\n",
            "epoch 650, loss 0.053467\n",
            "epoch 651, loss 0.053463\n",
            "epoch 652, loss 0.053459\n",
            "epoch 653, loss 0.053455\n",
            "epoch 654, loss 0.053450\n",
            "epoch 655, loss 0.053446\n",
            "epoch 656, loss 0.053442\n",
            "epoch 657, loss 0.053438\n",
            "epoch 658, loss 0.053434\n",
            "epoch 659, loss 0.053429\n",
            "epoch 660, loss 0.053425\n",
            "epoch 661, loss 0.053421\n",
            "epoch 662, loss 0.053417\n",
            "epoch 663, loss 0.053413\n",
            "epoch 664, loss 0.053409\n",
            "epoch 665, loss 0.053405\n",
            "epoch 666, loss 0.053401\n",
            "epoch 667, loss 0.053397\n",
            "epoch 668, loss 0.053393\n",
            "epoch 669, loss 0.053389\n",
            "epoch 670, loss 0.053385\n",
            "epoch 671, loss 0.053382\n",
            "epoch 672, loss 0.053378\n",
            "epoch 673, loss 0.053374\n",
            "epoch 674, loss 0.053370\n",
            "epoch 675, loss 0.053366\n",
            "epoch 676, loss 0.053362\n",
            "epoch 677, loss 0.053359\n",
            "epoch 678, loss 0.053355\n",
            "epoch 679, loss 0.053351\n",
            "epoch 680, loss 0.053347\n",
            "epoch 681, loss 0.053344\n",
            "epoch 682, loss 0.053340\n",
            "epoch 683, loss 0.053336\n",
            "epoch 684, loss 0.053333\n",
            "epoch 685, loss 0.053329\n",
            "epoch 686, loss 0.053326\n",
            "epoch 687, loss 0.053322\n",
            "epoch 688, loss 0.053318\n",
            "epoch 689, loss 0.053315\n",
            "epoch 690, loss 0.053311\n",
            "epoch 691, loss 0.053308\n",
            "epoch 692, loss 0.053304\n",
            "epoch 693, loss 0.053301\n",
            "epoch 694, loss 0.053298\n",
            "epoch 695, loss 0.053294\n",
            "epoch 696, loss 0.053291\n",
            "epoch 697, loss 0.053287\n",
            "epoch 698, loss 0.053284\n",
            "epoch 699, loss 0.053281\n",
            "epoch 700, loss 0.053277\n",
            "epoch 701, loss 0.053274\n",
            "epoch 702, loss 0.053271\n",
            "epoch 703, loss 0.053267\n",
            "epoch 704, loss 0.053264\n",
            "epoch 705, loss 0.053261\n",
            "epoch 706, loss 0.053258\n",
            "epoch 707, loss 0.053254\n",
            "epoch 708, loss 0.053251\n",
            "epoch 709, loss 0.053248\n",
            "epoch 710, loss 0.053245\n",
            "epoch 711, loss 0.053242\n",
            "epoch 712, loss 0.053239\n",
            "epoch 713, loss 0.053236\n",
            "epoch 714, loss 0.053233\n",
            "epoch 715, loss 0.053230\n",
            "epoch 716, loss 0.053226\n",
            "epoch 717, loss 0.053223\n",
            "epoch 718, loss 0.053220\n",
            "epoch 719, loss 0.053217\n",
            "epoch 720, loss 0.053214\n",
            "epoch 721, loss 0.053211\n",
            "epoch 722, loss 0.053208\n",
            "epoch 723, loss 0.053206\n",
            "epoch 724, loss 0.053203\n",
            "epoch 725, loss 0.053200\n",
            "epoch 726, loss 0.053197\n",
            "epoch 727, loss 0.053194\n",
            "epoch 728, loss 0.053191\n",
            "epoch 729, loss 0.053188\n",
            "epoch 730, loss 0.053185\n",
            "epoch 731, loss 0.053183\n",
            "epoch 732, loss 0.053180\n",
            "epoch 733, loss 0.053177\n",
            "epoch 734, loss 0.053174\n",
            "epoch 735, loss 0.053171\n",
            "epoch 736, loss 0.053169\n",
            "epoch 737, loss 0.053166\n",
            "epoch 738, loss 0.053163\n",
            "epoch 739, loss 0.053160\n",
            "epoch 740, loss 0.053158\n",
            "epoch 741, loss 0.053155\n",
            "epoch 742, loss 0.053152\n",
            "epoch 743, loss 0.053149\n",
            "epoch 744, loss 0.053147\n",
            "epoch 745, loss 0.053144\n",
            "epoch 746, loss 0.053141\n",
            "epoch 747, loss 0.053139\n",
            "epoch 748, loss 0.053136\n",
            "epoch 749, loss 0.053134\n",
            "epoch 750, loss 0.053131\n",
            "epoch 751, loss 0.053128\n",
            "epoch 752, loss 0.053126\n",
            "epoch 753, loss 0.053123\n",
            "epoch 754, loss 0.053121\n",
            "epoch 755, loss 0.053118\n",
            "epoch 756, loss 0.053116\n",
            "epoch 757, loss 0.053113\n",
            "epoch 758, loss 0.053111\n",
            "epoch 759, loss 0.053108\n",
            "epoch 760, loss 0.053105\n",
            "epoch 761, loss 0.053103\n",
            "epoch 762, loss 0.053101\n",
            "epoch 763, loss 0.053098\n",
            "epoch 764, loss 0.053096\n",
            "epoch 765, loss 0.053093\n",
            "epoch 766, loss 0.053091\n",
            "epoch 767, loss 0.053088\n",
            "epoch 768, loss 0.053086\n",
            "epoch 769, loss 0.053084\n",
            "epoch 770, loss 0.053081\n",
            "epoch 771, loss 0.053079\n",
            "epoch 772, loss 0.053076\n",
            "epoch 773, loss 0.053074\n",
            "epoch 774, loss 0.053072\n",
            "epoch 775, loss 0.053069\n",
            "epoch 776, loss 0.053067\n",
            "epoch 777, loss 0.053065\n",
            "epoch 778, loss 0.053063\n",
            "epoch 779, loss 0.053060\n",
            "epoch 780, loss 0.053058\n",
            "epoch 781, loss 0.053056\n",
            "epoch 782, loss 0.053054\n",
            "epoch 783, loss 0.053051\n",
            "epoch 784, loss 0.053049\n",
            "epoch 785, loss 0.053047\n",
            "epoch 786, loss 0.053045\n",
            "epoch 787, loss 0.053043\n",
            "epoch 788, loss 0.053040\n",
            "epoch 789, loss 0.053038\n",
            "epoch 790, loss 0.053036\n",
            "epoch 791, loss 0.053034\n",
            "epoch 792, loss 0.053032\n",
            "epoch 793, loss 0.053030\n",
            "epoch 794, loss 0.053028\n",
            "epoch 795, loss 0.053026\n",
            "epoch 796, loss 0.053024\n",
            "epoch 797, loss 0.053021\n",
            "epoch 798, loss 0.053019\n",
            "epoch 799, loss 0.053017\n",
            "epoch 800, loss 0.053015\n",
            "epoch 801, loss 0.053013\n",
            "epoch 802, loss 0.053011\n",
            "epoch 803, loss 0.053009\n",
            "epoch 804, loss 0.053007\n",
            "epoch 805, loss 0.053005\n",
            "epoch 806, loss 0.053003\n",
            "epoch 807, loss 0.053001\n",
            "epoch 808, loss 0.052999\n",
            "epoch 809, loss 0.052997\n",
            "epoch 810, loss 0.052995\n",
            "epoch 811, loss 0.052994\n",
            "epoch 812, loss 0.052992\n",
            "epoch 813, loss 0.052990\n",
            "epoch 814, loss 0.052988\n",
            "epoch 815, loss 0.052986\n",
            "epoch 816, loss 0.052984\n",
            "epoch 817, loss 0.052982\n",
            "epoch 818, loss 0.052980\n",
            "epoch 819, loss 0.052978\n",
            "epoch 820, loss 0.052977\n",
            "epoch 821, loss 0.052975\n",
            "epoch 822, loss 0.052973\n",
            "epoch 823, loss 0.052971\n",
            "epoch 824, loss 0.052969\n",
            "epoch 825, loss 0.052967\n",
            "epoch 826, loss 0.052966\n",
            "epoch 827, loss 0.052964\n",
            "epoch 828, loss 0.052962\n",
            "epoch 829, loss 0.052960\n",
            "epoch 830, loss 0.052959\n",
            "epoch 831, loss 0.052957\n",
            "epoch 832, loss 0.052955\n",
            "epoch 833, loss 0.052953\n",
            "epoch 834, loss 0.052952\n",
            "epoch 835, loss 0.052950\n",
            "epoch 836, loss 0.052948\n",
            "epoch 837, loss 0.052946\n",
            "epoch 838, loss 0.052945\n",
            "epoch 839, loss 0.052943\n",
            "epoch 840, loss 0.052941\n",
            "epoch 841, loss 0.052940\n",
            "epoch 842, loss 0.052938\n",
            "epoch 843, loss 0.052936\n",
            "epoch 844, loss 0.052935\n",
            "epoch 845, loss 0.052933\n",
            "epoch 846, loss 0.052932\n",
            "epoch 847, loss 0.052930\n",
            "epoch 848, loss 0.052928\n",
            "epoch 849, loss 0.052927\n",
            "epoch 850, loss 0.052925\n",
            "epoch 851, loss 0.052924\n",
            "epoch 852, loss 0.052922\n",
            "epoch 853, loss 0.052920\n",
            "epoch 854, loss 0.052919\n",
            "epoch 855, loss 0.052917\n",
            "epoch 856, loss 0.052916\n",
            "epoch 857, loss 0.052914\n",
            "epoch 858, loss 0.052913\n",
            "epoch 859, loss 0.052911\n",
            "epoch 860, loss 0.052910\n",
            "epoch 861, loss 0.052908\n",
            "epoch 862, loss 0.052907\n",
            "epoch 863, loss 0.052905\n",
            "epoch 864, loss 0.052904\n",
            "epoch 865, loss 0.052902\n",
            "epoch 866, loss 0.052901\n",
            "epoch 867, loss 0.052899\n",
            "epoch 868, loss 0.052898\n",
            "epoch 869, loss 0.052896\n",
            "epoch 870, loss 0.052895\n",
            "epoch 871, loss 0.052894\n",
            "epoch 872, loss 0.052892\n",
            "epoch 873, loss 0.052891\n",
            "epoch 874, loss 0.052889\n",
            "epoch 875, loss 0.052888\n",
            "epoch 876, loss 0.052887\n",
            "epoch 877, loss 0.052885\n",
            "epoch 878, loss 0.052884\n",
            "epoch 879, loss 0.052882\n",
            "epoch 880, loss 0.052881\n",
            "epoch 881, loss 0.052880\n",
            "epoch 882, loss 0.052878\n",
            "epoch 883, loss 0.052877\n",
            "epoch 884, loss 0.052876\n",
            "epoch 885, loss 0.052874\n",
            "epoch 886, loss 0.052873\n",
            "epoch 887, loss 0.052872\n",
            "epoch 888, loss 0.052870\n",
            "epoch 889, loss 0.052869\n",
            "epoch 890, loss 0.052868\n",
            "epoch 891, loss 0.052866\n",
            "epoch 892, loss 0.052865\n",
            "epoch 893, loss 0.052864\n",
            "epoch 894, loss 0.052863\n",
            "epoch 895, loss 0.052861\n",
            "epoch 896, loss 0.052860\n",
            "epoch 897, loss 0.052859\n",
            "epoch 898, loss 0.052858\n",
            "epoch 899, loss 0.052856\n",
            "epoch 900, loss 0.052855\n",
            "epoch 901, loss 0.052854\n",
            "epoch 902, loss 0.052853\n",
            "epoch 903, loss 0.052851\n",
            "epoch 904, loss 0.052850\n",
            "epoch 905, loss 0.052849\n",
            "epoch 906, loss 0.052848\n",
            "epoch 907, loss 0.052846\n",
            "epoch 908, loss 0.052845\n",
            "epoch 909, loss 0.052844\n",
            "epoch 910, loss 0.052843\n",
            "epoch 911, loss 0.052842\n",
            "epoch 912, loss 0.052841\n",
            "epoch 913, loss 0.052839\n",
            "epoch 914, loss 0.052838\n",
            "epoch 915, loss 0.052837\n",
            "epoch 916, loss 0.052836\n",
            "epoch 917, loss 0.052835\n",
            "epoch 918, loss 0.052834\n",
            "epoch 919, loss 0.052832\n",
            "epoch 920, loss 0.052831\n",
            "epoch 921, loss 0.052830\n",
            "epoch 922, loss 0.052829\n",
            "epoch 923, loss 0.052828\n",
            "epoch 924, loss 0.052827\n",
            "epoch 925, loss 0.052826\n",
            "epoch 926, loss 0.052824\n",
            "epoch 927, loss 0.052823\n",
            "epoch 928, loss 0.052822\n",
            "epoch 929, loss 0.052821\n",
            "epoch 930, loss 0.052820\n",
            "epoch 931, loss 0.052819\n",
            "epoch 932, loss 0.052818\n",
            "epoch 933, loss 0.052817\n",
            "epoch 934, loss 0.052816\n",
            "epoch 935, loss 0.052815\n",
            "epoch 936, loss 0.052814\n",
            "epoch 937, loss 0.052813\n",
            "epoch 938, loss 0.052811\n",
            "epoch 939, loss 0.052810\n",
            "epoch 940, loss 0.052809\n",
            "epoch 941, loss 0.052808\n",
            "epoch 942, loss 0.052807\n",
            "epoch 943, loss 0.052806\n",
            "epoch 944, loss 0.052805\n",
            "epoch 945, loss 0.052804\n",
            "epoch 946, loss 0.052803\n",
            "epoch 947, loss 0.052802\n",
            "epoch 948, loss 0.052801\n",
            "epoch 949, loss 0.052800\n",
            "epoch 950, loss 0.052799\n",
            "epoch 951, loss 0.052798\n",
            "epoch 952, loss 0.052797\n",
            "epoch 953, loss 0.052796\n",
            "epoch 954, loss 0.052795\n",
            "epoch 955, loss 0.052794\n",
            "epoch 956, loss 0.052793\n",
            "epoch 957, loss 0.052792\n",
            "epoch 958, loss 0.052791\n",
            "epoch 959, loss 0.052790\n",
            "epoch 960, loss 0.052789\n",
            "epoch 961, loss 0.052788\n",
            "epoch 962, loss 0.052787\n",
            "epoch 963, loss 0.052786\n",
            "epoch 964, loss 0.052785\n",
            "epoch 965, loss 0.052784\n",
            "epoch 966, loss 0.052783\n",
            "epoch 967, loss 0.052782\n",
            "epoch 968, loss 0.052781\n",
            "epoch 969, loss 0.052780\n",
            "epoch 970, loss 0.052779\n",
            "epoch 971, loss 0.052778\n",
            "epoch 972, loss 0.052777\n",
            "epoch 973, loss 0.052777\n",
            "epoch 974, loss 0.052776\n",
            "epoch 975, loss 0.052775\n",
            "epoch 976, loss 0.052774\n",
            "epoch 977, loss 0.052773\n",
            "epoch 978, loss 0.052772\n",
            "epoch 979, loss 0.052771\n",
            "epoch 980, loss 0.052770\n",
            "epoch 981, loss 0.052769\n",
            "epoch 982, loss 0.052768\n",
            "epoch 983, loss 0.052767\n",
            "epoch 984, loss 0.052766\n",
            "epoch 985, loss 0.052765\n",
            "epoch 986, loss 0.052765\n",
            "epoch 987, loss 0.052764\n",
            "epoch 988, loss 0.052763\n",
            "epoch 989, loss 0.052762\n",
            "epoch 990, loss 0.052761\n",
            "epoch 991, loss 0.052760\n",
            "epoch 992, loss 0.052759\n",
            "epoch 993, loss 0.052758\n",
            "epoch 994, loss 0.052757\n",
            "epoch 995, loss 0.052756\n",
            "epoch 996, loss 0.052756\n",
            "epoch 997, loss 0.052755\n",
            "epoch 998, loss 0.052754\n",
            "epoch 999, loss 0.052753\n",
            "epoch 1000, loss 0.052752\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method Module.parameters of Net(\n",
              "  (hl1): Linear(in_features=22, out_features=32, bias=True)\n",
              "  (ol): Linear(in_features=32, out_features=1, bias=True)\n",
              "  (relu): ReLU()\n",
              ")>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3oMfmcLyazKU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "646f1e87-e2ca-4eb9-8fb8-f421e0cd2acb"
      },
      "source": [
        "training_while(optimizer=optimizer,model=net,loss_fn=nn.MSELoss(),\n",
        "             inputs=X_train.float(),target=Y_train.float())\n",
        "loss=nn.MSELoss()(net(X_train.float()),Y_train.float())\n",
        "print(loss)"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/loss.py:431: UserWarning: Using a target size (torch.Size([11526])) that is different to the input size (torch.Size([11526, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch 1, loss 0.052602\n",
            "epoch 2, loss 0.052602\n",
            "epoch 3, loss 0.052602\n",
            "epoch 4, loss 0.052601\n",
            "epoch 5, loss 0.052601\n",
            "epoch 6, loss 0.052601\n",
            "epoch 7, loss 0.052601\n",
            "epoch 8, loss 0.052601\n",
            "epoch 9, loss 0.052601\n",
            "epoch 10, loss 0.052601\n",
            "epoch 11, loss 0.052601\n",
            "epoch 12, loss 0.052601\n",
            "epoch 13, loss 0.052600\n",
            "epoch 14, loss 0.052600\n",
            "epoch 15, loss 0.052600\n",
            "epoch 16, loss 0.052600\n",
            "epoch 17, loss 0.052600\n",
            "epoch 18, loss 0.052600\n",
            "epoch 19, loss 0.052600\n",
            "epoch 20, loss 0.052600\n",
            "epoch 21, loss 0.052600\n",
            "epoch 22, loss 0.052599\n",
            "epoch 23, loss 0.052599\n",
            "epoch 24, loss 0.052599\n",
            "epoch 25, loss 0.052599\n",
            "epoch 26, loss 0.052599\n",
            "epoch 27, loss 0.052599\n",
            "epoch 28, loss 0.052599\n",
            "epoch 29, loss 0.052599\n",
            "epoch 30, loss 0.052599\n",
            "epoch 31, loss 0.052598\n",
            "epoch 32, loss 0.052598\n",
            "epoch 33, loss 0.052598\n",
            "epoch 34, loss 0.052598\n",
            "epoch 35, loss 0.052598\n",
            "epoch 36, loss 0.052598\n",
            "epoch 37, loss 0.052598\n",
            "epoch 38, loss 0.052598\n",
            "epoch 39, loss 0.052598\n",
            "epoch 40, loss 0.052597\n",
            "epoch 41, loss 0.052597\n",
            "epoch 42, loss 0.052597\n",
            "epoch 43, loss 0.052597\n",
            "epoch 44, loss 0.052597\n",
            "epoch 45, loss 0.052597\n",
            "epoch 46, loss 0.052597\n",
            "epoch 47, loss 0.052597\n",
            "epoch 48, loss 0.052597\n",
            "epoch 49, loss 0.052596\n",
            "epoch 50, loss 0.052596\n",
            "epoch 51, loss 0.052596\n",
            "epoch 52, loss 0.052596\n",
            "epoch 53, loss 0.052596\n",
            "epoch 54, loss 0.052596\n",
            "epoch 55, loss 0.052596\n",
            "epoch 56, loss 0.052596\n",
            "epoch 57, loss 0.052596\n",
            "epoch 58, loss 0.052595\n",
            "epoch 59, loss 0.052595\n",
            "epoch 60, loss 0.052595\n",
            "epoch 61, loss 0.052595\n",
            "epoch 62, loss 0.052595\n",
            "epoch 63, loss 0.052595\n",
            "epoch 64, loss 0.052595\n",
            "epoch 65, loss 0.052595\n",
            "epoch 66, loss 0.052595\n",
            "epoch 67, loss 0.052594\n",
            "epoch 68, loss 0.052594\n",
            "epoch 69, loss 0.052594\n",
            "epoch 70, loss 0.052594\n",
            "epoch 71, loss 0.052594\n",
            "epoch 72, loss 0.052594\n",
            "epoch 73, loss 0.052594\n",
            "epoch 74, loss 0.052594\n",
            "epoch 75, loss 0.052594\n",
            "epoch 76, loss 0.052593\n",
            "epoch 77, loss 0.052593\n",
            "epoch 78, loss 0.052593\n",
            "epoch 79, loss 0.052593\n",
            "epoch 80, loss 0.052593\n",
            "epoch 81, loss 0.052593\n",
            "epoch 82, loss 0.052593\n",
            "epoch 83, loss 0.052593\n",
            "epoch 84, loss 0.052593\n",
            "epoch 85, loss 0.052592\n",
            "epoch 86, loss 0.052592\n",
            "epoch 87, loss 0.052592\n",
            "epoch 88, loss 0.052592\n",
            "epoch 89, loss 0.052592\n",
            "epoch 90, loss 0.052592\n",
            "epoch 91, loss 0.052592\n",
            "epoch 92, loss 0.052592\n",
            "epoch 93, loss 0.052592\n",
            "epoch 94, loss 0.052591\n",
            "epoch 95, loss 0.052591\n",
            "epoch 96, loss 0.052591\n",
            "epoch 97, loss 0.052591\n",
            "epoch 98, loss 0.052591\n",
            "epoch 99, loss 0.052591\n",
            "epoch 100, loss 0.052591\n",
            "epoch 101, loss 0.052591\n",
            "epoch 102, loss 0.052591\n",
            "epoch 103, loss 0.052590\n",
            "epoch 104, loss 0.052590\n",
            "epoch 105, loss 0.052590\n",
            "epoch 106, loss 0.052590\n",
            "epoch 107, loss 0.052590\n",
            "epoch 108, loss 0.052590\n",
            "epoch 109, loss 0.052590\n",
            "epoch 110, loss 0.052590\n",
            "epoch 111, loss 0.052590\n",
            "epoch 112, loss 0.052589\n",
            "epoch 113, loss 0.052589\n",
            "epoch 114, loss 0.052589\n",
            "epoch 115, loss 0.052589\n",
            "epoch 116, loss 0.052589\n",
            "epoch 117, loss 0.052589\n",
            "epoch 118, loss 0.052589\n",
            "epoch 119, loss 0.052589\n",
            "epoch 120, loss 0.052589\n",
            "epoch 121, loss 0.052588\n",
            "epoch 122, loss 0.052588\n",
            "epoch 123, loss 0.052588\n",
            "epoch 124, loss 0.052588\n",
            "epoch 125, loss 0.052588\n",
            "epoch 126, loss 0.052588\n",
            "epoch 127, loss 0.052588\n",
            "epoch 128, loss 0.052588\n",
            "epoch 129, loss 0.052588\n",
            "epoch 130, loss 0.052587\n",
            "epoch 131, loss 0.052587\n",
            "epoch 132, loss 0.052587\n",
            "epoch 133, loss 0.052587\n",
            "epoch 134, loss 0.052587\n",
            "epoch 135, loss 0.052587\n",
            "epoch 136, loss 0.052587\n",
            "epoch 137, loss 0.052587\n",
            "epoch 138, loss 0.052587\n",
            "epoch 139, loss 0.052586\n",
            "epoch 140, loss 0.052586\n",
            "epoch 141, loss 0.052586\n",
            "epoch 142, loss 0.052586\n",
            "epoch 143, loss 0.052586\n",
            "epoch 144, loss 0.052586\n",
            "epoch 145, loss 0.052586\n",
            "epoch 146, loss 0.052586\n",
            "epoch 147, loss 0.052586\n",
            "epoch 148, loss 0.052585\n",
            "epoch 149, loss 0.052585\n",
            "epoch 150, loss 0.052585\n",
            "epoch 151, loss 0.052585\n",
            "epoch 152, loss 0.052585\n",
            "epoch 153, loss 0.052585\n",
            "epoch 154, loss 0.052585\n",
            "epoch 155, loss 0.052585\n",
            "epoch 156, loss 0.052585\n",
            "epoch 157, loss 0.052584\n",
            "epoch 158, loss 0.052584\n",
            "epoch 159, loss 0.052584\n",
            "epoch 160, loss 0.052584\n",
            "epoch 161, loss 0.052584\n",
            "epoch 162, loss 0.052584\n",
            "epoch 163, loss 0.052584\n",
            "epoch 164, loss 0.052584\n",
            "epoch 165, loss 0.052584\n",
            "epoch 166, loss 0.052583\n",
            "epoch 167, loss 0.052583\n",
            "epoch 168, loss 0.052583\n",
            "epoch 169, loss 0.052583\n",
            "epoch 170, loss 0.052583\n",
            "epoch 171, loss 0.052583\n",
            "epoch 172, loss 0.052583\n",
            "epoch 173, loss 0.052583\n",
            "epoch 174, loss 0.052583\n",
            "epoch 175, loss 0.052582\n",
            "epoch 176, loss 0.052582\n",
            "epoch 177, loss 0.052582\n",
            "epoch 178, loss 0.052582\n",
            "epoch 179, loss 0.052582\n",
            "epoch 180, loss 0.052582\n",
            "epoch 181, loss 0.052582\n",
            "epoch 182, loss 0.052582\n",
            "epoch 183, loss 0.052582\n",
            "epoch 184, loss 0.052582\n",
            "epoch 185, loss 0.052581\n",
            "epoch 186, loss 0.052581\n",
            "epoch 187, loss 0.052581\n",
            "epoch 188, loss 0.052581\n",
            "epoch 189, loss 0.052581\n",
            "epoch 190, loss 0.052581\n",
            "epoch 191, loss 0.052581\n",
            "epoch 192, loss 0.052581\n",
            "epoch 193, loss 0.052581\n",
            "epoch 194, loss 0.052580\n",
            "epoch 195, loss 0.052580\n",
            "epoch 196, loss 0.052580\n",
            "epoch 197, loss 0.052580\n",
            "epoch 198, loss 0.052580\n",
            "epoch 199, loss 0.052580\n",
            "epoch 200, loss 0.052580\n",
            "epoch 201, loss 0.052580\n",
            "epoch 202, loss 0.052580\n",
            "epoch 203, loss 0.052579\n",
            "epoch 204, loss 0.052579\n",
            "epoch 205, loss 0.052579\n",
            "epoch 206, loss 0.052579\n",
            "epoch 207, loss 0.052579\n",
            "epoch 208, loss 0.052579\n",
            "epoch 209, loss 0.052579\n",
            "epoch 210, loss 0.052579\n",
            "epoch 211, loss 0.052579\n",
            "epoch 212, loss 0.052579\n",
            "epoch 213, loss 0.052578\n",
            "epoch 214, loss 0.052578\n",
            "epoch 215, loss 0.052578\n",
            "epoch 216, loss 0.052578\n",
            "epoch 217, loss 0.052578\n",
            "epoch 218, loss 0.052578\n",
            "epoch 219, loss 0.052578\n",
            "epoch 220, loss 0.052578\n",
            "epoch 221, loss 0.052578\n",
            "epoch 222, loss 0.052577\n",
            "epoch 223, loss 0.052577\n",
            "epoch 224, loss 0.052577\n",
            "epoch 225, loss 0.052577\n",
            "epoch 226, loss 0.052577\n",
            "epoch 227, loss 0.052577\n",
            "epoch 228, loss 0.052577\n",
            "epoch 229, loss 0.052577\n",
            "epoch 230, loss 0.052577\n",
            "epoch 231, loss 0.052576\n",
            "epoch 232, loss 0.052576\n",
            "epoch 233, loss 0.052576\n",
            "epoch 234, loss 0.052576\n",
            "epoch 235, loss 0.052576\n",
            "epoch 236, loss 0.052576\n",
            "epoch 237, loss 0.052576\n",
            "epoch 238, loss 0.052576\n",
            "epoch 239, loss 0.052576\n",
            "epoch 240, loss 0.052576\n",
            "epoch 241, loss 0.052575\n",
            "epoch 242, loss 0.052575\n",
            "epoch 243, loss 0.052575\n",
            "epoch 244, loss 0.052575\n",
            "epoch 245, loss 0.052575\n",
            "epoch 246, loss 0.052575\n",
            "epoch 247, loss 0.052575\n",
            "epoch 248, loss 0.052575\n",
            "epoch 249, loss 0.052575\n",
            "epoch 250, loss 0.052574\n",
            "epoch 251, loss 0.052574\n",
            "epoch 252, loss 0.052574\n",
            "epoch 253, loss 0.052574\n",
            "epoch 254, loss 0.052574\n",
            "epoch 255, loss 0.052574\n",
            "epoch 256, loss 0.052574\n",
            "epoch 257, loss 0.052574\n",
            "epoch 258, loss 0.052574\n",
            "epoch 259, loss 0.052574\n",
            "epoch 260, loss 0.052573\n",
            "epoch 261, loss 0.052573\n",
            "epoch 262, loss 0.052573\n",
            "epoch 263, loss 0.052573\n",
            "epoch 264, loss 0.052573\n",
            "epoch 265, loss 0.052573\n",
            "epoch 266, loss 0.052573\n",
            "epoch 267, loss 0.052573\n",
            "epoch 268, loss 0.052573\n",
            "epoch 269, loss 0.052572\n",
            "epoch 270, loss 0.052572\n",
            "epoch 271, loss 0.052572\n",
            "epoch 272, loss 0.052572\n",
            "epoch 273, loss 0.052572\n",
            "epoch 274, loss 0.052572\n",
            "epoch 275, loss 0.052572\n",
            "epoch 276, loss 0.052572\n",
            "epoch 277, loss 0.052572\n",
            "epoch 278, loss 0.052571\n",
            "epoch 279, loss 0.052571\n",
            "epoch 280, loss 0.052571\n",
            "epoch 281, loss 0.052571\n",
            "epoch 282, loss 0.052571\n",
            "epoch 283, loss 0.052571\n",
            "epoch 284, loss 0.052571\n",
            "epoch 285, loss 0.052571\n",
            "epoch 286, loss 0.052571\n",
            "epoch 287, loss 0.052571\n",
            "epoch 288, loss 0.052570\n",
            "epoch 289, loss 0.052570\n",
            "epoch 290, loss 0.052570\n",
            "epoch 291, loss 0.052570\n",
            "epoch 292, loss 0.052570\n",
            "epoch 293, loss 0.052570\n",
            "epoch 294, loss 0.052570\n",
            "epoch 295, loss 0.052570\n",
            "epoch 296, loss 0.052570\n",
            "epoch 297, loss 0.052569\n",
            "epoch 298, loss 0.052569\n",
            "epoch 299, loss 0.052569\n",
            "epoch 300, loss 0.052569\n",
            "epoch 301, loss 0.052569\n",
            "epoch 302, loss 0.052569\n",
            "epoch 303, loss 0.052569\n",
            "epoch 304, loss 0.052569\n",
            "epoch 305, loss 0.052569\n",
            "epoch 306, loss 0.052568\n",
            "epoch 307, loss 0.052568\n",
            "epoch 308, loss 0.052568\n",
            "epoch 309, loss 0.052568\n",
            "epoch 310, loss 0.052568\n",
            "epoch 311, loss 0.052568\n",
            "epoch 312, loss 0.052568\n",
            "epoch 313, loss 0.052568\n",
            "epoch 314, loss 0.052568\n",
            "epoch 315, loss 0.052568\n",
            "epoch 316, loss 0.052567\n",
            "epoch 317, loss 0.052567\n",
            "epoch 318, loss 0.052567\n",
            "epoch 319, loss 0.052567\n",
            "epoch 320, loss 0.052567\n",
            "epoch 321, loss 0.052567\n",
            "epoch 322, loss 0.052567\n",
            "epoch 323, loss 0.052567\n",
            "epoch 324, loss 0.052567\n",
            "epoch 325, loss 0.052566\n",
            "epoch 326, loss 0.052566\n",
            "epoch 327, loss 0.052566\n",
            "epoch 328, loss 0.052566\n",
            "epoch 329, loss 0.052566\n",
            "epoch 330, loss 0.052566\n",
            "epoch 331, loss 0.052566\n",
            "epoch 332, loss 0.052566\n",
            "epoch 333, loss 0.052566\n",
            "epoch 334, loss 0.052566\n",
            "epoch 335, loss 0.052565\n",
            "epoch 336, loss 0.052565\n",
            "epoch 337, loss 0.052565\n",
            "epoch 338, loss 0.052565\n",
            "epoch 339, loss 0.052565\n",
            "epoch 340, loss 0.052565\n",
            "epoch 341, loss 0.052565\n",
            "epoch 342, loss 0.052565\n",
            "epoch 343, loss 0.052565\n",
            "epoch 344, loss 0.052564\n",
            "epoch 345, loss 0.052564\n",
            "epoch 346, loss 0.052564\n",
            "epoch 347, loss 0.052564\n",
            "epoch 348, loss 0.052564\n",
            "epoch 349, loss 0.052564\n",
            "epoch 350, loss 0.052564\n",
            "epoch 351, loss 0.052564\n",
            "epoch 352, loss 0.052564\n",
            "epoch 353, loss 0.052563\n",
            "epoch 354, loss 0.052563\n",
            "epoch 355, loss 0.052563\n",
            "epoch 356, loss 0.052563\n",
            "epoch 357, loss 0.052563\n",
            "epoch 358, loss 0.052563\n",
            "epoch 359, loss 0.052563\n",
            "epoch 360, loss 0.052563\n",
            "epoch 361, loss 0.052563\n",
            "epoch 362, loss 0.052563\n",
            "epoch 363, loss 0.052562\n",
            "epoch 364, loss 0.052562\n",
            "epoch 365, loss 0.052562\n",
            "epoch 366, loss 0.052562\n",
            "epoch 367, loss 0.052562\n",
            "epoch 368, loss 0.052562\n",
            "epoch 369, loss 0.052562\n",
            "epoch 370, loss 0.052562\n",
            "epoch 371, loss 0.052562\n",
            "epoch 372, loss 0.052561\n",
            "epoch 373, loss 0.052561\n",
            "epoch 374, loss 0.052561\n",
            "epoch 375, loss 0.052561\n",
            "epoch 376, loss 0.052561\n",
            "epoch 377, loss 0.052561\n",
            "epoch 378, loss 0.052561\n",
            "epoch 379, loss 0.052561\n",
            "epoch 380, loss 0.052561\n",
            "epoch 381, loss 0.052561\n",
            "epoch 382, loss 0.052560\n",
            "epoch 383, loss 0.052560\n",
            "epoch 384, loss 0.052560\n",
            "epoch 385, loss 0.052560\n",
            "epoch 386, loss 0.052560\n",
            "epoch 387, loss 0.052560\n",
            "epoch 388, loss 0.052560\n",
            "epoch 389, loss 0.052560\n",
            "epoch 390, loss 0.052560\n",
            "epoch 391, loss 0.052560\n",
            "epoch 392, loss 0.052559\n",
            "epoch 393, loss 0.052559\n",
            "epoch 394, loss 0.052559\n",
            "epoch 395, loss 0.052559\n",
            "epoch 396, loss 0.052559\n",
            "epoch 397, loss 0.052559\n",
            "epoch 398, loss 0.052559\n",
            "epoch 399, loss 0.052559\n",
            "epoch 400, loss 0.052559\n",
            "epoch 401, loss 0.052558\n",
            "epoch 402, loss 0.052558\n",
            "epoch 403, loss 0.052558\n",
            "epoch 404, loss 0.052558\n",
            "epoch 405, loss 0.052558\n",
            "epoch 406, loss 0.052558\n",
            "epoch 407, loss 0.052558\n",
            "epoch 408, loss 0.052558\n",
            "epoch 409, loss 0.052558\n",
            "epoch 410, loss 0.052558\n",
            "epoch 411, loss 0.052557\n",
            "epoch 412, loss 0.052557\n",
            "epoch 413, loss 0.052557\n",
            "epoch 414, loss 0.052557\n",
            "epoch 415, loss 0.052557\n",
            "epoch 416, loss 0.052557\n",
            "epoch 417, loss 0.052557\n",
            "epoch 418, loss 0.052557\n",
            "epoch 419, loss 0.052557\n",
            "epoch 420, loss 0.052556\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-67-9bc4e863650b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m training_while(optimizer=optimizer,model=net,loss_fn=nn.MSELoss(),\n\u001b[0;32m----> 2\u001b[0;31m              inputs=X_train.float(),target=Y_train.float())\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMSELoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-20-f28bf59c6428>\u001b[0m in \u001b[0;36mtraining_while\u001b[0;34m(optimizer, model, loss_fn, inputs, target)\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0moutput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlast_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m>=\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    164\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m         \"\"\"\n\u001b[0;32m--> 166\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QzqpdECZhcMQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8WamM4-na0GE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "be020bfa-21aa-46db-8e68-126111fcff2e"
      },
      "source": [
        "#test error\"\n",
        "loss=nn.MSELoss()(net(X_test.float()),Y_test.float())\n",
        "print(loss)"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(0.0529, grad_fn=<MseLossBackward>)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/loss.py:431: UserWarning: Using a target size (torch.Size([4940])) that is different to the input size (torch.Size([4940, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uXykCQS7a9FM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 393
        },
        "outputId": "69d2ae38-c2ae-423c-9e46-3aebefc887a4"
      },
      "source": [
        "pd.set_option('display.multi_sparse', True)\n",
        "\n",
        "compare=pd.DataFrame()\n",
        "\n",
        "def comparer(X_test):\n",
        "    test=np.array([])\n",
        "    test=net(X_test.float())\n",
        "    return test\n",
        "Y=comparer(test2019X).detach().numpy()\n",
        "X=np.zeros((Y.shape[0],1))\n",
        "print(Y.shape)\n",
        "for i in range(Y.shape[0]):\n",
        "    #X[i,0]=0 if (Y[i,0]<=0.085) else Y[i,0]\n",
        "    if(Y[i,0]>=1):\n",
        "       X[i,0]=1\n",
        "compare[\"Square_ID\"]=data.iloc[:,39].to_numpy()\n",
        "compare[\"predict\"]=X#comparer(test2019X).detach().numpy()\n",
        "#compare[\"expected\"]=Y_test\n",
        "#compare=pd.DataFrame(X)\n",
        "compare.to_csv('out_anomalie_1.csv', index=False)\n",
        "compare.describe(include='all')"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(16466, 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Square_ID</th>\n",
              "      <th>predict</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>16466</td>\n",
              "      <td>16466.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>unique</th>\n",
              "      <td>16466</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>top</th>\n",
              "      <td>4e6a11ea-14ce-11ea-bce5-f49634744a41</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>freq</th>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                   Square_ID  predict\n",
              "count                                  16466  16466.0\n",
              "unique                                 16466      NaN\n",
              "top     4e6a11ea-14ce-11ea-bce5-f49634744a41      NaN\n",
              "freq                                       1      NaN\n",
              "mean                                     NaN      0.0\n",
              "std                                      NaN      0.0\n",
              "min                                      NaN      0.0\n",
              "25%                                      NaN      0.0\n",
              "50%                                      NaN      0.0\n",
              "75%                                      NaN      0.0\n",
              "max                                      NaN      0.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p0LY4QoOkJiq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "36133b05-66c9-43f5-d9dd-721b9cb90cb4"
      },
      "source": [
        "print(optimizer.__getstate__())"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'defaults': {'lr': 0.008, 'betas': (0.9, 0.999), 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}, 'state': defaultdict(<class 'dict'>, {Parameter containing:\n",
            "tensor([[ 8.9006e-02,  1.7240e-01, -7.3862e-04, -2.1073e-01, -1.5405e-01,\n",
            "          9.8008e-02,  3.9343e-03,  1.1310e-01,  1.2040e-01,  4.5003e-03,\n",
            "         -1.9355e-01,  1.5313e-01, -4.2645e-02,  6.4914e-02, -1.8292e-01,\n",
            "         -2.0988e-01,  1.4619e-01, -4.2632e-02,  1.5490e-01, -1.9035e-02,\n",
            "         -1.1998e-02, -1.3924e-01],\n",
            "        [ 6.7260e-02, -1.6979e-01, -1.2456e-01, -2.1266e-01,  3.6660e-04,\n",
            "         -1.9455e-02, -7.4534e-02, -1.9000e-01,  4.7516e-02, -1.8370e-01,\n",
            "          1.0037e-01, -1.3768e-01,  1.5320e-01,  1.1440e-01, -2.1075e-01,\n",
            "         -8.7111e-02,  1.3180e-02, -1.9446e-01, -1.2508e-01, -1.5153e-01,\n",
            "          2.9911e-02,  4.3956e-02],\n",
            "        [-1.0184e-01,  1.4974e-01, -1.7047e-01, -2.4900e-01, -4.9292e-02,\n",
            "         -3.2950e-02, -5.3854e-02,  1.6512e-01,  7.0563e-02,  1.3359e-01,\n",
            "          1.7745e-01, -2.3375e-01, -5.0192e-02,  1.7227e-01,  1.6698e-01,\n",
            "         -1.3140e-01,  5.2424e-02,  1.4290e-01,  9.3561e-02,  1.4412e-01,\n",
            "         -2.4142e-01,  1.6049e-01],\n",
            "        [-5.3129e-02,  3.4726e-03,  1.7949e-01, -2.3262e-01, -1.5055e-01,\n",
            "          1.1489e-01, -4.8788e-02,  7.9745e-02, -8.3752e-02, -2.1942e-01,\n",
            "          3.7560e-02, -2.9393e-02, -1.0127e-01, -7.6493e-03, -1.0051e-01,\n",
            "         -1.1837e-01, -2.0918e-01, -2.1336e-01, -9.1195e-02, -1.0424e-01,\n",
            "         -2.5483e-01, -5.8858e-02],\n",
            "        [ 1.2915e-01, -2.7293e-02,  4.7558e-02, -2.8809e-01, -1.2994e-01,\n",
            "         -6.3608e-02,  1.1536e-02, -4.7024e-02, -1.3857e-01, -5.0848e-02,\n",
            "         -7.8100e-02,  2.7066e-02, -2.7871e-01, -1.6121e-01, -2.5827e-01,\n",
            "         -5.0638e-02, -1.9154e-02, -7.8689e-02,  2.1721e-02,  1.2490e-02,\n",
            "         -4.6773e-02,  2.7905e-02],\n",
            "        [ 3.3692e-02,  1.4122e-01, -1.8523e-01, -2.2190e-01, -7.1197e-02,\n",
            "         -8.4842e-02, -6.2386e-02, -3.2937e-02, -1.4721e-02, -1.4681e-01,\n",
            "          1.0531e-01, -2.7789e-01,  7.6092e-02, -1.5898e-01, -1.8466e-01,\n",
            "         -5.7131e-02, -2.6491e-02, -6.1153e-02,  1.1667e-01,  5.7357e-02,\n",
            "         -2.0657e-01, -1.1141e-01],\n",
            "        [ 1.0324e-01,  7.8766e-02,  7.3278e-02, -6.9036e-02, -1.9020e-01,\n",
            "          1.1867e-01, -1.6583e-03,  1.3939e-01, -1.3910e-01,  5.1952e-02,\n",
            "         -2.5898e-02, -6.4122e-02,  7.9880e-02,  8.2586e-02, -1.2160e-01,\n",
            "         -2.0953e-02, -1.3350e-01,  1.9840e-01,  1.7029e-03, -1.4155e-01,\n",
            "         -1.6158e-01, -7.8760e-02],\n",
            "        [-8.1650e-02,  1.2327e-01, -5.7273e-02, -6.5277e-03, -1.0708e-02,\n",
            "         -1.3710e-01,  3.4603e-02,  5.6534e-02, -2.3290e-01, -1.8005e-01,\n",
            "         -3.9656e-02,  7.5855e-02,  1.6020e-02, -2.3613e-01, -4.6768e-03,\n",
            "         -1.3494e-02,  4.0143e-02, -1.4649e-02,  5.8175e-02, -1.1798e-01,\n",
            "         -1.8038e-01, -1.5506e-01],\n",
            "        [ 1.2957e-01,  6.0548e-02,  7.4940e-02, -1.8516e-02, -2.3897e-01,\n",
            "          3.8975e-02, -2.3043e-01, -2.0318e-01, -4.5861e-02, -2.9243e-01,\n",
            "         -5.8714e-02,  4.0270e-02,  2.9105e-02,  1.4777e-01, -1.4327e-01,\n",
            "         -6.3140e-02,  8.9007e-02, -2.0743e-01, -2.1926e-01,  2.7268e-01,\n",
            "          6.8848e-02,  9.3490e-02],\n",
            "        [-1.7936e-01, -1.1869e-01,  1.4358e-01,  9.5161e-02,  4.5319e-02,\n",
            "         -5.4651e-02, -2.0740e-01, -9.5976e-02,  5.2658e-02, -2.0998e-01,\n",
            "          9.3186e-02, -1.2599e-01,  7.2266e-02, -5.9341e-02, -5.0892e-02,\n",
            "          1.8088e-02,  4.9995e-02, -2.1268e-01, -1.1709e-01,  1.7629e-01,\n",
            "         -1.0939e-01, -8.8717e-02],\n",
            "        [-5.9538e-02,  1.2324e-01,  8.8273e-02,  8.5794e-02,  6.6409e-02,\n",
            "         -2.6214e-01, -2.8398e-01, -1.7363e-02,  4.1362e-02, -7.4297e-02,\n",
            "         -1.9452e-01,  1.0348e-01,  3.7318e-02, -1.6067e-01,  5.7227e-02,\n",
            "          8.6453e-02, -1.4214e-01, -2.8005e-01, -8.1703e-02,  5.5583e-02,\n",
            "         -1.8275e-01,  2.0397e-01],\n",
            "        [-2.5082e-02,  3.4787e-02, -8.3827e-02, -4.9524e-02,  1.7697e-01,\n",
            "         -9.0844e-02,  7.7990e-02,  2.1506e-02, -2.7652e-01,  8.3694e-02,\n",
            "          1.9480e-01,  6.6266e-02,  1.5618e-01, -1.7368e-01,  4.8844e-02,\n",
            "          4.2340e-02, -1.5310e-01,  1.2387e-01, -1.4588e-01, -7.1494e-03,\n",
            "          1.0405e-01,  6.1986e-02],\n",
            "        [-7.8637e-02,  1.9119e-01, -1.0650e-02,  1.2374e-01,  1.1823e-01,\n",
            "         -1.8711e-01, -1.6842e-01,  8.8823e-02, -6.3886e-02, -2.3087e-01,\n",
            "         -1.3772e-01,  1.0137e-01,  8.4369e-02, -1.4828e-01, -9.5749e-03,\n",
            "         -1.0015e-01, -1.4231e-01,  9.9914e-03, -1.2642e-01, -1.2801e-01,\n",
            "         -1.9897e-01, -4.5656e-02],\n",
            "        [ 1.6557e-01,  6.7866e-02, -3.5271e-02,  3.6577e-02, -1.9451e-01,\n",
            "          7.6476e-02,  1.0374e-01, -1.5609e-01,  4.6896e-02, -2.3004e-01,\n",
            "         -5.1200e-02,  1.5286e-01, -2.3629e-01, -6.3102e-02, -8.2445e-02,\n",
            "         -3.8065e-02, -1.5006e-01, -1.8536e-01,  1.3262e-02,  2.3026e-02,\n",
            "          1.1177e-01,  2.0236e-01],\n",
            "        [ 2.0003e-01,  1.7704e-01, -1.3710e-01,  2.4582e-02,  2.5518e-02,\n",
            "         -2.5868e-02, -1.7519e-01,  7.9375e-02, -1.5112e-01, -1.1814e-01,\n",
            "         -2.1881e-03, -1.5617e-02, -1.8498e-01,  1.5888e-01, -6.9953e-02,\n",
            "          1.9284e-01, -1.3973e-01,  4.2696e-02, -1.4620e-01, -1.2566e-01,\n",
            "         -7.1679e-02,  1.0366e-01],\n",
            "        [ 5.5690e-02, -1.2572e-01, -2.4853e-01,  1.1525e-02, -2.2235e-01,\n",
            "         -1.5575e-01, -2.1473e-02, -5.3989e-02, -2.6666e-01, -2.7092e-01,\n",
            "         -2.9847e-01,  8.0389e-02, -2.8547e-01, -2.3792e-01, -8.6329e-02,\n",
            "         -2.2742e-01, -4.8039e-02, -1.2875e-02, -6.3000e-03,  2.3134e-01,\n",
            "          1.9201e-02, -1.5889e-01],\n",
            "        [-1.0535e-01,  1.3129e-01, -6.2635e-02, -1.2161e-01, -2.1695e-02,\n",
            "         -1.8665e-01, -2.3470e-01,  5.0899e-02,  1.7348e-02,  4.4788e-02,\n",
            "          1.3856e-01,  5.5494e-02,  6.6865e-02, -5.0410e-02, -7.3080e-02,\n",
            "         -5.7380e-02, -1.2793e-01,  5.1544e-02, -2.2224e-01,  8.3176e-02,\n",
            "         -1.6024e-01,  1.7178e-01],\n",
            "        [ 1.1238e-01, -1.9893e-02, -1.3277e-01, -1.6570e-01,  2.1302e-01,\n",
            "         -1.1823e-01, -1.3658e-01, -1.8334e-01, -3.9861e-02,  8.9787e-02,\n",
            "          1.3153e-01,  7.5774e-02, -2.0185e-01,  1.1791e-01,  7.0294e-03,\n",
            "         -1.8543e-01, -9.7754e-02, -1.5560e-01,  1.4383e-02, -1.0519e-01,\n",
            "         -2.0545e-01,  8.7432e-02],\n",
            "        [-3.5440e-02,  1.6092e-01, -1.7671e-01, -6.5253e-02, -1.2143e-01,\n",
            "         -2.2218e-01, -5.5109e-02,  1.2215e-01,  7.1414e-02, -2.1712e-01,\n",
            "          5.5828e-02,  1.6644e-01,  7.4404e-02, -1.6748e-01,  1.0327e-01,\n",
            "         -8.4116e-02,  1.7943e-02,  8.5155e-02, -4.1637e-02,  2.2670e-01,\n",
            "          1.3302e-02,  6.5327e-04],\n",
            "        [ 7.3060e-02, -2.1726e-02, -2.8004e-02,  2.8051e-02, -6.4629e-02,\n",
            "         -3.6933e-02,  1.9400e-01, -1.2149e-01, -1.6973e-01,  6.5351e-02,\n",
            "          1.6123e-04, -1.4021e-01, -1.0485e-01, -1.0496e-01, -1.5989e-02,\n",
            "         -1.4995e-02,  1.8234e-01, -7.6295e-02,  1.4113e-01, -9.9309e-02,\n",
            "         -5.9704e-02,  1.7647e-01],\n",
            "        [ 1.8532e-03,  9.8720e-02,  1.8659e-02, -8.5535e-02,  9.3898e-02,\n",
            "          2.3073e-03, -5.2899e-02, -1.5686e-01, -8.1594e-02, -1.9131e-01,\n",
            "          6.3864e-02,  1.3651e-01,  2.5144e-02,  8.2117e-03,  1.8134e-01,\n",
            "         -9.7507e-02, -1.3476e-01, -8.4970e-02, -5.3713e-02,  9.2802e-02,\n",
            "          1.0779e-01,  4.1128e-02],\n",
            "        [-4.8485e-02, -1.2821e-01,  9.1751e-02, -2.5840e-01, -2.4985e-01,\n",
            "         -2.8358e-01, -2.5354e-01,  1.4321e-02, -1.2738e-01, -2.3781e-01,\n",
            "          4.3154e-02, -3.2443e-03, -3.1111e-01, -4.1958e-02, -1.5859e-01,\n",
            "         -2.9473e-01,  9.6869e-02, -2.2698e-01, -3.0675e-01,  6.6761e-02,\n",
            "         -6.2966e-02, -1.4892e-01],\n",
            "        [-2.2934e-02,  4.6730e-02,  1.0096e-01, -1.1321e-01, -2.7499e-01,\n",
            "         -1.4823e-01, -1.4550e-01, -1.6671e-02, -1.5677e-03, -2.4342e-02,\n",
            "         -1.6825e-01,  1.0212e-01,  2.5343e-02, -4.0655e-02,  1.7614e-02,\n",
            "          8.9644e-02, -2.8627e-01,  6.4274e-02, -8.0571e-02,  4.8564e-03,\n",
            "          1.7752e-02, -1.3622e-01],\n",
            "        [-1.0317e-01, -1.4169e-01, -7.9792e-02, -9.6562e-03,  6.0311e-03,\n",
            "          5.8048e-02, -2.1332e-01, -2.9887e-02, -5.1988e-02, -1.4523e-01,\n",
            "          3.4272e-02,  8.3705e-02, -2.1590e-02, -2.3207e-01, -1.4003e-01,\n",
            "         -5.3121e-02, -2.1188e-01,  1.4275e-01,  3.4861e-02, -3.1883e-02,\n",
            "         -6.3537e-02, -3.8595e-02],\n",
            "        [ 5.3968e-02, -2.0882e-01, -1.0388e-01,  9.0632e-02, -6.2769e-02,\n",
            "          1.4259e-01, -5.1977e-02, -1.6128e-01,  1.0428e-02, -6.3955e-02,\n",
            "         -9.3728e-02,  1.0527e-01, -2.0950e-01, -1.0779e-01, -1.2938e-01,\n",
            "          4.6993e-02, -2.4278e-01, -2.0845e-01, -8.5966e-02,  8.3100e-02,\n",
            "          2.8873e-02,  8.2027e-02],\n",
            "        [ 1.7241e-01, -2.0846e-01,  3.7933e-02, -2.3297e-01, -2.3048e-01,\n",
            "         -2.2674e-01, -1.1526e-01, -1.5117e-01,  5.4007e-03, -8.5077e-02,\n",
            "         -1.2590e-01, -1.6052e-01,  1.4849e-01,  7.6535e-02,  6.6378e-02,\n",
            "         -2.5380e-01, -2.0486e-01,  9.0941e-02,  1.2169e-01, -1.2678e-01,\n",
            "         -9.8034e-02, -2.0791e-01],\n",
            "        [ 3.2351e-02,  8.8450e-02, -1.5787e-01,  1.4066e-01, -3.9995e-02,\n",
            "          1.1149e-01,  1.7127e-01,  1.1466e-01, -1.8791e-01,  1.8222e-01,\n",
            "          1.4210e-01, -1.9938e-01, -1.0537e-01,  2.4362e-02, -1.7710e-01,\n",
            "          2.0958e-01, -1.4499e-01, -1.9660e-02,  1.3145e-01,  1.5118e-01,\n",
            "         -1.9652e-01, -8.6015e-02],\n",
            "        [ 1.1492e-01, -1.3243e-01,  6.5916e-02,  1.1481e-02,  1.0126e-01,\n",
            "         -7.2988e-02, -1.5938e-01,  7.0293e-02, -1.1731e-01,  1.7409e-01,\n",
            "         -2.6034e-01,  1.2452e-01, -7.3972e-02,  3.3482e-02, -1.0320e-02,\n",
            "         -2.3060e-01, -1.4440e-02,  7.4103e-02, -1.4251e-02, -6.1448e-02,\n",
            "         -1.4078e-01, -1.9099e-01],\n",
            "        [-3.9840e-03, -1.5695e-02, -4.3495e-02, -2.9343e-02, -5.4481e-02,\n",
            "          1.2443e-01, -2.3870e-01,  5.9997e-02,  1.4634e-01,  1.4642e-01,\n",
            "         -2.4588e-01, -2.8197e-02, -1.8600e-01,  7.3840e-02, -3.0251e-02,\n",
            "          6.9418e-03, -1.3485e-02, -1.9516e-01,  3.7673e-02, -1.3190e-01,\n",
            "         -2.1913e-01, -8.0650e-03],\n",
            "        [ 1.2382e-01, -9.0051e-02, -9.5602e-02,  7.6352e-02, -7.2662e-02,\n",
            "         -8.9230e-02,  1.2873e-01,  1.7558e-02, -7.7953e-02, -3.7710e-02,\n",
            "          9.3275e-02,  1.1896e-01, -5.6176e-02, -1.8207e-01, -9.1769e-02,\n",
            "          8.6835e-02, -8.1731e-02,  6.7510e-03, -6.6379e-02,  2.0538e-02,\n",
            "          8.2764e-02,  7.1990e-02],\n",
            "        [-5.7039e-02, -2.0154e-01,  1.9934e-01, -1.7485e-01,  1.7996e-01,\n",
            "          1.5244e-01,  6.9768e-02, -7.8110e-02, -1.9364e-01, -1.0852e-01,\n",
            "         -1.1483e-01, -2.0203e-01,  2.0158e-01,  5.0899e-02, -1.7721e-02,\n",
            "          5.3331e-02,  1.4912e-01, -3.1553e-02, -3.6944e-02, -1.9786e-01,\n",
            "         -1.4350e-01,  5.7852e-02],\n",
            "        [-3.4058e-01,  8.0465e-02, -2.6906e-01, -5.8237e-02, -3.2209e-01,\n",
            "         -7.9201e-02, -3.0732e-01, -2.5668e-01, -1.2072e-03, -9.9813e-02,\n",
            "          5.3049e-02, -9.0907e-02, -1.7665e-01, -3.3188e-01, -2.4335e-02,\n",
            "         -3.3899e-01, -1.9316e-01,  6.8571e-02, -9.9812e-02,  1.5124e-01,\n",
            "          2.1294e-02,  2.9409e-02]], requires_grad=True): {'step': 1263, 'exp_avg': tensor([[ 1.7564e-05, -1.3915e-06, -2.2168e-05, -4.0459e-05, -1.0320e-04,\n",
            "         -2.6711e-05, -4.3244e-04, -3.3858e-05,  6.5838e-04, -3.0172e-05,\n",
            "         -1.1399e-04,  1.2999e-04, -1.7158e-05,  7.4205e-05,  7.8106e-06,\n",
            "          9.9693e-05,  2.3807e-05, -6.7361e-06,  5.7909e-05, -1.7211e-05,\n",
            "          3.3522e-03, -4.0183e-16],\n",
            "        [-1.6012e-04, -2.5564e-04, -1.4401e-04,  2.0602e-04,  2.2623e-05,\n",
            "          1.9068e-04,  6.2535e-04, -5.2614e-05, -1.8393e-04, -2.9130e-05,\n",
            "         -8.4672e-05,  2.4117e-04,  5.4689e-05, -1.2296e-04, -2.5693e-04,\n",
            "         -1.9771e-04, -5.8575e-05, -1.3968e-04,  1.2078e-04, -6.9675e-05,\n",
            "         -4.3344e-04,  1.7765e-15],\n",
            "        [ 5.6052e-45,  0.0000e+00,  0.0000e+00,  5.6052e-45,  5.6052e-45,\n",
            "          5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45, -5.6052e-45,\n",
            "          5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
            "          5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45, -5.6052e-45,\n",
            "          5.6052e-45,  5.6052e-45],\n",
            "        [ 5.6052e-45,  0.0000e+00,  0.0000e+00,  5.6052e-45,  5.6052e-45,\n",
            "          5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
            "          5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
            "          5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45, -5.6052e-45,\n",
            "          5.6052e-45,  5.6052e-45],\n",
            "        [ 5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
            "          5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
            "          5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
            "          5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45, -5.6052e-45,\n",
            "          5.6052e-45,  5.6052e-45],\n",
            "        [ 5.6052e-45,  0.0000e+00,  0.0000e+00,  5.6052e-45,  5.6052e-45,\n",
            "          5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
            "          5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
            "          5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45, -5.6052e-45,\n",
            "          5.6052e-45,  5.6052e-45],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00],\n",
            "        [ 5.6052e-45,  0.0000e+00,  0.0000e+00,  5.6052e-45,  5.6052e-45,\n",
            "          5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
            "          5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
            "          5.6052e-45,  0.0000e+00,  5.6052e-45,  5.6052e-45, -5.6052e-45,\n",
            "          5.6052e-45,  5.6052e-45],\n",
            "        [ 2.1983e-05, -2.4096e-05, -6.5235e-06, -2.8083e-04,  3.5848e-06,\n",
            "         -1.4783e-04, -4.8772e-04, -2.3165e-06, -1.0613e-04, -1.1827e-05,\n",
            "          1.7967e-05, -2.1441e-04,  3.1628e-05,  1.0675e-04,  2.8913e-04,\n",
            "          1.6590e-04,  2.5319e-05,  5.4933e-05, -1.0314e-04,  6.0864e-05,\n",
            "         -2.3394e-04, -1.5563e-15],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  5.6052e-45,  5.6052e-45,\n",
            "          5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,  0.0000e+00,\n",
            "          5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
            "          5.6052e-45,  0.0000e+00,  5.6052e-45,  5.6052e-45, -5.6052e-45,\n",
            "          5.6052e-45,  5.6052e-45],\n",
            "        [ 5.6052e-45,  0.0000e+00,  0.0000e+00,  5.6052e-45,  5.6052e-45,\n",
            "          5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
            "          5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
            "          5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45, -5.6052e-45,\n",
            "          5.6052e-45,  5.6052e-45],\n",
            "        [-1.0058e-04,  1.0642e-04,  2.8810e-05, -4.4605e-05, -7.5818e-04,\n",
            "         -3.6883e-04, -5.3548e-04, -4.1793e-04, -4.3417e-04,  9.7476e-05,\n",
            "         -1.6925e-03, -1.4780e-03,  2.2307e-04, -3.5411e-04, -1.1086e-03,\n",
            "         -8.5342e-04, -1.3011e-04, -5.0111e-04, -8.7276e-04,  3.8674e-04,\n",
            "         -4.3561e-04,  7.1729e-15],\n",
            "        [ 5.6052e-45,  0.0000e+00,  0.0000e+00,  5.6052e-45,  5.6052e-45,\n",
            "          5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
            "          5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
            "          5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45, -5.6052e-45,\n",
            "          5.6052e-45,  5.6052e-45],\n",
            "        [-1.0157e-04,  1.0747e-04,  2.9096e-05, -1.9463e-04, -3.5553e-04,\n",
            "          3.9288e-04,  2.1611e-04,  9.5395e-05,  2.1686e-03,  1.3131e-04,\n",
            "         -2.8982e-04, -2.4874e-04,  3.9874e-04, -3.7545e-04, -3.3768e-04,\n",
            "         -5.0157e-05, -1.1973e-04, -1.4784e-04,  4.7976e-04, -2.4185e-04,\n",
            "          1.7960e-03,  8.0127e-15],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00],\n",
            "        [-4.8231e-08,  5.6052e-45,  5.6052e-45, -8.9010e-08, -1.5467e-07,\n",
            "         -2.1750e-07, -1.8233e-07, -6.7577e-07, -1.5686e-06, -1.6365e-08,\n",
            "         -9.8213e-07, -5.1704e-07, -2.4612e-07, -1.1768e-07, -3.8270e-07,\n",
            "         -1.1964e-07,  5.6052e-45, -1.9932e-07, -7.0928e-07,  3.1791e-07,\n",
            "         -5.5266e-05, -7.6955e-34],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  5.6052e-45,  5.6052e-45,\n",
            "          5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
            "          5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
            "          5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45, -5.6052e-45,\n",
            "          5.6052e-45,  5.6052e-45],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00],\n",
            "        [-5.4859e-05,  5.8043e-05,  1.5714e-05, -1.1986e-04, -1.9811e-04,\n",
            "          1.9781e-04,  1.0722e-04,  1.0561e-05,  1.1295e-03,  7.0813e-05,\n",
            "         -1.8632e-04, -1.5748e-04,  2.1290e-04, -2.0675e-04, -1.9791e-04,\n",
            "         -3.4253e-05, -6.4666e-05, -9.2619e-05,  2.2493e-04, -1.1458e-04,\n",
            "          9.1983e-04,  4.3244e-15],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00],\n",
            "        [ 8.7425e-05, -9.2514e-05, -2.5046e-05, -7.3584e-04,  2.3174e-04,\n",
            "         -4.6873e-04, -2.2826e-04, -1.6595e-03, -2.5909e-03, -8.7988e-05,\n",
            "         -4.2492e-04, -4.4190e-04, -4.6899e-04,  1.3214e-04,  7.4607e-05,\n",
            "          3.1301e-04,  1.0307e-04, -2.5111e-04, -1.3120e-03,  6.2806e-04,\n",
            "         -3.3962e-03, -7.1099e-15],\n",
            "        [ 5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
            "          5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
            "          5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
            "          5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45, -5.6052e-45,\n",
            "          5.6052e-45,  5.6052e-45],\n",
            "        [-2.4780e-05, -6.7835e-05, -3.4023e-05, -7.0007e-05,  6.3969e-06,\n",
            "         -3.9019e-05, -9.0288e-05,  8.8689e-05,  1.9851e-04, -2.2801e-05,\n",
            "          1.4076e-04,  9.6320e-05,  2.8240e-05,  4.0848e-05,  1.5758e-04,\n",
            "          5.8567e-05,  1.3620e-06,  6.8688e-05,  1.1140e-04, -4.7061e-05,\n",
            "          1.8118e-03, -4.5164e-16],\n",
            "        [ 5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
            "          5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
            "          5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
            "          5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45, -5.6052e-45,\n",
            "          5.6052e-45,  5.6052e-45],\n",
            "        [-1.2489e-04, -1.9508e-04, -1.3951e-04,  3.3281e-04, -1.0987e-04,\n",
            "          2.7826e-04, -1.9241e-05, -2.5867e-04, -2.7318e-04, -4.0920e-05,\n",
            "         -5.2183e-04, -2.0971e-04, -2.4486e-04, -2.3045e-04, -5.9638e-04,\n",
            "         -3.8034e-04, -6.9119e-05, -4.0386e-04, -2.2362e-04,  7.1238e-05,\n",
            "         -3.8652e-03,  2.9597e-15],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  5.6052e-45,  5.6052e-45,\n",
            "          5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
            "          5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
            "          5.6052e-45,  0.0000e+00,  5.6052e-45,  5.6052e-45, -5.6052e-45,\n",
            "          5.6052e-45,  5.6052e-45],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00],\n",
            "        [ 5.6052e-45,  0.0000e+00,  0.0000e+00,  5.6052e-45,  5.6052e-45,\n",
            "          5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,  0.0000e+00,\n",
            "          5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
            "          5.6052e-45,  0.0000e+00,  5.6052e-45,  5.6052e-45, -5.6052e-45,\n",
            "          5.6052e-45,  5.6052e-45],\n",
            "        [ 5.6052e-45,  0.0000e+00,  0.0000e+00,  5.6052e-45,  5.6052e-45,\n",
            "          5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
            "          5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
            "          5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45, -5.6052e-45,\n",
            "          5.6052e-45,  5.6052e-45],\n",
            "        [ 1.6233e-04, -1.7176e-04, -4.6500e-05,  3.5468e-04,  5.8623e-04,\n",
            "         -5.8534e-04, -3.1727e-04, -3.1252e-05, -3.3422e-03, -2.0954e-04,\n",
            "          5.5135e-04,  4.6601e-04, -6.3001e-04,  6.1180e-04,  5.8563e-04,\n",
            "          1.0136e-04,  1.9135e-04,  2.7407e-04, -6.6558e-04,  3.3905e-04,\n",
            "         -2.7219e-03, -1.2796e-14],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00],\n",
            "        [-5.8594e-07, -2.2812e-07,  6.2793e-08, -9.5761e-07, -1.2153e-06,\n",
            "         -3.4944e-06, -4.4405e-06, -5.6511e-06, -2.0047e-05, -3.0410e-07,\n",
            "         -1.0125e-05, -5.1876e-06, -4.1984e-06, -1.8414e-06, -2.5589e-06,\n",
            "         -1.9739e-06,  5.6052e-45,  1.2067e-07, -8.6351e-06,  3.7802e-06,\n",
            "         -2.4445e-04, -4.2164e-20]]), 'exp_avg_sq': tensor([[2.1502e-01, 4.9061e-01, 1.0641e-01, 3.1341e+00, 4.6914e+00, 4.4417e+00,\n",
            "         3.2390e+01, 4.3858e+01, 2.2382e+02, 1.2263e-01, 7.4960e+01, 4.3758e+01,\n",
            "         1.1299e+01, 1.0323e+00, 1.7909e+01, 5.1255e+00, 7.5467e-03, 6.7667e+00,\n",
            "         7.2448e+01, 1.4523e+01, 3.3139e+04, 6.9136e-24],\n",
            "        [1.7063e-01, 3.8018e-01, 8.0657e-02, 2.2729e+00, 3.6620e+00, 3.3458e+00,\n",
            "         2.5245e+01, 3.4022e+01, 1.8071e+02, 9.7051e-02, 5.9179e+01, 3.3600e+01,\n",
            "         9.2649e+00, 8.5224e-01, 1.4353e+01, 4.0944e+00, 5.8885e-03, 5.3308e+00,\n",
            "         5.7000e+01, 1.1389e+01, 2.7936e+04, 5.3309e-24],\n",
            "        [1.0388e-11, 0.0000e+00, 0.0000e+00, 9.1702e-04, 3.5093e-04, 1.8057e-03,\n",
            "         8.9715e-04, 9.0470e-03, 1.5202e-02, 4.0942e-07, 7.5131e-03, 4.6415e-03,\n",
            "         4.1597e-05, 6.8967e-05, 1.9241e-03, 8.3358e-04, 1.1425e-08, 8.4766e-04,\n",
            "         8.6914e-03, 1.9036e-03, 2.5739e-02, 1.4943e-27],\n",
            "        [1.1798e-10, 0.0000e+00, 0.0000e+00, 5.1331e-04, 2.0239e-04, 9.7238e-04,\n",
            "         5.1340e-04, 4.6854e-03, 8.8081e-03, 1.3220e-07, 4.3520e-03, 2.9301e-03,\n",
            "         3.2817e-05, 3.4293e-05, 1.0057e-03, 4.5441e-04, 2.4776e-08, 4.7630e-04,\n",
            "         4.8698e-03, 1.0659e-03, 1.5626e-02, 8.5479e-28],\n",
            "        [5.1262e-02, 1.1056e-01, 2.2937e-02, 7.3106e-01, 1.1559e+00, 1.0941e+00,\n",
            "         7.8303e+00, 1.1054e+01, 5.8016e+01, 2.9184e-02, 1.8998e+01, 1.0695e+01,\n",
            "         2.9115e+00, 2.7364e-01, 4.6329e+00, 1.3168e+00, 1.7472e-03, 1.7100e+00,\n",
            "         1.8303e+01, 3.6601e+00, 8.9329e+03, 1.7231e-24],\n",
            "        [5.5049e-08, 0.0000e+00, 0.0000e+00, 1.9700e-02, 8.2111e-03, 3.2744e-02,\n",
            "         2.3883e-02, 1.5890e-01, 3.5598e-01, 2.8667e-06, 1.6738e-01, 1.2620e-01,\n",
            "         2.3153e-03, 1.0677e-03, 3.6239e-02, 1.3851e-02, 1.9023e-06, 1.7292e-02,\n",
            "         1.8156e-01, 3.9602e-02, 9.3526e-01, 4.0430e-26],\n",
            "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
            "        [4.6543e-11, 0.0000e+00, 0.0000e+00, 2.7331e-04, 7.6702e-05, 4.3806e-04,\n",
            "         1.7896e-04, 2.3941e-03, 3.2602e-03, 4.3891e-08, 1.8543e-03, 1.1009e-03,\n",
            "         5.8839e-06, 1.9611e-05, 4.3676e-04, 1.9455e-04, 0.0000e+00, 2.1084e-04,\n",
            "         2.1158e-03, 4.6539e-04, 5.2052e-03, 7.7582e-29],\n",
            "        [7.6010e-02, 1.7504e-01, 3.8252e-02, 1.0946e+00, 1.6358e+00, 1.5320e+00,\n",
            "         1.1376e+01, 1.5142e+01, 7.7291e+01, 4.3353e-02, 2.5978e+01, 1.5257e+01,\n",
            "         3.9317e+00, 3.5486e-01, 6.1742e+00, 1.7671e+00, 2.6745e-03, 2.3426e+00,\n",
            "         2.5087e+01, 5.0294e+00, 1.1449e+04, 2.3979e-24],\n",
            "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 2.9191e-08, 1.3015e-08, 7.3636e-08,\n",
            "         2.1962e-08, 2.0478e-07, 4.4827e-07, 0.0000e+00, 3.9610e-07, 2.4765e-07,\n",
            "         5.4954e-11, 1.2570e-09, 4.8532e-08, 6.4946e-08, 0.0000e+00, 2.3797e-08,\n",
            "         3.2188e-07, 7.1499e-08, 5.8258e-07, 3.4933e-39],\n",
            "        [3.5322e-07, 0.0000e+00, 0.0000e+00, 1.0131e-02, 3.7720e-03, 1.5495e-02,\n",
            "         1.0716e-02, 7.9612e-02, 1.6742e-01, 9.2043e-07, 7.8670e-02, 6.1228e-02,\n",
            "         1.0189e-03, 4.7103e-04, 1.7067e-02, 6.0467e-03, 8.9352e-07, 8.0714e-03,\n",
            "         8.6043e-02, 1.8789e-02, 5.3902e-01, 1.8597e-26],\n",
            "        [2.0572e-01, 4.5717e-01, 9.7047e-02, 2.9750e+00, 4.5695e+00, 4.3392e+00,\n",
            "         3.1189e+01, 4.3266e+01, 2.2398e+02, 1.1712e-01, 7.3993e+01, 4.2415e+01,\n",
            "         1.1244e+01, 1.0476e+00, 1.7910e+01, 5.1083e+00, 7.1423e-03, 6.6809e+00,\n",
            "         7.1492e+01, 1.4314e+01, 3.3724e+04, 6.7674e-24],\n",
            "        [7.3259e-06, 0.0000e+00, 0.0000e+00, 7.2596e-02, 2.4985e-02, 9.7219e-02,\n",
            "         7.9541e-02, 5.3929e-01, 1.0225e+00, 4.9592e-06, 5.0856e-01, 4.1047e-01,\n",
            "         7.0544e-03, 2.6241e-03, 1.1008e-01, 3.2786e-02, 3.1160e-06, 4.9294e-02,\n",
            "         5.4777e-01, 1.1974e-01, 5.7505e+00, 1.0499e-25],\n",
            "        [2.8566e-01, 6.3603e-01, 1.3523e-01, 4.1312e+00, 6.3355e+00, 6.0142e+00,\n",
            "         4.3281e+01, 5.9931e+01, 3.1001e+02, 1.6265e-01, 1.0249e+02, 5.8822e+01,\n",
            "         1.5569e+01, 1.4489e+00, 2.4789e+01, 7.0724e+00, 9.9250e-03, 9.2544e+00,\n",
            "         9.9033e+01, 1.9830e+01, 4.6632e+04, 9.3776e-24],\n",
            "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
            "        [7.7860e-03, 1.8489e-02, 4.1395e-03, 1.0827e-01, 1.6012e-01, 1.4363e-01,\n",
            "         1.1452e+00, 1.4454e+00, 7.3073e+00, 4.4597e-03, 2.4933e+00, 1.4891e+00,\n",
            "         3.8344e-01, 3.3213e-02, 5.8367e-01, 1.6507e-01, 2.7312e-04, 2.2393e-01,\n",
            "         2.4031e+00, 4.8171e-01, 1.0977e+03, 2.2960e-25],\n",
            "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 7.6073e-07, 3.6594e-07, 1.3701e-06,\n",
            "         8.5672e-07, 5.3464e-06, 1.5938e-05, 3.3742e-12, 7.8948e-06, 6.5311e-06,\n",
            "         9.3055e-08, 3.1798e-08, 1.3020e-06, 7.5028e-07, 1.9665e-10, 8.5091e-07,\n",
            "         7.8391e-06, 1.7136e-06, 2.1758e-05, 8.1289e-31],\n",
            "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
            "        [3.7059e-01, 8.2640e-01, 1.7596e-01, 5.3670e+00, 8.2146e+00, 7.7977e+00,\n",
            "         5.6153e+01, 7.7648e+01, 4.0120e+02, 2.1106e-01, 1.3279e+02, 7.6303e+01,\n",
            "         2.0154e+01, 1.8729e+00, 3.2084e+01, 9.1547e+00, 1.2883e-02, 1.1989e+01,\n",
            "         1.2830e+02, 2.5693e+01, 6.0277e+04, 1.2159e-23],\n",
            "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
            "        [2.6559e-01, 6.0521e-01, 1.3118e-01, 3.8546e+00, 5.7907e+00, 5.4715e+00,\n",
            "         3.9996e+01, 5.4106e+01, 2.7670e+02, 1.5157e-01, 9.2564e+01, 5.3952e+01,\n",
            "         1.3982e+01, 1.2784e+00, 2.2133e+01, 6.3337e+00, 9.3074e-03, 8.3539e+00,\n",
            "         8.9438e+01, 1.7926e+01, 4.1087e+04, 8.5192e-24],\n",
            "        [3.7728e-04, 4.1435e-04, 8.3006e-05, 9.3359e-03, 1.7484e-02, 1.4976e-02,\n",
            "         1.0550e-01, 1.9926e-01, 1.0504e+00, 3.3420e-04, 3.8535e-01, 1.7381e-01,\n",
            "         4.7999e-02, 4.9266e-03, 8.5625e-02, 1.9714e-02, 7.7364e-06, 2.8712e-02,\n",
            "         3.1918e-01, 6.3788e-02, 2.3848e+02, 3.8263e-26],\n",
            "        [2.7911e-02, 6.0832e-02, 1.2713e-02, 4.0439e-01, 6.3012e-01, 6.0040e-01,\n",
            "         4.2653e+00, 6.0177e+00, 3.1366e+01, 1.5888e-02, 1.0293e+01, 5.8374e+00,\n",
            "         1.5683e+00, 1.4766e-01, 2.5086e+00, 7.1349e-01, 9.6140e-04, 9.2905e-01,\n",
            "         9.9405e+00, 1.9891e+00, 4.7646e+03, 9.3874e-25],\n",
            "        [1.3047e-01, 2.8054e-01, 5.8044e-02, 1.9260e+00, 2.9941e+00, 2.8798e+00,\n",
            "         2.0150e+01, 2.8805e+01, 1.5006e+02, 7.4431e-02, 4.9180e+01, 2.7788e+01,\n",
            "         7.4807e+00, 7.0772e-01, 1.2015e+01, 3.4070e+00, 4.4640e-03, 4.4345e+00,\n",
            "         4.7474e+01, 9.5003e+00, 2.2891e+04, 4.5020e-24],\n",
            "        [4.4216e-01, 9.8791e-01, 2.1051e-01, 5.9539e+00, 9.4429e+00, 8.6903e+00,\n",
            "         6.5010e+01, 8.8049e+01, 4.6361e+02, 2.4994e-01, 1.5227e+02, 8.6818e+01,\n",
            "         2.3679e+01, 2.1790e+00, 3.6890e+01, 1.0514e+01, 1.5230e-02, 1.3720e+01,\n",
            "         1.4678e+02, 2.9341e+01, 7.1463e+04, 1.3634e-23],\n",
            "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 3.5663e-09, 4.0345e-09, 2.8068e-09,\n",
            "         1.6886e-08, 2.8503e-08, 1.6431e-07, 5.1768e-11, 5.2649e-08, 1.7661e-08,\n",
            "         1.2690e-09, 1.3700e-10, 2.2734e-08, 3.7802e-09, 0.0000e+00, 5.0422e-09,\n",
            "         6.1820e-08, 1.3298e-08, 2.2919e-07, 5.2446e-36],\n",
            "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
            "        [8.1922e-13, 0.0000e+00, 0.0000e+00, 5.1497e-06, 6.1232e-07, 3.3528e-06,\n",
            "         1.4060e-06, 3.3947e-05, 3.0012e-05, 0.0000e+00, 1.5886e-05, 1.0050e-05,\n",
            "         1.3247e-07, 3.3947e-07, 4.0534e-06, 5.4362e-07, 0.0000e+00, 2.3607e-06,\n",
            "         2.1566e-05, 4.7185e-06, 6.2975e-05, 3.8995e-31],\n",
            "        [8.6730e-11, 0.0000e+00, 0.0000e+00, 6.3138e-04, 2.5630e-04, 1.1786e-03,\n",
            "         6.5726e-04, 5.7784e-03, 1.1388e-02, 1.6366e-07, 5.3054e-03, 3.6888e-03,\n",
            "         4.7526e-05, 4.1582e-05, 1.2597e-03, 5.2537e-04, 4.1541e-08, 5.9170e-04,\n",
            "         6.0513e-03, 1.3220e-03, 2.0014e-02, 1.3566e-27],\n",
            "        [6.6546e-01, 1.5097e+00, 3.2607e-01, 9.6503e+00, 1.4556e+01, 1.3766e+01,\n",
            "         1.0033e+02, 1.3634e+02, 6.9886e+02, 3.7960e-01, 2.3323e+02, 1.3553e+02,\n",
            "         3.5271e+01, 3.2364e+00, 5.5897e+01, 1.5986e+01, 2.3282e-02, 2.1051e+01,\n",
            "         2.2536e+02, 4.5160e+01, 1.0405e+05, 2.1439e-23],\n",
            "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
            "        [8.1672e-03, 1.7642e-02, 3.6610e-03, 1.1839e-01, 1.8573e-01, 1.7701e-01,\n",
            "         1.2535e+00, 1.7785e+00, 9.2962e+00, 4.6534e-03, 3.0440e+00, 1.7188e+00,\n",
            "         4.6441e-01, 4.3860e-02, 7.4359e-01, 2.1119e-01, 2.8011e-04, 2.7461e-01,\n",
            "         2.9384e+00, 5.8784e-01, 1.4179e+03, 2.7722e-25]])}, Parameter containing:\n",
            "tensor([-0.2079,  0.1196, -0.0886, -0.2132, -0.2260, -0.0766, -0.0996, -0.2450,\n",
            "        -0.2750,  0.0101, -0.0784,  0.0394, -0.2738,  0.0170, -0.0795, -0.2956,\n",
            "        -0.0432,  0.1637, -0.0730,  0.2028,  0.1388, -0.1840, -0.1407, -0.1252,\n",
            "         0.0732, -0.2234, -0.0507, -0.1001, -0.1326, -0.0048, -0.1891, -0.0711],\n",
            "       requires_grad=True): {'step': 1263, 'exp_avg': tensor([ 1.2785e-06,  3.9768e-06,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
            "         5.6052e-45,  0.0000e+00,  5.6052e-45, -3.2241e-06,  5.6052e-45,\n",
            "         5.6052e-45, -2.5101e-05,  5.6052e-45,  1.3388e-05,  0.0000e+00,\n",
            "        -1.9932e-08,  5.6052e-45,  0.0000e+00,  6.2541e-06,  0.0000e+00,\n",
            "        -3.7423e-05,  5.6052e-45,  3.1012e-06,  5.6052e-45, -5.9943e-06,\n",
            "         5.6052e-45,  0.0000e+00,  5.6052e-45,  5.6052e-45, -1.8507e-05,\n",
            "         0.0000e+00, -2.4202e-07]), 'exp_avg_sq': tensor([5.8638e-02, 4.6081e-02, 7.0871e-06, 3.9740e-06, 1.4794e-02, 1.4869e-04,\n",
            "        0.0000e+00, 1.7237e-06, 2.0310e-02, 2.6077e-10, 7.0559e-05, 5.7824e-02,\n",
            "        4.5066e-04, 8.0102e-02, 0.0000e+00, 1.9469e-03, 6.3929e-09, 0.0000e+00,\n",
            "        1.0378e-01, 0.0000e+00, 7.2386e-02, 2.5694e-04, 8.0369e-03, 3.8379e-02,\n",
            "        1.1869e-01, 5.0422e-11, 0.0000e+00, 1.7653e-08, 4.9407e-06, 1.8237e-01,\n",
            "        0.0000e+00, 2.3754e-03])}, Parameter containing:\n",
            "tensor([[ 0.0114, -0.0148, -0.0744, -0.0358, -0.0042,  0.0574,  0.1731, -0.0959,\n",
            "          0.0136, -0.0138,  0.0008, -0.0601,  0.0578, -0.0607, -0.0517, -0.0021,\n",
            "          0.0366,  0.0874, -0.0328, -0.0534,  0.0523,  0.0479,  0.0054, -0.0485,\n",
            "         -0.0269, -0.0587, -0.1044,  0.0174, -0.0358,  0.0970,  0.0812,  0.0018]],\n",
            "       requires_grad=True): {'step': 1263, 'exp_avg': tensor([[ 8.3052e-03,  2.4154e-04, -5.6052e-45,  5.6052e-45, -5.6052e-45,\n",
            "          5.6052e-45,  0.0000e+00, -5.6052e-45,  6.6590e-03, -5.6052e-45,\n",
            "          5.6052e-45,  6.6951e-03,  5.6052e-45, -5.6624e-03,  0.0000e+00,\n",
            "          1.7626e-05, -5.6052e-45,  0.0000e+00, -6.3459e-04,  0.0000e+00,\n",
            "          4.3001e-03, -5.6052e-45,  6.9431e-03, -5.6052e-45, -1.2778e-02,\n",
            "         -5.6052e-45,  0.0000e+00, -5.6052e-45, -5.6052e-45,  1.0511e-03,\n",
            "          0.0000e+00,  1.1056e-03]]), 'exp_avg_sq': tensor([[6.4152e+03, 1.9535e+04, 9.3266e-03, 2.3082e-02, 1.1874e+03, 2.3410e-01,\n",
            "         0.0000e+00, 5.5445e-05, 6.6655e+04, 3.3127e-10, 2.3322e-01, 9.6988e+04,\n",
            "         1.3938e+00, 1.1707e+05, 0.0000e+00, 2.6398e+04, 1.0733e-05, 0.0000e+00,\n",
            "         2.1206e+04, 0.0000e+00, 8.7166e+04, 1.0167e+03, 4.0027e+04, 1.5092e+03,\n",
            "         1.2902e+04, 1.6955e-10, 0.0000e+00, 9.0972e-06, 7.7434e-03, 4.8463e+04,\n",
            "         0.0000e+00, 6.9255e+04]])}, Parameter containing:\n",
            "tensor([-0.1059], requires_grad=True): {'step': 1263, 'exp_avg': tensor([-0.0002]), 'exp_avg_sq': tensor([6.3556])}}), 'param_groups': [{'params': [Parameter containing:\n",
            "tensor([[ 8.9006e-02,  1.7240e-01, -7.3862e-04, -2.1073e-01, -1.5405e-01,\n",
            "          9.8008e-02,  3.9343e-03,  1.1310e-01,  1.2040e-01,  4.5003e-03,\n",
            "         -1.9355e-01,  1.5313e-01, -4.2645e-02,  6.4914e-02, -1.8292e-01,\n",
            "         -2.0988e-01,  1.4619e-01, -4.2632e-02,  1.5490e-01, -1.9035e-02,\n",
            "         -1.1998e-02, -1.3924e-01],\n",
            "        [ 6.7260e-02, -1.6979e-01, -1.2456e-01, -2.1266e-01,  3.6660e-04,\n",
            "         -1.9455e-02, -7.4534e-02, -1.9000e-01,  4.7516e-02, -1.8370e-01,\n",
            "          1.0037e-01, -1.3768e-01,  1.5320e-01,  1.1440e-01, -2.1075e-01,\n",
            "         -8.7111e-02,  1.3180e-02, -1.9446e-01, -1.2508e-01, -1.5153e-01,\n",
            "          2.9911e-02,  4.3956e-02],\n",
            "        [-1.0184e-01,  1.4974e-01, -1.7047e-01, -2.4900e-01, -4.9292e-02,\n",
            "         -3.2950e-02, -5.3854e-02,  1.6512e-01,  7.0563e-02,  1.3359e-01,\n",
            "          1.7745e-01, -2.3375e-01, -5.0192e-02,  1.7227e-01,  1.6698e-01,\n",
            "         -1.3140e-01,  5.2424e-02,  1.4290e-01,  9.3561e-02,  1.4412e-01,\n",
            "         -2.4142e-01,  1.6049e-01],\n",
            "        [-5.3129e-02,  3.4726e-03,  1.7949e-01, -2.3262e-01, -1.5055e-01,\n",
            "          1.1489e-01, -4.8788e-02,  7.9745e-02, -8.3752e-02, -2.1942e-01,\n",
            "          3.7560e-02, -2.9393e-02, -1.0127e-01, -7.6493e-03, -1.0051e-01,\n",
            "         -1.1837e-01, -2.0918e-01, -2.1336e-01, -9.1195e-02, -1.0424e-01,\n",
            "         -2.5483e-01, -5.8858e-02],\n",
            "        [ 1.2915e-01, -2.7293e-02,  4.7558e-02, -2.8809e-01, -1.2994e-01,\n",
            "         -6.3608e-02,  1.1536e-02, -4.7024e-02, -1.3857e-01, -5.0848e-02,\n",
            "         -7.8100e-02,  2.7066e-02, -2.7871e-01, -1.6121e-01, -2.5827e-01,\n",
            "         -5.0638e-02, -1.9154e-02, -7.8689e-02,  2.1721e-02,  1.2490e-02,\n",
            "         -4.6773e-02,  2.7905e-02],\n",
            "        [ 3.3692e-02,  1.4122e-01, -1.8523e-01, -2.2190e-01, -7.1197e-02,\n",
            "         -8.4842e-02, -6.2386e-02, -3.2937e-02, -1.4721e-02, -1.4681e-01,\n",
            "          1.0531e-01, -2.7789e-01,  7.6092e-02, -1.5898e-01, -1.8466e-01,\n",
            "         -5.7131e-02, -2.6491e-02, -6.1153e-02,  1.1667e-01,  5.7357e-02,\n",
            "         -2.0657e-01, -1.1141e-01],\n",
            "        [ 1.0324e-01,  7.8766e-02,  7.3278e-02, -6.9036e-02, -1.9020e-01,\n",
            "          1.1867e-01, -1.6583e-03,  1.3939e-01, -1.3910e-01,  5.1952e-02,\n",
            "         -2.5898e-02, -6.4122e-02,  7.9880e-02,  8.2586e-02, -1.2160e-01,\n",
            "         -2.0953e-02, -1.3350e-01,  1.9840e-01,  1.7029e-03, -1.4155e-01,\n",
            "         -1.6158e-01, -7.8760e-02],\n",
            "        [-8.1650e-02,  1.2327e-01, -5.7273e-02, -6.5277e-03, -1.0708e-02,\n",
            "         -1.3710e-01,  3.4603e-02,  5.6534e-02, -2.3290e-01, -1.8005e-01,\n",
            "         -3.9656e-02,  7.5855e-02,  1.6020e-02, -2.3613e-01, -4.6768e-03,\n",
            "         -1.3494e-02,  4.0143e-02, -1.4649e-02,  5.8175e-02, -1.1798e-01,\n",
            "         -1.8038e-01, -1.5506e-01],\n",
            "        [ 1.2957e-01,  6.0548e-02,  7.4940e-02, -1.8516e-02, -2.3897e-01,\n",
            "          3.8975e-02, -2.3043e-01, -2.0318e-01, -4.5861e-02, -2.9243e-01,\n",
            "         -5.8714e-02,  4.0270e-02,  2.9105e-02,  1.4777e-01, -1.4327e-01,\n",
            "         -6.3140e-02,  8.9007e-02, -2.0743e-01, -2.1926e-01,  2.7268e-01,\n",
            "          6.8848e-02,  9.3490e-02],\n",
            "        [-1.7936e-01, -1.1869e-01,  1.4358e-01,  9.5161e-02,  4.5319e-02,\n",
            "         -5.4651e-02, -2.0740e-01, -9.5976e-02,  5.2658e-02, -2.0998e-01,\n",
            "          9.3186e-02, -1.2599e-01,  7.2266e-02, -5.9341e-02, -5.0892e-02,\n",
            "          1.8088e-02,  4.9995e-02, -2.1268e-01, -1.1709e-01,  1.7629e-01,\n",
            "         -1.0939e-01, -8.8717e-02],\n",
            "        [-5.9538e-02,  1.2324e-01,  8.8273e-02,  8.5794e-02,  6.6409e-02,\n",
            "         -2.6214e-01, -2.8398e-01, -1.7363e-02,  4.1362e-02, -7.4297e-02,\n",
            "         -1.9452e-01,  1.0348e-01,  3.7318e-02, -1.6067e-01,  5.7227e-02,\n",
            "          8.6453e-02, -1.4214e-01, -2.8005e-01, -8.1703e-02,  5.5583e-02,\n",
            "         -1.8275e-01,  2.0397e-01],\n",
            "        [-2.5082e-02,  3.4787e-02, -8.3827e-02, -4.9524e-02,  1.7697e-01,\n",
            "         -9.0844e-02,  7.7990e-02,  2.1506e-02, -2.7652e-01,  8.3694e-02,\n",
            "          1.9480e-01,  6.6266e-02,  1.5618e-01, -1.7368e-01,  4.8844e-02,\n",
            "          4.2340e-02, -1.5310e-01,  1.2387e-01, -1.4588e-01, -7.1494e-03,\n",
            "          1.0405e-01,  6.1986e-02],\n",
            "        [-7.8637e-02,  1.9119e-01, -1.0650e-02,  1.2374e-01,  1.1823e-01,\n",
            "         -1.8711e-01, -1.6842e-01,  8.8823e-02, -6.3886e-02, -2.3087e-01,\n",
            "         -1.3772e-01,  1.0137e-01,  8.4369e-02, -1.4828e-01, -9.5749e-03,\n",
            "         -1.0015e-01, -1.4231e-01,  9.9914e-03, -1.2642e-01, -1.2801e-01,\n",
            "         -1.9897e-01, -4.5656e-02],\n",
            "        [ 1.6557e-01,  6.7866e-02, -3.5271e-02,  3.6577e-02, -1.9451e-01,\n",
            "          7.6476e-02,  1.0374e-01, -1.5609e-01,  4.6896e-02, -2.3004e-01,\n",
            "         -5.1200e-02,  1.5286e-01, -2.3629e-01, -6.3102e-02, -8.2445e-02,\n",
            "         -3.8065e-02, -1.5006e-01, -1.8536e-01,  1.3262e-02,  2.3026e-02,\n",
            "          1.1177e-01,  2.0236e-01],\n",
            "        [ 2.0003e-01,  1.7704e-01, -1.3710e-01,  2.4582e-02,  2.5518e-02,\n",
            "         -2.5868e-02, -1.7519e-01,  7.9375e-02, -1.5112e-01, -1.1814e-01,\n",
            "         -2.1881e-03, -1.5617e-02, -1.8498e-01,  1.5888e-01, -6.9953e-02,\n",
            "          1.9284e-01, -1.3973e-01,  4.2696e-02, -1.4620e-01, -1.2566e-01,\n",
            "         -7.1679e-02,  1.0366e-01],\n",
            "        [ 5.5690e-02, -1.2572e-01, -2.4853e-01,  1.1525e-02, -2.2235e-01,\n",
            "         -1.5575e-01, -2.1473e-02, -5.3989e-02, -2.6666e-01, -2.7092e-01,\n",
            "         -2.9847e-01,  8.0389e-02, -2.8547e-01, -2.3792e-01, -8.6329e-02,\n",
            "         -2.2742e-01, -4.8039e-02, -1.2875e-02, -6.3000e-03,  2.3134e-01,\n",
            "          1.9201e-02, -1.5889e-01],\n",
            "        [-1.0535e-01,  1.3129e-01, -6.2635e-02, -1.2161e-01, -2.1695e-02,\n",
            "         -1.8665e-01, -2.3470e-01,  5.0899e-02,  1.7348e-02,  4.4788e-02,\n",
            "          1.3856e-01,  5.5494e-02,  6.6865e-02, -5.0410e-02, -7.3080e-02,\n",
            "         -5.7380e-02, -1.2793e-01,  5.1544e-02, -2.2224e-01,  8.3176e-02,\n",
            "         -1.6024e-01,  1.7178e-01],\n",
            "        [ 1.1238e-01, -1.9893e-02, -1.3277e-01, -1.6570e-01,  2.1302e-01,\n",
            "         -1.1823e-01, -1.3658e-01, -1.8334e-01, -3.9861e-02,  8.9787e-02,\n",
            "          1.3153e-01,  7.5774e-02, -2.0185e-01,  1.1791e-01,  7.0294e-03,\n",
            "         -1.8543e-01, -9.7754e-02, -1.5560e-01,  1.4383e-02, -1.0519e-01,\n",
            "         -2.0545e-01,  8.7432e-02],\n",
            "        [-3.5440e-02,  1.6092e-01, -1.7671e-01, -6.5253e-02, -1.2143e-01,\n",
            "         -2.2218e-01, -5.5109e-02,  1.2215e-01,  7.1414e-02, -2.1712e-01,\n",
            "          5.5828e-02,  1.6644e-01,  7.4404e-02, -1.6748e-01,  1.0327e-01,\n",
            "         -8.4116e-02,  1.7943e-02,  8.5155e-02, -4.1637e-02,  2.2670e-01,\n",
            "          1.3302e-02,  6.5327e-04],\n",
            "        [ 7.3060e-02, -2.1726e-02, -2.8004e-02,  2.8051e-02, -6.4629e-02,\n",
            "         -3.6933e-02,  1.9400e-01, -1.2149e-01, -1.6973e-01,  6.5351e-02,\n",
            "          1.6123e-04, -1.4021e-01, -1.0485e-01, -1.0496e-01, -1.5989e-02,\n",
            "         -1.4995e-02,  1.8234e-01, -7.6295e-02,  1.4113e-01, -9.9309e-02,\n",
            "         -5.9704e-02,  1.7647e-01],\n",
            "        [ 1.8532e-03,  9.8720e-02,  1.8659e-02, -8.5535e-02,  9.3898e-02,\n",
            "          2.3073e-03, -5.2899e-02, -1.5686e-01, -8.1594e-02, -1.9131e-01,\n",
            "          6.3864e-02,  1.3651e-01,  2.5144e-02,  8.2117e-03,  1.8134e-01,\n",
            "         -9.7507e-02, -1.3476e-01, -8.4970e-02, -5.3713e-02,  9.2802e-02,\n",
            "          1.0779e-01,  4.1128e-02],\n",
            "        [-4.8485e-02, -1.2821e-01,  9.1751e-02, -2.5840e-01, -2.4985e-01,\n",
            "         -2.8358e-01, -2.5354e-01,  1.4321e-02, -1.2738e-01, -2.3781e-01,\n",
            "          4.3154e-02, -3.2443e-03, -3.1111e-01, -4.1958e-02, -1.5859e-01,\n",
            "         -2.9473e-01,  9.6869e-02, -2.2698e-01, -3.0675e-01,  6.6761e-02,\n",
            "         -6.2966e-02, -1.4892e-01],\n",
            "        [-2.2934e-02,  4.6730e-02,  1.0096e-01, -1.1321e-01, -2.7499e-01,\n",
            "         -1.4823e-01, -1.4550e-01, -1.6671e-02, -1.5677e-03, -2.4342e-02,\n",
            "         -1.6825e-01,  1.0212e-01,  2.5343e-02, -4.0655e-02,  1.7614e-02,\n",
            "          8.9644e-02, -2.8627e-01,  6.4274e-02, -8.0571e-02,  4.8564e-03,\n",
            "          1.7752e-02, -1.3622e-01],\n",
            "        [-1.0317e-01, -1.4169e-01, -7.9792e-02, -9.6562e-03,  6.0311e-03,\n",
            "          5.8048e-02, -2.1332e-01, -2.9887e-02, -5.1988e-02, -1.4523e-01,\n",
            "          3.4272e-02,  8.3705e-02, -2.1590e-02, -2.3207e-01, -1.4003e-01,\n",
            "         -5.3121e-02, -2.1188e-01,  1.4275e-01,  3.4861e-02, -3.1883e-02,\n",
            "         -6.3537e-02, -3.8595e-02],\n",
            "        [ 5.3968e-02, -2.0882e-01, -1.0388e-01,  9.0632e-02, -6.2769e-02,\n",
            "          1.4259e-01, -5.1977e-02, -1.6128e-01,  1.0428e-02, -6.3955e-02,\n",
            "         -9.3728e-02,  1.0527e-01, -2.0950e-01, -1.0779e-01, -1.2938e-01,\n",
            "          4.6993e-02, -2.4278e-01, -2.0845e-01, -8.5966e-02,  8.3100e-02,\n",
            "          2.8873e-02,  8.2027e-02],\n",
            "        [ 1.7241e-01, -2.0846e-01,  3.7933e-02, -2.3297e-01, -2.3048e-01,\n",
            "         -2.2674e-01, -1.1526e-01, -1.5117e-01,  5.4007e-03, -8.5077e-02,\n",
            "         -1.2590e-01, -1.6052e-01,  1.4849e-01,  7.6535e-02,  6.6378e-02,\n",
            "         -2.5380e-01, -2.0486e-01,  9.0941e-02,  1.2169e-01, -1.2678e-01,\n",
            "         -9.8034e-02, -2.0791e-01],\n",
            "        [ 3.2351e-02,  8.8450e-02, -1.5787e-01,  1.4066e-01, -3.9995e-02,\n",
            "          1.1149e-01,  1.7127e-01,  1.1466e-01, -1.8791e-01,  1.8222e-01,\n",
            "          1.4210e-01, -1.9938e-01, -1.0537e-01,  2.4362e-02, -1.7710e-01,\n",
            "          2.0958e-01, -1.4499e-01, -1.9660e-02,  1.3145e-01,  1.5118e-01,\n",
            "         -1.9652e-01, -8.6015e-02],\n",
            "        [ 1.1492e-01, -1.3243e-01,  6.5916e-02,  1.1481e-02,  1.0126e-01,\n",
            "         -7.2988e-02, -1.5938e-01,  7.0293e-02, -1.1731e-01,  1.7409e-01,\n",
            "         -2.6034e-01,  1.2452e-01, -7.3972e-02,  3.3482e-02, -1.0320e-02,\n",
            "         -2.3060e-01, -1.4440e-02,  7.4103e-02, -1.4251e-02, -6.1448e-02,\n",
            "         -1.4078e-01, -1.9099e-01],\n",
            "        [-3.9840e-03, -1.5695e-02, -4.3495e-02, -2.9343e-02, -5.4481e-02,\n",
            "          1.2443e-01, -2.3870e-01,  5.9997e-02,  1.4634e-01,  1.4642e-01,\n",
            "         -2.4588e-01, -2.8197e-02, -1.8600e-01,  7.3840e-02, -3.0251e-02,\n",
            "          6.9418e-03, -1.3485e-02, -1.9516e-01,  3.7673e-02, -1.3190e-01,\n",
            "         -2.1913e-01, -8.0650e-03],\n",
            "        [ 1.2382e-01, -9.0051e-02, -9.5602e-02,  7.6352e-02, -7.2662e-02,\n",
            "         -8.9230e-02,  1.2873e-01,  1.7558e-02, -7.7953e-02, -3.7710e-02,\n",
            "          9.3275e-02,  1.1896e-01, -5.6176e-02, -1.8207e-01, -9.1769e-02,\n",
            "          8.6835e-02, -8.1731e-02,  6.7510e-03, -6.6379e-02,  2.0538e-02,\n",
            "          8.2764e-02,  7.1990e-02],\n",
            "        [-5.7039e-02, -2.0154e-01,  1.9934e-01, -1.7485e-01,  1.7996e-01,\n",
            "          1.5244e-01,  6.9768e-02, -7.8110e-02, -1.9364e-01, -1.0852e-01,\n",
            "         -1.1483e-01, -2.0203e-01,  2.0158e-01,  5.0899e-02, -1.7721e-02,\n",
            "          5.3331e-02,  1.4912e-01, -3.1553e-02, -3.6944e-02, -1.9786e-01,\n",
            "         -1.4350e-01,  5.7852e-02],\n",
            "        [-3.4058e-01,  8.0465e-02, -2.6906e-01, -5.8237e-02, -3.2209e-01,\n",
            "         -7.9201e-02, -3.0732e-01, -2.5668e-01, -1.2072e-03, -9.9813e-02,\n",
            "          5.3049e-02, -9.0907e-02, -1.7665e-01, -3.3188e-01, -2.4335e-02,\n",
            "         -3.3899e-01, -1.9316e-01,  6.8571e-02, -9.9812e-02,  1.5124e-01,\n",
            "          2.1294e-02,  2.9409e-02]], requires_grad=True), Parameter containing:\n",
            "tensor([-0.2079,  0.1196, -0.0886, -0.2132, -0.2260, -0.0766, -0.0996, -0.2450,\n",
            "        -0.2750,  0.0101, -0.0784,  0.0394, -0.2738,  0.0170, -0.0795, -0.2956,\n",
            "        -0.0432,  0.1637, -0.0730,  0.2028,  0.1388, -0.1840, -0.1407, -0.1252,\n",
            "         0.0732, -0.2234, -0.0507, -0.1001, -0.1326, -0.0048, -0.1891, -0.0711],\n",
            "       requires_grad=True), Parameter containing:\n",
            "tensor([[ 0.0114, -0.0148, -0.0744, -0.0358, -0.0042,  0.0574,  0.1731, -0.0959,\n",
            "          0.0136, -0.0138,  0.0008, -0.0601,  0.0578, -0.0607, -0.0517, -0.0021,\n",
            "          0.0366,  0.0874, -0.0328, -0.0534,  0.0523,  0.0479,  0.0054, -0.0485,\n",
            "         -0.0269, -0.0587, -0.1044,  0.0174, -0.0358,  0.0970,  0.0812,  0.0018]],\n",
            "       requires_grad=True), Parameter containing:\n",
            "tensor([-0.1059], requires_grad=True)], 'lr': 0.01, 'betas': (0.9, 0.999), 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}]}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u8S5eB9dPo9m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}